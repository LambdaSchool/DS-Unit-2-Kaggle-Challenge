{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Curry 223 assignment_kaggle_challenge_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikedcurry/DS-Unit-2-Kaggle-Challenge/blob/master/Curry_223_assignment_kaggle_challenge_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IXUfiQ2UKj6",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Kaggle Challenge, Module 3\n",
        "\n",
        "## Assignment\n",
        "- [ ] [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2/portfolio-project/ds6), then choose your dataset, and [submit this form](https://forms.gle/nyWURUg65x1UTRNV9), due today at 4pm Pacific.\n",
        "- [ ] Continue to participate in our Kaggle challenge.\n",
        "- [ ] Try xgboost.\n",
        "- [ ] Get your model's permutation importances.\n",
        "- [ ] Try feature selection with permutation importances.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Doing\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Do more exploratory data analysis, data cleaning, feature engineering, and feature selection.\n",
        "- [ ] Try other categorical encodings.\n",
        "- [ ] Try other Python libraries for gradient boosting.\n",
        "- [ ] Look at the bonus notebook in the repo, about monotonic constraints with gradient boosting.\n",
        "- [ ] Make visualizations and share on Slack.\n",
        "\n",
        "### Reading\n",
        "\n",
        "Top recommendations in _**bold italic:**_\n",
        "\n",
        "#### Permutation Importances\n",
        "- _**[Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)**_\n",
        "- [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "\n",
        "#### (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "#### Gradient Boosting\n",
        "  - [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
        "  - _**[A Kaggle Master Explains Gradient Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)**_\n",
        "  - [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8\n",
        "  - [Gradient Boosting Explained](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)\n",
        "  - _**[Boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw) (2.5 minute video)**_\n",
        "\n",
        "#### Categorical encoding for trees\n",
        "- [Are categorical variables getting lost in your random forests?](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)\n",
        "- [Beyond One-Hot: An Exploration of Categorical Variables](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/)\n",
        "- _**[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)**_\n",
        "- _**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)**_\n",
        "- [Mean (likelihood) encodings: a comprehensive study](https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study)\n",
        "- [The Mechanics of Machine Learning, Chapter 6: Categorically Speaking](https://mlbook.explained.ai/catvars.html)\n",
        "\n",
        "#### Imposter Syndrome\n",
        "- [Effort Shock and Reward Shock (How The Karate Kid Ruined The Modern World)](http://www.tempobook.com/2014/07/09/effort-shock-and-reward-shock/)\n",
        "- [How to manage impostor syndrome in data science](https://towardsdatascience.com/how-to-manage-impostor-syndrome-in-data-science-ad814809f068)\n",
        "- [\"I am not a real data scientist\"](https://brohrer.github.io/imposter_syndrome.html)\n",
        "- _**[Imposter Syndrome in Data Science](https://caitlinhudon.com/2018/01/19/imposter-syndrome-in-data-science/)**_\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd6T-m6bneLS",
        "colab_type": "text"
      },
      "source": [
        "### Python libraries for Gradient Boosting\n",
        "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
        "  - Anaconda: already installed\n",
        "  - Google Colab: already installed\n",
        "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
        "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
        "  - Windows: `conda install -c anaconda py-xgboost`\n",
        "  - Google Colab: already installed\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
        "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
        "  - Google Colab: already installed\n",
        "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
        "  - Anaconda: `conda install -c conda-forge catboost`\n",
        "  - Google Colab: `pip install catboost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1nF5eU9nJwL",
        "colab_type": "text"
      },
      "source": [
        "### Categorical Encodings\n",
        "\n",
        "**1.** The article **[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)** mentions 4 encodings:\n",
        "\n",
        "- **\"Categorical Encoding\":** This means using the raw categorical values as-is, not encoded. Scikit-learn doesn't support this, but some tree algorithm implementations do. For example, [Catboost](https://catboost.ai/), or R's [rpart](https://cran.r-project.org/web/packages/rpart/index.html) package.\n",
        "- **Numeric Encoding:** Synonymous with Label Encoding, or \"Ordinal\" Encoding with random order. We can use [category_encoders.OrdinalEncoder](https://contrib.scikit-learn.org/categorical-encoding/ordinal.html).\n",
        "- **One-Hot Encoding:** We can use [category_encoders.OneHotEncoder](http://contrib.scikit-learn.org/categorical-encoding/onehot.html).\n",
        "- **Binary Encoding:** We can use [category_encoders.BinaryEncoder](http://contrib.scikit-learn.org/categorical-encoding/binary.html).\n",
        "\n",
        "\n",
        "**2.** The short video \n",
        "**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)** introduces an interesting idea: use both X _and_ y to encode categoricals.\n",
        "\n",
        "Category Encoders has multiple implementations of this general concept:\n",
        "\n",
        "- [CatBoost Encoder](http://contrib.scikit-learn.org/categorical-encoding/catboost.html)\n",
        "- [James-Stein Encoder](http://contrib.scikit-learn.org/categorical-encoding/jamesstein.html)\n",
        "- [Leave One Out](http://contrib.scikit-learn.org/categorical-encoding/leaveoneout.html)\n",
        "- [M-estimate](http://contrib.scikit-learn.org/categorical-encoding/mestimate.html)\n",
        "- [Target Encoder](http://contrib.scikit-learn.org/categorical-encoding/targetencoder.html)\n",
        "- [Weight of Evidence](http://contrib.scikit-learn.org/categorical-encoding/woe.html)\n",
        "\n",
        "Category Encoder's mean encoding implementations work for regression problems or binary classification problems. \n",
        "\n",
        "For multi-class classification problems, you will need to temporarily reformulate it as binary classification. For example:\n",
        "\n",
        "```python\n",
        "encoder = ce.TargetEncoder(min_samples_leaf=..., smoothing=...) # Both parameters > 1 to avoid overfitting\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train=='functional')\n",
        "X_val_encoded = encoder.transform(X_train, y_val=='functional')\n",
        "```\n",
        "\n",
        "**3.** The **[dirty_cat](https://dirty-cat.github.io/stable/)** library has a Target Encoder implementation that works with multi-class classification.\n",
        "\n",
        "```python\n",
        " dirty_cat.TargetEncoder(clf_type='multiclass-clf')\n",
        "```\n",
        "It also implements an interesting idea called [\"Similarity Encoder\" for dirty categories](https://www.slideshare.net/GaelVaroquaux/machine-learning-on-non-curated-data-154905090).\n",
        "\n",
        "However, it seems like dirty_cat doesn't handle missing values or unknown categories as well as category_encoders does. And you may need to use it with one column at a time, instead of with your whole dataframe.\n",
        "\n",
        "**4. [Embeddings](https://www.kaggle.com/learn/embeddings)** can work well with sparse / high cardinality categoricals.\n",
        "\n",
        "_**I hope it’s not too frustrating or confusing that there’s not one “canonical” way to encode categorcals. It’s an active area of research and experimentation! Maybe you can make your own contributions!**_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9eSnDYhUGD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16a4db5e-5d19-4b97-a818-ee48778a27ae"
      },
      "source": [
        "# If you're in Colab...\n",
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "    # Install required python packages:\n",
        "    # category_encoders, version >= 2.0\n",
        "    # eli5, version >= 0.9\n",
        "    # pandas-profiling, version >= 2.0\n",
        "    # plotly, version >= 4.0\n",
        "    !pip install --upgrade category_encoders eli5 pandas-profiling plotly\n",
        "    \n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module3')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.3MB/s \n",
            "\u001b[?25hCollecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cb/e773ec38d6d8b48b18537020e7782ac038581b52047d41b6500135e4bdc7/eli5-0.9.0-py2.py3-none-any.whl (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 27.0MB/s \n",
            "\u001b[?25hCollecting pandas-profiling\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/2f/aae19e2173c10a9bb7fee5f5cad35dbe53a393960fc91abc477dcc4661e8/pandas-profiling-2.3.0.tar.gz (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 46.1MB/s \n",
            "\u001b[?25hCollecting plotly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/2b/4ca10995bfbdefd65c4238f9a2d3fde33705d18dd50914dd13302ec1daf1/plotly-4.1.0-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 41.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.1.0)\n",
            "Requirement already satisfied, skipping upgrade: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: typing in /usr/local/lib/python3.6/dist-packages (from eli5) (3.7.4)\n",
            "Requirement already satisfied, skipping upgrade: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.3)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.10.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=1.4 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12 (from pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting phik>=0.9.8 (from pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ad/24a16fa4ba612fb96a3c4bb115a5b9741483f53b66d3d3afd987f20fa227/phik-0.9.8-py3-none-any.whl (606kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 34.4MB/s \n",
            "\u001b[?25hCollecting confuse>=1.0.0 (from pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.13.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling) (2.4.2)\n",
            "Requirement already satisfied, skipping upgrade: seaborn in /usr/local/lib/python3.6/dist-packages (from missingno>=0.4.2->pandas-profiling) (0.9.0)\n",
            "Collecting pytest-pylint>=0.13.0 (from phik>=0.9.8->pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/64/dc/6f35f114844fb12e38d60c4f3d2441a55baff7043ad4e013777dff55746c/pytest_pylint-0.14.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling) (5.6.0)\n",
            "Collecting pytest>=4.0.2 (from phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/1d/2430053122a3c6106f7fd1ff0bc68eb73e27db8f951db70fcd942da52c7b/pytest-5.0.1-py3-none-any.whl (221kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 42.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling) (5.3.1)\n",
            "Requirement already satisfied, skipping upgrade: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling) (0.40.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4->pandas-profiling) (41.0.1)\n",
            "Collecting pylint>=1.4.5 (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/c2/b3f73f4ac008bef6e75bca4992f3963b3f85942e0277237721ef1c151f0d/pylint-2.3.1-py3-none-any.whl (765kB)\n",
            "\u001b[K     |████████████████████████████████| 768kB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (1.4.2)\n",
            "Requirement already satisfied, skipping upgrade: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (2.1.3)\n",
            "Requirement already satisfied, skipping upgrade: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (0.19)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (19.1)\n",
            "Collecting pluggy<1.0,>=0.12 (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/06/ee/de89e0582276e3551df3110088bf20844de2b0e7df2748406876cc78e021/pluggy-0.12.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (7.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (17.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (4.5.3)\n",
            "Requirement already satisfied, skipping upgrade: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling) (0.29.0)\n",
            "Collecting mccabe<0.7,>=0.6 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting astroid<3,>=2.2.0 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/ad/7221a62a2dbce5c3b8c57fd18e1052c7331adc19b3f27f1561aa6e620db2/astroid-2.2.5-py3-none-any.whl (193kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 45.8MB/s \n",
            "\u001b[?25hCollecting isort<5,>=4.2.5 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 20.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12->pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (0.5.2)\n",
            "Collecting typed-ast>=1.3.0; implementation_name == \"cpython\" (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 39.1MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/2a/d73b99e9407be3acd7c0328fcc44bcf6f5c42e6d03d1fb192032c0057d13/lazy_object_proxy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 19.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.6/dist-packages (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling) (1.11.2)\n",
            "Building wheels for collected packages: pandas-profiling, htmlmin, confuse\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.3.0-py2.py3-none-any.whl size=145036 sha256=9ce3032df94f6609a16410720dc5e67b77682dca0bd8793bd45a9dd4a6591cfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/c7/f1/dbfef4848ebb048cb1d4a22d1ed0c62d8ff2523747235e19fe\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27085 sha256=7f2bfa338a14aa303891f9d49522e670c8f6594efa4857c90ba83d09e3f065ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.0.0-cp36-none-any.whl size=17487 sha256=9b3e916cd237f23f39ec22a8d72559f04afc3654bded009bc3afdce31f1942bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
            "Successfully built pandas-profiling htmlmin confuse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: category-encoders, eli5, htmlmin, mccabe, typed-ast, lazy-object-proxy, astroid, isort, pylint, pluggy, pytest, pytest-pylint, phik, confuse, pandas-profiling, plotly\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Found existing installation: plotly 3.6.1\n",
            "    Uninstalling plotly-3.6.1:\n",
            "      Successfully uninstalled plotly-3.6.1\n",
            "Successfully installed astroid-2.2.5 category-encoders-2.0.0 confuse-1.0.0 eli5-0.9.0 htmlmin-0.1.12 isort-4.3.21 lazy-object-proxy-1.4.1 mccabe-0.6.1 pandas-profiling-2.3.0 phik-0.9.8 plotly-4.1.0 pluggy-0.12.0 pylint-2.3.1 pytest-5.0.1 pytest-pylint-0.14.1 typed-ast-1.4.0\n",
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 42 (delta 2), reused 7 (delta 0), pack-reused 33\n",
            "Unpacking objects: 100% (42/42), done.\n",
            "From https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJBD4ruICm1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
        "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "    \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "   \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['pump_age'] = X['year_recorded'] - X['construction_year']\n",
        "    X['pump_age_MISSING'] = X['pump_age'].isnull()\n",
        "    \n",
        "#     # Turn all NaNs into feaures...\n",
        "#     nans_cols = ['funder', 'installer', 'population', 'scheme_name', 'scheme_management',\n",
        "#                 'public_meeting']\n",
        "#     for col in nans_cols:\n",
        "#         X[col] = X[col].replace(0, np.nan)\n",
        "#         X[col+'_MISSING'] = X[col].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEuTtr8Mt5Mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "\n",
        "target = 'status_group'\n",
        "\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "\n",
        "X_test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5mHzGjNFHit",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0018e811-4c12-4610-f474-783ae6e45c6d"
      },
      "source": [
        "# Again with tweak parameters\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=115, random_state=42, n_jobs=-1,\n",
        "                          )\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8138047138047138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-47zoJlKFrMr",
        "colab_type": "text"
      },
      "source": [
        "## Exploration: \n",
        "- amount_tsh\n",
        "- waterpoint_type\n",
        "- extraction_type_class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LPOFmbnMXbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.amount_tsh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyKNrr90uRuZ",
        "colab_type": "text"
      },
      "source": [
        "##  Inspecting Feature Importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfdZS5nwuJ4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wucjxI90uKy8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fc0aebb-34b2-4662-f85b-4fda11dd74c5"
      },
      "source": [
        "# Same as 222 assignment: Random Forest Classifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8135521885521886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGS_y3rdvESq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get feature importances from the middle of the pipeline above\n",
        "\n",
        "# named_steps is the trick... maybe also why Herr always breaks the whole process down...\n",
        "rf = pipeline.named_steps['randomforestclassifier']  \n",
        "\n",
        "# Not totally sure how he figured this out...\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVH7hRGgvIIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "b292ba4a-6cb7-4347-b6e3-e82e7bd78425"
      },
      "source": [
        "# Plot feature importances -- Nice visualization trick\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='purple');"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAJOCAYAAACzyR8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndQy5kiRJah1DriRJklrn/wFyupR0eEsNLQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V7RF4c9vH5G",
        "colab_type": "text"
      },
      "source": [
        "### VERY COOL!  eli5 Library to see Permutation Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCMQxbk1x6Yn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "d607e85a-da73-4a02-9665-bb00e0e4011a"
      },
      "source": [
        "# The pipeline has to be broken up here...\n",
        "\n",
        "# 1st make a pipeline just for Ordinal Encoding, and imputing NaNs\n",
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median')\n",
        ")\n",
        "\n",
        "\n",
        "# 2nd run train and val through 1st Pipeline\n",
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.transform(X_val)\n",
        "\n",
        "\n",
        "# Declare a model, and fit it to the above transformed features (normal process, but split appart)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSAuZHR1yA9a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "ed7f8a79-5a25-441a-cd34-7083d8156c04"
      },
      "source": [
        "# Looking at permutation imporance ranked in order with color-shading...\n",
        "\n",
        "# SPECIAL NOTE: we had to split appart the process to run the transformed data\n",
        "#               through BOTH the permuter and the model\n",
        "\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "# 1st  Herr-style declaring a function\n",
        "permuter = PermutationImportance(\n",
        "    model, scoring='accuracy', n_iter=2, random_state=42\n",
        ")\n",
        "\n",
        "# 2nd fitting the transformed data to the permuter\n",
        "permuter.fit(X_val_transformed, y_val)\n",
        "\n",
        "# Creating a list of feature names to match permuter list\n",
        "feature_names = X_val.columns.tolist()\n",
        "\n",
        "#eli5.show_weights?\n",
        "eli5.show_weights(\n",
        "    permuter, \n",
        "    top=None,  # show the permutation importances for all features (can declare a top n )\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1005\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0105\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                amount_tsh\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.92%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0104\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.02%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0100\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.15%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0096\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.74%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0075\n",
              "                \n",
              "                    &plusmn; 0.0019\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.89%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0070\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.09%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0064\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.08%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0035\n",
              "                \n",
              "                    &plusmn; 0.0034\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0035\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                pump_age\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.33%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0029\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                public_meeting\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                subvillage\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                payment\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0023\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                day_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0018\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.94%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0015\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                district_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0014\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.18%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ward\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                year_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wpt_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                water_quality\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                pump_age_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                permit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.42%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                funder\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.45%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                lga\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.51%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0024\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.54%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0021\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                month_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                num_private\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.70%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.91%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0008\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                installer\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0009\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quality_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 98.78%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0019\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                basin\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At03F8ZG0vcw",
        "colab_type": "text"
      },
      "source": [
        "### Chopping Data based upon feature importance..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25rQdNUR04RD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e7bc324-bac5-447a-a2de-c4af3821a0f3"
      },
      "source": [
        "# To compare relative to chopped set\n",
        "X_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47520, 45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He6nWTbP1mRA",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg0hqxzR1a4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Herr's code in case I screw it up... I don't like replacing my features and X_train, etc.\n",
        "\n",
        "\n",
        "# minimum_importance = 0\n",
        "# mask = permuter.feature_importances_ > 0\n",
        "# features = X_train.columns[mask]\n",
        "# X_train = X_train[features]\n",
        "# print('Shape after removing features:', X_train.shape)\n",
        "\n",
        "# X_val = X_val[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fjs-bb80zrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec0584fb-193b-4f0f-83cb-946e7e21e433"
      },
      "source": [
        "# Here's where we chop it...\n",
        "\n",
        "minimum_importance = 0\n",
        "mask = permuter.feature_importances_ > 0\n",
        "\n",
        "features1 = X_train.columns[mask] # find new features that meet that meet criteria\n",
        "\n",
        "X_train1 = X_train[features1]     # create a new X_train set with these features\n",
        "X_val1 = X_val[features1]         #   same for validation X set\n",
        "X_test1 = X_test[features1] \n",
        "\n",
        "# Compare shape to un-chopped\n",
        "X_train1.shape\n",
        "\n",
        "# Looks like it smaller...\n",
        " "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47520, 37)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtkXiGr72QMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7cfeb79-8891-40a5-aeb0-3996ac6fc683"
      },
      "source": [
        "# We can run the model again with the Chopped set and see how it goes...\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train1, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val1, y_val))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8135521885521886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvga0ZQ27bnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc18d59b-2941-4b26-8fc1-46345a796070"
      },
      "source": [
        "# Messing with max_features ... \n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1,\n",
        "                          max_features=20)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train1, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val1, y_val))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8091750841750842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYnRRBt8B8bU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e857a59d-db2d-444b-8ed7-d0801e6132b6"
      },
      "source": [
        "# We can run the model again with the Chopped set and see how it goes...\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=120, random_state=42, n_jobs=-1,\n",
        "                          class_weight='balanced')\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train1, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val1, y_val))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8132996632996633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UECLoEr72lQY",
        "colab_type": "text"
      },
      "source": [
        "### XGBoost gradiant boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccuR2rDo2es_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5057d616-58d5-4484-ea97-88453c834f26"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Running it on original set\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median'),\n",
        "    XGBClassifier(n_estimator=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7456228956228956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di1guqKF2yW7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b1f7a9e-1541-41fa-c1f7-0bfe8f11f621"
      },
      "source": [
        "# Running again, for fun, on the chopped set...\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median'),\n",
        "    XGBClassifier(n_estimator=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train1, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_val1)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))\n",
        "\n",
        "\n",
        "# mmmm--kay"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7427609427609427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_qFj7Vr4FqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcfb6e3e-2f2f-4a98-c4eb-4c6ed407e218"
      },
      "source": [
        "\n",
        "\n",
        "# Running it on original set again with the values found from our lecture experiment...\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median'),\n",
        "    XGBClassifier(n_estimator=150, random_state=42, learning_rate=.5,\n",
        "                  n_jobs=-1, max_depth=7)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))\n",
        "\n",
        "\n",
        "# Well, poo. "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7978956228956229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujXIS-pB7Xgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0caa5fa1-86b2-4dd1-e7b9-1c6ecd51c41a"
      },
      "source": [
        "# Running again with lower learning rate\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median'),\n",
        "    XGBClassifier(n_estimator=270, random_state=42, learning_rate=.1,\n",
        "                  n_jobs=-1, max_depth=8)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8007575757575758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te9I71Xb45np",
        "colab_type": "text"
      },
      "source": [
        "### Visualize number of n_estimators w/ Early Stoppping method\n",
        "Note: you can't do this in a pipeline... D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx0pxzlc4tGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3816202-045d-481f-bf41-593703cc35bb"
      },
      "source": [
        "# (Doesn't work with pipelines....)\n",
        "\n",
        "# Same process as before: ordinal encode X's\n",
        "encoder = ce.OrdinalEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "\n",
        "# THE NEW THING!!! Don't knwo how it works.... \n",
        "eval_set = [(X_train_encoded, y_train), \n",
        "            (X_val_encoded, y_val)]\n",
        "\n",
        "# Same as before: define the model\n",
        "model = XGBClassifier(\n",
        "    n_estimators=1000, # <= 1000 trees, way HIGH, but it should stop before then, we hope...\n",
        "    max_depth=7,\n",
        "    learning_rate=.1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Same as before, but with new parameter: early stopping_rounds...\n",
        "model.fit(X_train_encoded, y_train, early_stopping_rounds=50, \n",
        "          eval_metric='merror', eval_set=eval_set)               # again, I don't know how this works at all..."
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-merror:0.249558\tvalidation_1-merror:0.257997\n",
            "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-merror:0.250547\tvalidation_1-merror:0.260185\n",
            "[2]\tvalidation_0-merror:0.250589\tvalidation_1-merror:0.262205\n",
            "[3]\tvalidation_0-merror:0.248127\tvalidation_1-merror:0.259259\n",
            "[4]\tvalidation_0-merror:0.247117\tvalidation_1-merror:0.256145\n",
            "[5]\tvalidation_0-merror:0.243035\tvalidation_1-merror:0.252525\n",
            "[6]\tvalidation_0-merror:0.242193\tvalidation_1-merror:0.252694\n",
            "[7]\tvalidation_0-merror:0.240278\tvalidation_1-merror:0.249832\n",
            "[8]\tvalidation_0-merror:0.238173\tvalidation_1-merror:0.247222\n",
            "[9]\tvalidation_0-merror:0.23729\tvalidation_1-merror:0.246549\n",
            "[10]\tvalidation_0-merror:0.235669\tvalidation_1-merror:0.246717\n",
            "[11]\tvalidation_0-merror:0.234764\tvalidation_1-merror:0.245539\n",
            "[12]\tvalidation_0-merror:0.233838\tvalidation_1-merror:0.244865\n",
            "[13]\tvalidation_0-merror:0.233228\tvalidation_1-merror:0.244276\n",
            "[14]\tvalidation_0-merror:0.233228\tvalidation_1-merror:0.245202\n",
            "[15]\tvalidation_0-merror:0.231987\tvalidation_1-merror:0.244108\n",
            "[16]\tvalidation_0-merror:0.230324\tvalidation_1-merror:0.243519\n",
            "[17]\tvalidation_0-merror:0.229314\tvalidation_1-merror:0.243182\n",
            "[18]\tvalidation_0-merror:0.228535\tvalidation_1-merror:0.241582\n",
            "[19]\tvalidation_0-merror:0.227441\tvalidation_1-merror:0.240741\n",
            "[20]\tvalidation_0-merror:0.225568\tvalidation_1-merror:0.238973\n",
            "[21]\tvalidation_0-merror:0.224095\tvalidation_1-merror:0.2367\n",
            "[22]\tvalidation_0-merror:0.223232\tvalidation_1-merror:0.236279\n",
            "[23]\tvalidation_0-merror:0.221843\tvalidation_1-merror:0.235859\n",
            "[24]\tvalidation_0-merror:0.220518\tvalidation_1-merror:0.234848\n",
            "[25]\tvalidation_0-merror:0.219465\tvalidation_1-merror:0.233165\n",
            "[26]\tvalidation_0-merror:0.217782\tvalidation_1-merror:0.232239\n",
            "[27]\tvalidation_0-merror:0.216519\tvalidation_1-merror:0.231481\n",
            "[28]\tvalidation_0-merror:0.215299\tvalidation_1-merror:0.231229\n",
            "[29]\tvalidation_0-merror:0.21471\tvalidation_1-merror:0.231061\n",
            "[30]\tvalidation_0-merror:0.213826\tvalidation_1-merror:0.22963\n",
            "[31]\tvalidation_0-merror:0.211595\tvalidation_1-merror:0.227946\n",
            "[32]\tvalidation_0-merror:0.211048\tvalidation_1-merror:0.228367\n",
            "[33]\tvalidation_0-merror:0.208775\tvalidation_1-merror:0.227273\n",
            "[34]\tvalidation_0-merror:0.207828\tvalidation_1-merror:0.226683\n",
            "[35]\tvalidation_0-merror:0.206734\tvalidation_1-merror:0.226515\n",
            "[36]\tvalidation_0-merror:0.205829\tvalidation_1-merror:0.226347\n",
            "[37]\tvalidation_0-merror:0.204566\tvalidation_1-merror:0.225673\n",
            "[38]\tvalidation_0-merror:0.203472\tvalidation_1-merror:0.224916\n",
            "[39]\tvalidation_0-merror:0.202652\tvalidation_1-merror:0.224832\n",
            "[40]\tvalidation_0-merror:0.200589\tvalidation_1-merror:0.223401\n",
            "[41]\tvalidation_0-merror:0.199558\tvalidation_1-merror:0.222643\n",
            "[42]\tvalidation_0-merror:0.198506\tvalidation_1-merror:0.221886\n",
            "[43]\tvalidation_0-merror:0.197348\tvalidation_1-merror:0.221465\n",
            "[44]\tvalidation_0-merror:0.196149\tvalidation_1-merror:0.220286\n",
            "[45]\tvalidation_0-merror:0.194318\tvalidation_1-merror:0.219697\n",
            "[46]\tvalidation_0-merror:0.193666\tvalidation_1-merror:0.21936\n",
            "[47]\tvalidation_0-merror:0.19295\tvalidation_1-merror:0.218603\n",
            "[48]\tvalidation_0-merror:0.192572\tvalidation_1-merror:0.218182\n",
            "[49]\tvalidation_0-merror:0.191162\tvalidation_1-merror:0.217677\n",
            "[50]\tvalidation_0-merror:0.190194\tvalidation_1-merror:0.217424\n",
            "[51]\tvalidation_0-merror:0.189394\tvalidation_1-merror:0.216919\n",
            "[52]\tvalidation_0-merror:0.188952\tvalidation_1-merror:0.217088\n",
            "[53]\tvalidation_0-merror:0.188342\tvalidation_1-merror:0.216835\n",
            "[54]\tvalidation_0-merror:0.187479\tvalidation_1-merror:0.215825\n",
            "[55]\tvalidation_0-merror:0.186637\tvalidation_1-merror:0.215404\n",
            "[56]\tvalidation_0-merror:0.18609\tvalidation_1-merror:0.215152\n",
            "[57]\tvalidation_0-merror:0.185564\tvalidation_1-merror:0.214899\n",
            "[58]\tvalidation_0-merror:0.185206\tvalidation_1-merror:0.21431\n",
            "[59]\tvalidation_0-merror:0.184827\tvalidation_1-merror:0.213805\n",
            "[60]\tvalidation_0-merror:0.184301\tvalidation_1-merror:0.213552\n",
            "[61]\tvalidation_0-merror:0.183712\tvalidation_1-merror:0.2133\n",
            "[62]\tvalidation_0-merror:0.183123\tvalidation_1-merror:0.213047\n",
            "[63]\tvalidation_0-merror:0.182955\tvalidation_1-merror:0.212626\n",
            "[64]\tvalidation_0-merror:0.182197\tvalidation_1-merror:0.213215\n",
            "[65]\tvalidation_0-merror:0.181524\tvalidation_1-merror:0.212879\n",
            "[66]\tvalidation_0-merror:0.181145\tvalidation_1-merror:0.212458\n",
            "[67]\tvalidation_0-merror:0.180513\tvalidation_1-merror:0.212626\n",
            "[68]\tvalidation_0-merror:0.179861\tvalidation_1-merror:0.212458\n",
            "[69]\tvalidation_0-merror:0.179251\tvalidation_1-merror:0.211869\n",
            "[70]\tvalidation_0-merror:0.178641\tvalidation_1-merror:0.211616\n",
            "[71]\tvalidation_0-merror:0.177841\tvalidation_1-merror:0.210774\n",
            "[72]\tvalidation_0-merror:0.177525\tvalidation_1-merror:0.210943\n",
            "[73]\tvalidation_0-merror:0.177168\tvalidation_1-merror:0.210859\n",
            "[74]\tvalidation_0-merror:0.176684\tvalidation_1-merror:0.210859\n",
            "[75]\tvalidation_0-merror:0.175863\tvalidation_1-merror:0.210438\n",
            "[76]\tvalidation_0-merror:0.175484\tvalidation_1-merror:0.210269\n",
            "[77]\tvalidation_0-merror:0.175189\tvalidation_1-merror:0.210522\n",
            "[78]\tvalidation_0-merror:0.17479\tvalidation_1-merror:0.210269\n",
            "[79]\tvalidation_0-merror:0.174011\tvalidation_1-merror:0.209848\n",
            "[80]\tvalidation_0-merror:0.173316\tvalidation_1-merror:0.209596\n",
            "[81]\tvalidation_0-merror:0.173148\tvalidation_1-merror:0.20968\n",
            "[82]\tvalidation_0-merror:0.172601\tvalidation_1-merror:0.209596\n",
            "[83]\tvalidation_0-merror:0.172138\tvalidation_1-merror:0.209343\n",
            "[84]\tvalidation_0-merror:0.171864\tvalidation_1-merror:0.209343\n",
            "[85]\tvalidation_0-merror:0.171717\tvalidation_1-merror:0.209175\n",
            "[86]\tvalidation_0-merror:0.171296\tvalidation_1-merror:0.209343\n",
            "[87]\tvalidation_0-merror:0.170981\tvalidation_1-merror:0.209091\n",
            "[88]\tvalidation_0-merror:0.17016\tvalidation_1-merror:0.208754\n",
            "[89]\tvalidation_0-merror:0.169802\tvalidation_1-merror:0.208586\n",
            "[90]\tvalidation_0-merror:0.169444\tvalidation_1-merror:0.208754\n",
            "[91]\tvalidation_0-merror:0.168981\tvalidation_1-merror:0.208249\n",
            "[92]\tvalidation_0-merror:0.16875\tvalidation_1-merror:0.208165\n",
            "[93]\tvalidation_0-merror:0.168035\tvalidation_1-merror:0.208418\n",
            "[94]\tvalidation_0-merror:0.167719\tvalidation_1-merror:0.208586\n",
            "[95]\tvalidation_0-merror:0.16713\tvalidation_1-merror:0.207997\n",
            "[96]\tvalidation_0-merror:0.167045\tvalidation_1-merror:0.207997\n",
            "[97]\tvalidation_0-merror:0.166667\tvalidation_1-merror:0.207744\n",
            "[98]\tvalidation_0-merror:0.166225\tvalidation_1-merror:0.207997\n",
            "[99]\tvalidation_0-merror:0.165972\tvalidation_1-merror:0.207912\n",
            "[100]\tvalidation_0-merror:0.165762\tvalidation_1-merror:0.207744\n",
            "[101]\tvalidation_0-merror:0.165425\tvalidation_1-merror:0.207828\n",
            "[102]\tvalidation_0-merror:0.16532\tvalidation_1-merror:0.207912\n",
            "[103]\tvalidation_0-merror:0.164983\tvalidation_1-merror:0.207323\n",
            "[104]\tvalidation_0-merror:0.164562\tvalidation_1-merror:0.206481\n",
            "[105]\tvalidation_0-merror:0.164436\tvalidation_1-merror:0.206566\n",
            "[106]\tvalidation_0-merror:0.16412\tvalidation_1-merror:0.206734\n",
            "[107]\tvalidation_0-merror:0.163952\tvalidation_1-merror:0.206902\n",
            "[108]\tvalidation_0-merror:0.163552\tvalidation_1-merror:0.206987\n",
            "[109]\tvalidation_0-merror:0.163026\tvalidation_1-merror:0.206481\n",
            "[110]\tvalidation_0-merror:0.162816\tvalidation_1-merror:0.206061\n",
            "[111]\tvalidation_0-merror:0.162269\tvalidation_1-merror:0.205808\n",
            "[112]\tvalidation_0-merror:0.161785\tvalidation_1-merror:0.205219\n",
            "[113]\tvalidation_0-merror:0.161721\tvalidation_1-merror:0.204714\n",
            "[114]\tvalidation_0-merror:0.161322\tvalidation_1-merror:0.204966\n",
            "[115]\tvalidation_0-merror:0.160922\tvalidation_1-merror:0.205135\n",
            "[116]\tvalidation_0-merror:0.160396\tvalidation_1-merror:0.204882\n",
            "[117]\tvalidation_0-merror:0.160101\tvalidation_1-merror:0.204377\n",
            "[118]\tvalidation_0-merror:0.159596\tvalidation_1-merror:0.204545\n",
            "[119]\tvalidation_0-merror:0.158944\tvalidation_1-merror:0.204293\n",
            "[120]\tvalidation_0-merror:0.158502\tvalidation_1-merror:0.204125\n",
            "[121]\tvalidation_0-merror:0.158144\tvalidation_1-merror:0.204209\n",
            "[122]\tvalidation_0-merror:0.157471\tvalidation_1-merror:0.203956\n",
            "[123]\tvalidation_0-merror:0.157344\tvalidation_1-merror:0.203788\n",
            "[124]\tvalidation_0-merror:0.156944\tvalidation_1-merror:0.203535\n",
            "[125]\tvalidation_0-merror:0.156187\tvalidation_1-merror:0.203367\n",
            "[126]\tvalidation_0-merror:0.15604\tvalidation_1-merror:0.203535\n",
            "[127]\tvalidation_0-merror:0.155829\tvalidation_1-merror:0.203451\n",
            "[128]\tvalidation_0-merror:0.155471\tvalidation_1-merror:0.203367\n",
            "[129]\tvalidation_0-merror:0.155345\tvalidation_1-merror:0.20362\n",
            "[130]\tvalidation_0-merror:0.155135\tvalidation_1-merror:0.20404\n",
            "[131]\tvalidation_0-merror:0.15423\tvalidation_1-merror:0.203367\n",
            "[132]\tvalidation_0-merror:0.153683\tvalidation_1-merror:0.203451\n",
            "[133]\tvalidation_0-merror:0.153556\tvalidation_1-merror:0.203535\n",
            "[134]\tvalidation_0-merror:0.153262\tvalidation_1-merror:0.203114\n",
            "[135]\tvalidation_0-merror:0.152883\tvalidation_1-merror:0.203199\n",
            "[136]\tvalidation_0-merror:0.152441\tvalidation_1-merror:0.202778\n",
            "[137]\tvalidation_0-merror:0.152125\tvalidation_1-merror:0.202609\n",
            "[138]\tvalidation_0-merror:0.151557\tvalidation_1-merror:0.202778\n",
            "[139]\tvalidation_0-merror:0.151178\tvalidation_1-merror:0.202778\n",
            "[140]\tvalidation_0-merror:0.150926\tvalidation_1-merror:0.202778\n",
            "[141]\tvalidation_0-merror:0.150547\tvalidation_1-merror:0.202525\n",
            "[142]\tvalidation_0-merror:0.14979\tvalidation_1-merror:0.202357\n",
            "[143]\tvalidation_0-merror:0.149263\tvalidation_1-merror:0.201852\n",
            "[144]\tvalidation_0-merror:0.149242\tvalidation_1-merror:0.201936\n",
            "[145]\tvalidation_0-merror:0.148758\tvalidation_1-merror:0.201094\n",
            "[146]\tvalidation_0-merror:0.148653\tvalidation_1-merror:0.201263\n",
            "[147]\tvalidation_0-merror:0.148295\tvalidation_1-merror:0.201263\n",
            "[148]\tvalidation_0-merror:0.148064\tvalidation_1-merror:0.201431\n",
            "[149]\tvalidation_0-merror:0.147748\tvalidation_1-merror:0.201515\n",
            "[150]\tvalidation_0-merror:0.14779\tvalidation_1-merror:0.201431\n",
            "[151]\tvalidation_0-merror:0.147222\tvalidation_1-merror:0.20101\n",
            "[152]\tvalidation_0-merror:0.146864\tvalidation_1-merror:0.201431\n",
            "[153]\tvalidation_0-merror:0.146465\tvalidation_1-merror:0.201431\n",
            "[154]\tvalidation_0-merror:0.146338\tvalidation_1-merror:0.201515\n",
            "[155]\tvalidation_0-merror:0.145939\tvalidation_1-merror:0.201263\n",
            "[156]\tvalidation_0-merror:0.14577\tvalidation_1-merror:0.20101\n",
            "[157]\tvalidation_0-merror:0.145707\tvalidation_1-merror:0.200926\n",
            "[158]\tvalidation_0-merror:0.145581\tvalidation_1-merror:0.201263\n",
            "[159]\tvalidation_0-merror:0.145097\tvalidation_1-merror:0.201515\n",
            "[160]\tvalidation_0-merror:0.144444\tvalidation_1-merror:0.20101\n",
            "[161]\tvalidation_0-merror:0.144192\tvalidation_1-merror:0.20101\n",
            "[162]\tvalidation_0-merror:0.144066\tvalidation_1-merror:0.200421\n",
            "[163]\tvalidation_0-merror:0.14375\tvalidation_1-merror:0.200421\n",
            "[164]\tvalidation_0-merror:0.143098\tvalidation_1-merror:0.200168\n",
            "[165]\tvalidation_0-merror:0.142635\tvalidation_1-merror:0.200168\n",
            "[166]\tvalidation_0-merror:0.142361\tvalidation_1-merror:0.200421\n",
            "[167]\tvalidation_0-merror:0.141814\tvalidation_1-merror:0.199663\n",
            "[168]\tvalidation_0-merror:0.141582\tvalidation_1-merror:0.199411\n",
            "[169]\tvalidation_0-merror:0.14133\tvalidation_1-merror:0.198906\n",
            "[170]\tvalidation_0-merror:0.140678\tvalidation_1-merror:0.198822\n",
            "[171]\tvalidation_0-merror:0.140194\tvalidation_1-merror:0.198737\n",
            "[172]\tvalidation_0-merror:0.139815\tvalidation_1-merror:0.198737\n",
            "[173]\tvalidation_0-merror:0.139794\tvalidation_1-merror:0.199242\n",
            "[174]\tvalidation_0-merror:0.13912\tvalidation_1-merror:0.198485\n",
            "[175]\tvalidation_0-merror:0.138889\tvalidation_1-merror:0.198569\n",
            "[176]\tvalidation_0-merror:0.138152\tvalidation_1-merror:0.198148\n",
            "[177]\tvalidation_0-merror:0.1383\tvalidation_1-merror:0.198737\n",
            "[178]\tvalidation_0-merror:0.138131\tvalidation_1-merror:0.198316\n",
            "[179]\tvalidation_0-merror:0.137689\tvalidation_1-merror:0.198485\n",
            "[180]\tvalidation_0-merror:0.137226\tvalidation_1-merror:0.198232\n",
            "[181]\tvalidation_0-merror:0.136953\tvalidation_1-merror:0.198148\n",
            "[182]\tvalidation_0-merror:0.136195\tvalidation_1-merror:0.19798\n",
            "[183]\tvalidation_0-merror:0.136132\tvalidation_1-merror:0.198148\n",
            "[184]\tvalidation_0-merror:0.135922\tvalidation_1-merror:0.198401\n",
            "[185]\tvalidation_0-merror:0.135606\tvalidation_1-merror:0.198148\n",
            "[186]\tvalidation_0-merror:0.135417\tvalidation_1-merror:0.19798\n",
            "[187]\tvalidation_0-merror:0.135206\tvalidation_1-merror:0.197811\n",
            "[188]\tvalidation_0-merror:0.134785\tvalidation_1-merror:0.197643\n",
            "[189]\tvalidation_0-merror:0.134617\tvalidation_1-merror:0.197811\n",
            "[190]\tvalidation_0-merror:0.134028\tvalidation_1-merror:0.197138\n",
            "[191]\tvalidation_0-merror:0.133712\tvalidation_1-merror:0.19697\n",
            "[192]\tvalidation_0-merror:0.133165\tvalidation_1-merror:0.197138\n",
            "[193]\tvalidation_0-merror:0.132618\tvalidation_1-merror:0.196801\n",
            "[194]\tvalidation_0-merror:0.132218\tvalidation_1-merror:0.19697\n",
            "[195]\tvalidation_0-merror:0.131671\tvalidation_1-merror:0.196801\n",
            "[196]\tvalidation_0-merror:0.131334\tvalidation_1-merror:0.196549\n",
            "[197]\tvalidation_0-merror:0.131229\tvalidation_1-merror:0.196549\n",
            "[198]\tvalidation_0-merror:0.130997\tvalidation_1-merror:0.196801\n",
            "[199]\tvalidation_0-merror:0.130408\tvalidation_1-merror:0.197138\n",
            "[200]\tvalidation_0-merror:0.130324\tvalidation_1-merror:0.196296\n",
            "[201]\tvalidation_0-merror:0.130156\tvalidation_1-merror:0.196465\n",
            "[202]\tvalidation_0-merror:0.129882\tvalidation_1-merror:0.196465\n",
            "[203]\tvalidation_0-merror:0.129482\tvalidation_1-merror:0.19537\n",
            "[204]\tvalidation_0-merror:0.129356\tvalidation_1-merror:0.19537\n",
            "[205]\tvalidation_0-merror:0.129272\tvalidation_1-merror:0.194865\n",
            "[206]\tvalidation_0-merror:0.128998\tvalidation_1-merror:0.194865\n",
            "[207]\tvalidation_0-merror:0.128725\tvalidation_1-merror:0.195118\n",
            "[208]\tvalidation_0-merror:0.128641\tvalidation_1-merror:0.195034\n",
            "[209]\tvalidation_0-merror:0.128409\tvalidation_1-merror:0.195034\n",
            "[210]\tvalidation_0-merror:0.12822\tvalidation_1-merror:0.194781\n",
            "[211]\tvalidation_0-merror:0.127799\tvalidation_1-merror:0.194781\n",
            "[212]\tvalidation_0-merror:0.127546\tvalidation_1-merror:0.194781\n",
            "[213]\tvalidation_0-merror:0.127146\tvalidation_1-merror:0.194865\n",
            "[214]\tvalidation_0-merror:0.126936\tvalidation_1-merror:0.194949\n",
            "[215]\tvalidation_0-merror:0.126662\tvalidation_1-merror:0.194613\n",
            "[216]\tvalidation_0-merror:0.126178\tvalidation_1-merror:0.193771\n",
            "[217]\tvalidation_0-merror:0.125947\tvalidation_1-merror:0.193519\n",
            "[218]\tvalidation_0-merror:0.125694\tvalidation_1-merror:0.193434\n",
            "[219]\tvalidation_0-merror:0.125673\tvalidation_1-merror:0.193687\n",
            "[220]\tvalidation_0-merror:0.125337\tvalidation_1-merror:0.193771\n",
            "[221]\tvalidation_0-merror:0.125337\tvalidation_1-merror:0.194024\n",
            "[222]\tvalidation_0-merror:0.124958\tvalidation_1-merror:0.19436\n",
            "[223]\tvalidation_0-merror:0.124769\tvalidation_1-merror:0.194444\n",
            "[224]\tvalidation_0-merror:0.12439\tvalidation_1-merror:0.194529\n",
            "[225]\tvalidation_0-merror:0.124179\tvalidation_1-merror:0.194192\n",
            "[226]\tvalidation_0-merror:0.124032\tvalidation_1-merror:0.194192\n",
            "[227]\tvalidation_0-merror:0.123779\tvalidation_1-merror:0.193939\n",
            "[228]\tvalidation_0-merror:0.123653\tvalidation_1-merror:0.193939\n",
            "[229]\tvalidation_0-merror:0.123232\tvalidation_1-merror:0.193687\n",
            "[230]\tvalidation_0-merror:0.123127\tvalidation_1-merror:0.193603\n",
            "[231]\tvalidation_0-merror:0.122959\tvalidation_1-merror:0.193266\n",
            "[232]\tvalidation_0-merror:0.122685\tvalidation_1-merror:0.193013\n",
            "[233]\tvalidation_0-merror:0.122664\tvalidation_1-merror:0.19335\n",
            "[234]\tvalidation_0-merror:0.122454\tvalidation_1-merror:0.193266\n",
            "[235]\tvalidation_0-merror:0.122159\tvalidation_1-merror:0.193519\n",
            "[236]\tvalidation_0-merror:0.122117\tvalidation_1-merror:0.19335\n",
            "[237]\tvalidation_0-merror:0.121991\tvalidation_1-merror:0.193519\n",
            "[238]\tvalidation_0-merror:0.121759\tvalidation_1-merror:0.193519\n",
            "[239]\tvalidation_0-merror:0.12157\tvalidation_1-merror:0.193182\n",
            "[240]\tvalidation_0-merror:0.121212\tvalidation_1-merror:0.193013\n",
            "[241]\tvalidation_0-merror:0.120791\tvalidation_1-merror:0.192929\n",
            "[242]\tvalidation_0-merror:0.12056\tvalidation_1-merror:0.192845\n",
            "[243]\tvalidation_0-merror:0.120265\tvalidation_1-merror:0.192929\n",
            "[244]\tvalidation_0-merror:0.120097\tvalidation_1-merror:0.193013\n",
            "[245]\tvalidation_0-merror:0.119802\tvalidation_1-merror:0.193013\n",
            "[246]\tvalidation_0-merror:0.119529\tvalidation_1-merror:0.192845\n",
            "[247]\tvalidation_0-merror:0.119381\tvalidation_1-merror:0.192845\n",
            "[248]\tvalidation_0-merror:0.119129\tvalidation_1-merror:0.192929\n",
            "[249]\tvalidation_0-merror:0.118645\tvalidation_1-merror:0.192593\n",
            "[250]\tvalidation_0-merror:0.118392\tvalidation_1-merror:0.192508\n",
            "[251]\tvalidation_0-merror:0.118287\tvalidation_1-merror:0.192677\n",
            "[252]\tvalidation_0-merror:0.118098\tvalidation_1-merror:0.192761\n",
            "[253]\tvalidation_0-merror:0.117908\tvalidation_1-merror:0.192761\n",
            "[254]\tvalidation_0-merror:0.117761\tvalidation_1-merror:0.193013\n",
            "[255]\tvalidation_0-merror:0.117298\tvalidation_1-merror:0.192929\n",
            "[256]\tvalidation_0-merror:0.117235\tvalidation_1-merror:0.193098\n",
            "[257]\tvalidation_0-merror:0.117109\tvalidation_1-merror:0.193182\n",
            "[258]\tvalidation_0-merror:0.116688\tvalidation_1-merror:0.193266\n",
            "[259]\tvalidation_0-merror:0.116561\tvalidation_1-merror:0.193182\n",
            "[260]\tvalidation_0-merror:0.116456\tvalidation_1-merror:0.193098\n",
            "[261]\tvalidation_0-merror:0.116288\tvalidation_1-merror:0.192845\n",
            "[262]\tvalidation_0-merror:0.116098\tvalidation_1-merror:0.192929\n",
            "[263]\tvalidation_0-merror:0.115804\tvalidation_1-merror:0.192677\n",
            "[264]\tvalidation_0-merror:0.115341\tvalidation_1-merror:0.192593\n",
            "[265]\tvalidation_0-merror:0.115109\tvalidation_1-merror:0.192424\n",
            "[266]\tvalidation_0-merror:0.114752\tvalidation_1-merror:0.19234\n",
            "[267]\tvalidation_0-merror:0.114394\tvalidation_1-merror:0.19234\n",
            "[268]\tvalidation_0-merror:0.114247\tvalidation_1-merror:0.191835\n",
            "[269]\tvalidation_0-merror:0.114205\tvalidation_1-merror:0.192003\n",
            "[270]\tvalidation_0-merror:0.114057\tvalidation_1-merror:0.191835\n",
            "[271]\tvalidation_0-merror:0.113847\tvalidation_1-merror:0.192172\n",
            "[272]\tvalidation_0-merror:0.113636\tvalidation_1-merror:0.192256\n",
            "[273]\tvalidation_0-merror:0.113405\tvalidation_1-merror:0.192593\n",
            "[274]\tvalidation_0-merror:0.1133\tvalidation_1-merror:0.192845\n",
            "[275]\tvalidation_0-merror:0.112921\tvalidation_1-merror:0.192929\n",
            "[276]\tvalidation_0-merror:0.11271\tvalidation_1-merror:0.193182\n",
            "[277]\tvalidation_0-merror:0.1125\tvalidation_1-merror:0.193266\n",
            "[278]\tvalidation_0-merror:0.112416\tvalidation_1-merror:0.19335\n",
            "[279]\tvalidation_0-merror:0.112205\tvalidation_1-merror:0.193098\n",
            "[280]\tvalidation_0-merror:0.112079\tvalidation_1-merror:0.19335\n",
            "[281]\tvalidation_0-merror:0.111827\tvalidation_1-merror:0.193434\n",
            "[282]\tvalidation_0-merror:0.111679\tvalidation_1-merror:0.193687\n",
            "[283]\tvalidation_0-merror:0.11149\tvalidation_1-merror:0.193098\n",
            "[284]\tvalidation_0-merror:0.111279\tvalidation_1-merror:0.193013\n",
            "[285]\tvalidation_0-merror:0.110795\tvalidation_1-merror:0.192761\n",
            "[286]\tvalidation_0-merror:0.11048\tvalidation_1-merror:0.192761\n",
            "[287]\tvalidation_0-merror:0.110311\tvalidation_1-merror:0.193013\n",
            "[288]\tvalidation_0-merror:0.110227\tvalidation_1-merror:0.193519\n",
            "[289]\tvalidation_0-merror:0.110185\tvalidation_1-merror:0.19335\n",
            "[290]\tvalidation_0-merror:0.109891\tvalidation_1-merror:0.193182\n",
            "[291]\tvalidation_0-merror:0.109806\tvalidation_1-merror:0.193013\n",
            "[292]\tvalidation_0-merror:0.109785\tvalidation_1-merror:0.192845\n",
            "[293]\tvalidation_0-merror:0.109722\tvalidation_1-merror:0.192845\n",
            "[294]\tvalidation_0-merror:0.109554\tvalidation_1-merror:0.192761\n",
            "[295]\tvalidation_0-merror:0.109175\tvalidation_1-merror:0.192761\n",
            "[296]\tvalidation_0-merror:0.109049\tvalidation_1-merror:0.193013\n",
            "[297]\tvalidation_0-merror:0.108817\tvalidation_1-merror:0.193182\n",
            "[298]\tvalidation_0-merror:0.10867\tvalidation_1-merror:0.193266\n",
            "[299]\tvalidation_0-merror:0.108586\tvalidation_1-merror:0.192929\n",
            "[300]\tvalidation_0-merror:0.108523\tvalidation_1-merror:0.192929\n",
            "[301]\tvalidation_0-merror:0.108249\tvalidation_1-merror:0.192845\n",
            "[302]\tvalidation_0-merror:0.108102\tvalidation_1-merror:0.192845\n",
            "[303]\tvalidation_0-merror:0.107955\tvalidation_1-merror:0.192845\n",
            "[304]\tvalidation_0-merror:0.107849\tvalidation_1-merror:0.192677\n",
            "[305]\tvalidation_0-merror:0.107786\tvalidation_1-merror:0.192677\n",
            "[306]\tvalidation_0-merror:0.107218\tvalidation_1-merror:0.192593\n",
            "[307]\tvalidation_0-merror:0.107113\tvalidation_1-merror:0.192677\n",
            "[308]\tvalidation_0-merror:0.106671\tvalidation_1-merror:0.192508\n",
            "[309]\tvalidation_0-merror:0.106545\tvalidation_1-merror:0.192424\n",
            "[310]\tvalidation_0-merror:0.106229\tvalidation_1-merror:0.192677\n",
            "[311]\tvalidation_0-merror:0.105997\tvalidation_1-merror:0.192677\n",
            "[312]\tvalidation_0-merror:0.105997\tvalidation_1-merror:0.192929\n",
            "[313]\tvalidation_0-merror:0.105829\tvalidation_1-merror:0.193013\n",
            "[314]\tvalidation_0-merror:0.105387\tvalidation_1-merror:0.192929\n",
            "[315]\tvalidation_0-merror:0.10524\tvalidation_1-merror:0.193098\n",
            "[316]\tvalidation_0-merror:0.104903\tvalidation_1-merror:0.192845\n",
            "[317]\tvalidation_0-merror:0.104566\tvalidation_1-merror:0.193098\n",
            "[318]\tvalidation_0-merror:0.104377\tvalidation_1-merror:0.192845\n",
            "Stopping. Best iteration:\n",
            "[268]\tvalidation_0-merror:0.114247\tvalidation_1-merror:0.191835\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=-1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8A5mDj26tU3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "d42170ae-4ca1-4d9c-ddb7-abfb06b1e0e4"
      },
      "source": [
        "# Plot the results of the above trickery\n",
        "\n",
        "results = model.evals_result()\n",
        "train_error = results['validation_0']['merror']\n",
        "val_error = results['validation_1']['merror']\n",
        "epoch = range(1, len(train_error)+1)\n",
        "plt.plot(epoch, train_error, label='Train')\n",
        "plt.plot(epoch, val_error, label='Validation')\n",
        "plt.xlabel('Model Complexity (n_estimators)')\n",
        "plt.legend()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8d31fa2048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAELCAYAAAA1AlaNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY1DBkQ1RswAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PIuGnO4G0qq",
        "colab_type": "text"
      },
      "source": [
        "## Submitting to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xYJtYrwG4b0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WAIT!!! This is the last step...\n",
        "\n",
        "# Predict on test\n",
        "y_pred = pipeline.predict(X_test1)\n",
        "\n",
        "\n",
        "# Write submission csv file\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "submission.to_csv('curry_submit_7.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ1WzjBCG6BX",
        "colab_type": "code",
        "outputId": "10a4e854-f106-47b3-a259-a44bb1641f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "!head curry_submit_7.csv"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id,status_group\n",
            "50785,non functional\n",
            "51630,functional\n",
            "17168,functional\n",
            "45559,non functional\n",
            "49871,functional\n",
            "52449,functional\n",
            "24806,non functional\n",
            "28965,non functional\n",
            "36301,non functional\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6z-idyjG8dY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if in_colab:\n",
        "    from google.colab import files\n",
        "    # Just try again if you get this error:\n",
        "    # TypeError: Failed to fetch\n",
        "    # https://github.com/googlecolab/colabtools/issues/337\n",
        "    files.download('curry_submit_7.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}