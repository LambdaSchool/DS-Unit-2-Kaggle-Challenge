{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IXUfiQ2UKj6"
   },
   "source": [
    "Lambda School Data Science, Unit 2: Predictive Modeling\n",
    "\n",
    "# Kaggle Challenge, Module 3\n",
    "\n",
    "## Assignment\n",
    "- [ ] [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2/portfolio-project/ds6), then choose your dataset, and [submit this form](https://forms.gle/nyWURUg65x1UTRNV9), due today at 4pm Pacific.\n",
    "- [ ] Continue to participate in our Kaggle challenge.\n",
    "- [ ] Try xgboost.\n",
    "- [ ] Get your model's permutation importances.\n",
    "- [ ] Try feature selection with permutation importances.\n",
    "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
    "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
    "\n",
    "## Stretch Goals\n",
    "\n",
    "### Doing\n",
    "- [ ] Add your own stretch goal(s) !\n",
    "- [ ] Do more exploratory data analysis, data cleaning, feature engineering, and feature selection.\n",
    "- [ ] Try other categorical encodings.\n",
    "- [ ] Try other Python libraries for gradient boosting.\n",
    "- [ ] Look at the bonus notebook in the repo, about monotonic constraints with gradient boosting.\n",
    "- [ ] Make visualizations and share on Slack.\n",
    "\n",
    "### Reading\n",
    "\n",
    "Top recommendations in _**bold italic:**_\n",
    "\n",
    "#### Permutation Importances\n",
    "- _**[Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)**_\n",
    "- [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
    "\n",
    "#### (Default) Feature Importances\n",
    "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    "#### Gradient Boosting\n",
    "  - [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
    "  - _**[A Kaggle Master Explains Gradient Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)**_\n",
    "  - [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8\n",
    "  - [Gradient Boosting Explained](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)\n",
    "  - _**[Boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw) (2.5 minute video)**_\n",
    "\n",
    "#### Categorical encoding for trees\n",
    "- [Are categorical variables getting lost in your random forests?](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)\n",
    "- [Beyond One-Hot: An Exploration of Categorical Variables](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/)\n",
    "- _**[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)**_\n",
    "- _**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)**_\n",
    "- [Mean (likelihood) encodings: a comprehensive study](https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study)\n",
    "- [The Mechanics of Machine Learning, Chapter 6: Categorically Speaking](https://mlbook.explained.ai/catvars.html)\n",
    "\n",
    "#### Imposter Syndrome\n",
    "- [Effort Shock and Reward Shock (How The Karate Kid Ruined The Modern World)](http://www.tempobook.com/2014/07/09/effort-shock-and-reward-shock/)\n",
    "- [How to manage impostor syndrome in data science](https://towardsdatascience.com/how-to-manage-impostor-syndrome-in-data-science-ad814809f068)\n",
    "- [\"I am not a real data scientist\"](https://brohrer.github.io/imposter_syndrome.html)\n",
    "- _**[Imposter Syndrome in Data Science](https://caitlinhudon.com/2018/01/19/imposter-syndrome-in-data-science/)**_\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wd6T-m6bneLS"
   },
   "source": [
    "### Python libraries for Gradient Boosting\n",
    "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
    "  - Anaconda: already installed\n",
    "  - Google Colab: already installed\n",
    "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
    "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
    "  - Windows: `conda install -c anaconda py-xgboost`\n",
    "  - Google Colab: already installed\n",
    "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
    "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
    "  - Google Colab: already installed\n",
    "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
    "  - Anaconda: `conda install -c conda-forge catboost`\n",
    "  - Google Colab: `pip install catboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1nF5eU9nJwL"
   },
   "source": [
    "### Categorical Encodings\n",
    "\n",
    "**1.** The article **[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)** mentions 4 encodings:\n",
    "\n",
    "- **\"Categorical Encoding\":** This means using the raw categorical values as-is, not encoded. Scikit-learn doesn't support this, but some tree algorithm implementations do. For example, [Catboost](https://catboost.ai/), or R's [rpart](https://cran.r-project.org/web/packages/rpart/index.html) package.\n",
    "- **Numeric Encoding:** Synonymous with Label Encoding, or \"Ordinal\" Encoding with random order. We can use [category_encoders.OrdinalEncoder](https://contrib.scikit-learn.org/categorical-encoding/ordinal.html).\n",
    "- **One-Hot Encoding:** We can use [category_encoders.OneHotEncoder](http://contrib.scikit-learn.org/categorical-encoding/onehot.html).\n",
    "- **Binary Encoding:** We can use [category_encoders.BinaryEncoder](http://contrib.scikit-learn.org/categorical-encoding/binary.html).\n",
    "\n",
    "\n",
    "**2.** The short video \n",
    "**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)** introduces an interesting idea: use both X _and_ y to encode categoricals.\n",
    "\n",
    "Category Encoders has multiple implementations of this general concept:\n",
    "\n",
    "- [CatBoost Encoder](http://contrib.scikit-learn.org/categorical-encoding/catboost.html)\n",
    "- [James-Stein Encoder](http://contrib.scikit-learn.org/categorical-encoding/jamesstein.html)\n",
    "- [Leave One Out](http://contrib.scikit-learn.org/categorical-encoding/leaveoneout.html)\n",
    "- [M-estimate](http://contrib.scikit-learn.org/categorical-encoding/mestimate.html)\n",
    "- [Target Encoder](http://contrib.scikit-learn.org/categorical-encoding/targetencoder.html)\n",
    "- [Weight of Evidence](http://contrib.scikit-learn.org/categorical-encoding/woe.html)\n",
    "\n",
    "Category Encoder's mean encoding implementations work for regression problems or binary classification problems. \n",
    "\n",
    "For multi-class classification problems, you will need to temporarily reformulate it as binary classification. For example:\n",
    "\n",
    "```python\n",
    "encoder = ce.TargetEncoder(min_samples_leaf=..., smoothing=...) # Both parameters > 1 to avoid overfitting\n",
    "X_train_encoded = encoder.fit_transform(X_train, y_train=='functional')\n",
    "X_val_encoded = encoder.transform(X_train, y_val=='functional')\n",
    "```\n",
    "\n",
    "**3.** The **[dirty_cat](https://dirty-cat.github.io/stable/)** library has a Target Encoder implementation that works with multi-class classification.\n",
    "\n",
    "```python\n",
    " dirty_cat.TargetEncoder(clf_type='multiclass-clf')\n",
    "```\n",
    "It also implements an interesting idea called [\"Similarity Encoder\" for dirty categories](https://www.slideshare.net/GaelVaroquaux/machine-learning-on-non-curated-data-154905090).\n",
    "\n",
    "However, it seems like dirty_cat doesn't handle missing values or unknown categories as well as category_encoders does. And you may need to use it with one column at a time, instead of with your whole dataframe.\n",
    "\n",
    "**4. [Embeddings](https://www.kaggle.com/learn/embeddings)** can work well with sparse / high cardinality categoricals.\n",
    "\n",
    "_**I hope it’s not too frustrating or confusing that there’s not one “canonical” way to encode categorcals. It’s an active area of research and experimentation! Maybe you can make your own contributions!**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9eSnDYhUGD7"
   },
   "outputs": [],
   "source": [
    "# If you're in Colab...\n",
    "import os, sys\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "\n",
    "if in_colab:\n",
    "    # Install required python packages:\n",
    "    # category_encoders, version >= 2.0\n",
    "    # eli5, version >= 0.9\n",
    "    # pandas-profiling, version >= 2.0\n",
    "    # plotly, version >= 4.0\n",
    "    !pip install --upgrade category_encoders eli5 pandas-profiling plotly\n",
    "    \n",
    "    # Pull files from Github repo\n",
    "    os.chdir('/content')\n",
    "    !git init .\n",
    "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge.git\n",
    "    !git pull origin master\n",
    "    \n",
    "    # Change into directory for module\n",
    "    os.chdir('module3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJBD4ruICm1m"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Merge train_features.csv & train_labels.csv\n",
    "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
    "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
    "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUp(data):\n",
    "    #I don't want setting with copy errors\n",
    "    #data=data[allcats].copy()\n",
    "    data=data.copy()\n",
    "    #get rid of the bad faux 0s \n",
    "    data['latitude']=data['latitude'].replace(-2e-08, 0)\n",
    "    #Replace fake 0's with NaNs for accuracy  \n",
    "    \n",
    "    zeros=['latitude','longitude', 'num_private', 'construction_year','population','amount_tsh']\n",
    "    for col in zeros:\n",
    "        data[col]=data[col].replace(0,np.nan)\n",
    "\n",
    "    # there are some numbers which should be treated as strings\n",
    "    numStrings=['region_code','district_code']\n",
    "    for col in numStrings:\n",
    "        data[col]=data[col].astype(str)\n",
    "    #Theres a date string\n",
    "    data['date_recorded']=pd.to_datetime(data['date_recorded'], infer_datetime_format=True)\n",
    "    data['age']=data['date_recorded'].apply(lambda x: x.year)-data['construction_year']\n",
    "    #convert the date into readable numbers for the regressor\n",
    "    data['recorded_year']=data['date_recorded'].dt.year\n",
    "    data['recorded_month']=data['date_recorded'].dt.month\n",
    "    data['recorded_day']=data['date_recorded'].dt.day\n",
    "    #the GPS values that are 0 where the age is null are also errors and should be nan's \n",
    "    def gpsHeight(cols):\n",
    "        age=cols[0]\n",
    "        height=cols[1]\n",
    "        if pd.isnull(age):\n",
    "            if height==0:\n",
    "                return np.NaN\n",
    "        else:\n",
    "            return height\n",
    "    data['gps_height']=data[['construction_year','gps_height']].apply(gpsHeight,axis=1)\n",
    "    #handle duplicate columns,and ID is random, date recorded can't be processed\n",
    "    data = data.drop(['quantity_group','id','date_recorded','recorded_by'],axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=cleanUp(train)\n",
    "test=cleanUp(test)\n",
    "y=train['status_group']\n",
    "train=train.drop('status_group',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=make_pipeline(\n",
    "    encoder,\n",
    "    SimpleImputer(),\n",
    "    StandardScaler(),\n",
    "    SelectKBest(),\n",
    "    RandomForestClassifier(n_jobs=-1,n_estimators=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80373737, 0.80570707, 0.80267677])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline, train, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distro={\n",
    "    'simpleimputer__strategy':['mean','median'],\n",
    "    'randomforestclassifier__n_estimators':range(1,200),\n",
    "    'randomforestclassifier__bootstrap':['True','False'],\n",
    "    'randomforestclassifier__max_depth':range(1,50),\n",
    "    'randomforestclassifier__max_features':['auto','log2'],\n",
    "    'selectkbest__k':range(1,220),\n",
    "}\n",
    "\n",
    "search=RandomizedSearchCV(pipeline, param_distributions=param_distro, n_iter=100, cv=3, verbose=20, return_train_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:   58.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed:  6.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 190 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 191 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 195 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 203 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 211 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 219 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 221 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 227 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 231 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 235 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 239 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 243 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 245 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 246 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 247 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 251 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 253 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 254 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 255 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 259 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 260 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 262 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 263 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed: 12.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 265 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 266 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 267 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 269 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 270 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 271 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 273 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 274 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 275 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 277 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 279 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 282 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 283 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 285 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 286 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 287 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 14.1min finished\n",
      "/Users/eyvonnegeordan/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [  3   7  11  17  23  30  37  45  53  61  69  77  86  96 107 121 134 148\n",
      " 167 188 210] are constant.\n",
      "  UserWarning)\n",
      "/Users/eyvonnegeordan/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('columntransformer',\n",
       "                                              ColumnTransformer(n_jobs=None,\n",
       "                                                                remainder='drop',\n",
       "                                                                sparse_threshold=0.3,\n",
       "                                                                transformer_weights=None,\n",
       "                                                                transformers=[('onehotencoder',\n",
       "                                                                               OneHotEncoder(cols=None,\n",
       "                                                                                             drop_invariant=False,\n",
       "                                                                                             handle_unknown='impute',\n",
       "                                                                                             impute_missing=True,\n",
       "                                                                                             return_df=True,\n",
       "                                                                                             use_cat...\n",
       "                   param_distributions={'randomforestclassifier__bootstrap': ['True',\n",
       "                                                                              'False'],\n",
       "                                        'randomforestclassifier__max_depth': range(1, 50),\n",
       "                                        'randomforestclassifier__max_features': ['auto',\n",
       "                                                                                 'log2'],\n",
       "                                        'randomforestclassifier__n_estimators': range(1, 200),\n",
       "                                        'selectkbest__k': range(1, 220),\n",
       "                                        'simpleimputer__strategy': ['mean',\n",
       "                                                                    'median']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True, scoring=None, verbose=20)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simpleimputer__strategy': 'median',\n",
       " 'selectkbest__k': 146,\n",
       " 'randomforestclassifier__n_estimators': 110,\n",
       " 'randomforestclassifier__max_features': 'auto',\n",
       " 'randomforestclassifier__max_depth': 19,\n",
       " 'randomforestclassifier__bootstrap': 'False'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7922053872053872"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=train.describe(exclude='number').T.sort_values('unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eyvonnegeordan/anaconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:751: DeprecationWarning: `make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\n",
      "  warnings.warn(message, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   1,    0,    0, ...,    0,    1,    1],\n",
       "       [   0,    1,    0, ...,    0,    2,    2],\n",
       "       [   0,    0,    1, ...,    0,    3,    3],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,   26,  450],\n",
       "       [   0,    1,    0, ...,    0,  640, 1331],\n",
       "       [   0,    0,    0, ...,    0,   69,  859]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is a thing I found on the internet, it lets some of the things be done onehot \n",
    "#and some ordinal\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "preprocess= make_column_transformer(\n",
    "    (['payment','water_quality'], ce.OneHotEncoder()),\n",
    "    (['funder','ward'],ce.OrdinalEncoder())\n",
    ")\n",
    "preprocess.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>permit</th>\n",
       "      <td>56344</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>38852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_meeting</th>\n",
       "      <td>56066</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>51011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_class</th>\n",
       "      <td>59400</td>\n",
       "      <td>3</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>45794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management_group</th>\n",
       "      <td>59400</td>\n",
       "      <td>5</td>\n",
       "      <td>user-group</td>\n",
       "      <td>52490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity</th>\n",
       "      <td>59400</td>\n",
       "      <td>5</td>\n",
       "      <td>enough</td>\n",
       "      <td>33186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <td>59400</td>\n",
       "      <td>6</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>34625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_group</th>\n",
       "      <td>59400</td>\n",
       "      <td>6</td>\n",
       "      <td>good</td>\n",
       "      <td>50818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type</th>\n",
       "      <td>59400</td>\n",
       "      <td>7</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>28522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment</th>\n",
       "      <td>59400</td>\n",
       "      <td>7</td>\n",
       "      <td>never pay</td>\n",
       "      <td>25348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>59400</td>\n",
       "      <td>7</td>\n",
       "      <td>never pay</td>\n",
       "      <td>25348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_type</th>\n",
       "      <td>59400</td>\n",
       "      <td>7</td>\n",
       "      <td>spring</td>\n",
       "      <td>17021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_class</th>\n",
       "      <td>59400</td>\n",
       "      <td>7</td>\n",
       "      <td>gravity</td>\n",
       "      <td>26780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_quality</th>\n",
       "      <td>59400</td>\n",
       "      <td>8</td>\n",
       "      <td>soft</td>\n",
       "      <td>50818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basin</th>\n",
       "      <td>59400</td>\n",
       "      <td>9</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>10248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>59400</td>\n",
       "      <td>10</td>\n",
       "      <td>spring</td>\n",
       "      <td>17021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scheme_management</th>\n",
       "      <td>55523</td>\n",
       "      <td>12</td>\n",
       "      <td>VWC</td>\n",
       "      <td>36793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>59400</td>\n",
       "      <td>12</td>\n",
       "      <td>vwc</td>\n",
       "      <td>40507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_group</th>\n",
       "      <td>59400</td>\n",
       "      <td>13</td>\n",
       "      <td>gravity</td>\n",
       "      <td>26780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type</th>\n",
       "      <td>59400</td>\n",
       "      <td>18</td>\n",
       "      <td>gravity</td>\n",
       "      <td>26780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_code</th>\n",
       "      <td>59400</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>12203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>59400</td>\n",
       "      <td>21</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>5294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_code</th>\n",
       "      <td>59400</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lga</th>\n",
       "      <td>59400</td>\n",
       "      <td>125</td>\n",
       "      <td>Njombe</td>\n",
       "      <td>2503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funder</th>\n",
       "      <td>55765</td>\n",
       "      <td>1897</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>9084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ward</th>\n",
       "      <td>59400</td>\n",
       "      <td>2092</td>\n",
       "      <td>Igosi</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer</th>\n",
       "      <td>55745</td>\n",
       "      <td>2145</td>\n",
       "      <td>DWE</td>\n",
       "      <td>17402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scheme_name</th>\n",
       "      <td>31234</td>\n",
       "      <td>2696</td>\n",
       "      <td>K</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subvillage</th>\n",
       "      <td>59029</td>\n",
       "      <td>19287</td>\n",
       "      <td>Madukani</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wpt_name</th>\n",
       "      <td>59400</td>\n",
       "      <td>37400</td>\n",
       "      <td>none</td>\n",
       "      <td>3563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count unique                     top   freq\n",
       "permit                 56344      2                    True  38852\n",
       "public_meeting         56066      2                    True  51011\n",
       "source_class           59400      3             groundwater  45794\n",
       "management_group       59400      5              user-group  52490\n",
       "quantity               59400      5                  enough  33186\n",
       "waterpoint_type_group  59400      6      communal standpipe  34625\n",
       "quality_group          59400      6                    good  50818\n",
       "waterpoint_type        59400      7      communal standpipe  28522\n",
       "payment                59400      7               never pay  25348\n",
       "payment_type           59400      7               never pay  25348\n",
       "source_type            59400      7                  spring  17021\n",
       "extraction_type_class  59400      7                 gravity  26780\n",
       "water_quality          59400      8                    soft  50818\n",
       "basin                  59400      9           Lake Victoria  10248\n",
       "source                 59400     10                  spring  17021\n",
       "scheme_management      55523     12                     VWC  36793\n",
       "management             59400     12                     vwc  40507\n",
       "extraction_type_group  59400     13                 gravity  26780\n",
       "extraction_type        59400     18                 gravity  26780\n",
       "district_code          59400     20                       1  12203\n",
       "region                 59400     21                  Iringa   5294\n",
       "region_code            59400     27                      11   5300\n",
       "lga                    59400    125                  Njombe   2503\n",
       "funder                 55765   1897  Government Of Tanzania   9084\n",
       "ward                   59400   2092                   Igosi    307\n",
       "installer              55745   2145                     DWE  17402\n",
       "scheme_name            31234   2696                       K    682\n",
       "subvillage             59029  19287                Madukani    508\n",
       "wpt_name               59400  37400                    none   3563"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohecats=desc[desc['unique']<22].index.tolist()\n",
    "ordcats=desc[desc['unique']>22].index.tolist()\n",
    "\n",
    "desc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,     0,     0, ...,     1,     1,     1],\n",
       "       [    0,     1,     0, ...,     2,     2,     2],\n",
       "       [    0,     1,     0, ...,     3,     3,     3],\n",
       "       ...,\n",
       "       [    1,     0,     0, ...,     2, 15309,    88],\n",
       "       [    0,     1,     0, ...,     2,   453, 37399],\n",
       "       [    0,     1,     0, ...,     2, 19288, 37400]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder=make_column_transformer(\n",
    "    (ce.OneHotEncoder(), ohecats),\n",
    "    (ce.OrdinalEncoder(), ordcats)\n",
    ")\n",
    "encoder.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eyvonnegeordan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(cols=None,\n",
       "                                                                drop_invariant=False,\n",
       "                                                                handle_unknown='impute',\n",
       "                                                                impute_missing=True,\n",
       "                                                                return_df=True,\n",
       "                                                                use_cat_names=False,\n",
       "                                                                verbose=0),\n",
       "                                                  ['permit', 'public_meeting',\n",
       "                                                   'source_class',...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline=make_pipeline(\n",
    "    encoder,\n",
    "    SimpleImputer(),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "pipeline.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 219)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.named_steps['columntransformer'].transform(train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_kaggle_challenge_3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
