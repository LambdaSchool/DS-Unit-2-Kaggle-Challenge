{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge train_features.csv & train_labels.csv\n",
    "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
    "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 41), (14358, 40))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wrangle(X):\n",
    "      \n",
    "    # Prevent errors with propogation of changes to master matrix\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Treat near zero as zero\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values.\n",
    "    # So we will replace the zeros with nulls, and impute missing values later.\n",
    "    # Also create a \"missing indicator\" column, because the fact that\n",
    "    # values are missing may be a predictive signal.\n",
    "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
    "                       'gps_height', 'population']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        X[col+'_MISSING'] = X[col].isnull()\n",
    "            \n",
    "    # Drop duplicate columns\n",
    "    duplicates = ['quantity_group', 'payment_type']\n",
    "    X = X.drop(columns=duplicates)\n",
    "    \n",
    "    # Drop unusable features\n",
    "    unusable_variance = ['recorded_by', 'id']\n",
    "    X = X.drop(columns=unusable_variance)\n",
    "    \n",
    "#     # Convert date_recorded to datetime\n",
    "#     X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "# #     Extract components from date_recorded, then drop the original column\n",
    "#     X['year_recorded'] = X['date_recorded'].dt.year\n",
    "#     X['month_recorded'] = X['date_recorded'].dt.month\n",
    "#     X['day_recorded'] = X['date_recorded'].dt.day\n",
    "#     X = X.drop(columns='date_recorded')\n",
    "    \n",
    "# #     Engineer feature: how many years from construction_year to date_recorded\n",
    "#     X['years'] = X['year_recorded'] - X['construction_year']\n",
    "#     X['years_MISSING'] = X['years'].isnull()\n",
    "    \n",
    "    # return the wrangled dataframe\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 42), (11880, 42), (14358, 41))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def split_wrangle(train,test):\n",
    "  \"\"\"Creates a 3-way train,val,test split and wrangles data. \n",
    "  Returns train, test, val sets\"\"\"\n",
    "  train, val = train_test_split(train, train_size=0.80, test_size=0.20,\n",
    "                              stratify=train['status_group'], random_state=20)\n",
    "  # Use wrangle function on split data sets\n",
    "  a = wrangle(train)  \n",
    "  b = wrangle(val)\n",
    "  c = wrangle(test)\n",
    "\n",
    "  return a,b,c\n",
    "\n",
    "train, val, test = split_wrangle(train,test)\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize into target vector and feature matrices\n",
    "target = 'status_group'\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=target)\n",
    "y_val = val[target]\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import f_regression,SelectKBest\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create modeling pipeline for Hyperperameter optimization\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    RandomForestClassifier(n_jobs=-1,random_state=20)\n",
    ")\n",
    "param_distributions = {\n",
    "    'simpleimputer__strategy': ['median','mean','most_frequent'],\n",
    "    'randomforestclassifier__n_estimators': randint(50, 500),\n",
    "    'randomforestclassifier__max_depth': (20, 25, 1),\n",
    "    'randomforestclassifier__max_features': uniform(0, 1),\n",
    "    'randomforestclassifier__min_samples_leaf': randint(1,10),\n",
    "    'randomforestclassifier__bootstrap': [0,1]\n",
    "}\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10, \n",
    "    cv=5, \n",
    "    scoring='accuracy', \n",
    "    verbose=50, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1,\n",
    "    random_state=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  50 | elapsed:  3.7min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  50 | elapsed:  3.8min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:  3.8min remaining:   49.7s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  50 | elapsed:  3.8min remaining:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  50 | elapsed:  3.8min remaining:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:  3.8min remaining:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.8min finished\n"
     ]
    }
   ],
   "source": [
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'randomforestclassifier__bootstrap': 0, 'randomforestclassifier__max_depth': 20, 'randomforestclassifier__max_features': 0.7702519331384002, 'randomforestclassifier__min_samples_leaf': 7, 'randomforestclassifier__n_estimators': 381, 'simpleimputer__strategy': 'most_frequent'}\n",
      "Cross-validation MAE -0.8008627946127946\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation MAE', -search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.8085016835016835\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "print ('Validation Accuracy', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non functional', 'functional', 'functional', ..., 'functional',\n",
       "       'functional', 'non functional'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/waterpumps/sample_submission.csv')\n",
    "# submission = sample_submission.copy()\n",
    "# submission['status_group'] = y_pred\n",
    "# submission.to_csv('tyler-etheridge-sub4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
