{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Curry 222 assignment_kaggle_challenge_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikedcurry/DS-Unit-2-Kaggle-Challenge/blob/master/Curry_222_assignment_kaggle_challenge_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IXUfiQ2UKj6",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Kaggle Challenge, Module 2\n",
        "\n",
        "## Assignment\n",
        "- [ ] Read [“Adopting a Hypothesis-Driven Workflow”](https://outline.com/5S5tsB), a blog post by a Lambda DS student about the Tanzania Waterpumps challenge.\n",
        "- [ ] Continue to participate in our Kaggle challenge.\n",
        "- [ ] Try Ordinal Encoding.\n",
        "- [ ] Try a Random Forest Classifier.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Doing\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Do more exploratory data analysis, data cleaning, feature engineering, and feature selection.\n",
        "- [ ] Try other [categorical encodings](https://contrib.scikit-learn.org/categorical-encoding/).\n",
        "- [ ] Get and plot your feature importances.\n",
        "- [ ] Make visualizations and share on Slack.\n",
        "\n",
        "### Reading\n",
        "\n",
        "Top recommendations in _**bold italic:**_\n",
        "\n",
        "#### Decision Trees\n",
        "- A Visual Introduction to Machine Learning, [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/),  and _**[Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)**_\n",
        "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
        "- [How a Russian mathematician constructed a decision tree — by hand — to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
        "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
        "- [Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU)\n",
        "\n",
        "#### Random Forests\n",
        "- [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/), Chapter 8: Tree-Based Methods\n",
        "- [Coloring with Random Forests](http://structuringtheunstructured.blogspot.com/2017/11/coloring-with-random-forests.html)\n",
        "- _**[Random Forests for Complete Beginners: The definitive guide to Random Forests and Decision Trees](https://victorzhou.com/blog/intro-to-random-forests/)**_\n",
        "\n",
        "#### Categorical encoding for trees\n",
        "- [Are categorical variables getting lost in your random forests?](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)\n",
        "- [Beyond One-Hot: An Exploration of Categorical Variables](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/)\n",
        "- _**[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)**_\n",
        "- _**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)**_\n",
        "- [Mean (likelihood) encodings: a comprehensive study](https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study)\n",
        "- [The Mechanics of Machine Learning, Chapter 6: Categorically Speaking](https://mlbook.explained.ai/catvars.html)\n",
        "\n",
        "#### Imposter Syndrome\n",
        "- [Effort Shock and Reward Shock (How The Karate Kid Ruined The Modern World)](http://www.tempobook.com/2014/07/09/effort-shock-and-reward-shock/)\n",
        "- [How to manage impostor syndrome in data science](https://towardsdatascience.com/how-to-manage-impostor-syndrome-in-data-science-ad814809f068)\n",
        "- [\"I am not a real data scientist\"](https://brohrer.github.io/imposter_syndrome.html)\n",
        "- _**[Imposter Syndrome in Data Science](https://caitlinhudon.com/2018/01/19/imposter-syndrome-in-data-science/)**_\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9eSnDYhUGD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45214353-c947-4939-ef30-d315ee28f9fe"
      },
      "source": [
        "# If you're in Colab...\n",
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "    # Install required python packages:\n",
        "    # category_encoders, version >= 2.0\n",
        "    # pandas-profiling, version >= 2.0\n",
        "    # plotly, version >= 4.0\n",
        "    !pip install --upgrade category_encoders pandas-profiling plotly\n",
        "    \n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module2')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.7MB/s \n",
            "\u001b[?25hCollecting pandas-profiling\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/2f/aae19e2173c10a9bb7fee5f5cad35dbe53a393960fc91abc477dcc4661e8/pandas-profiling-2.3.0.tar.gz (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 15.9MB/s \n",
            "\u001b[?25hCollecting plotly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/2b/4ca10995bfbdefd65c4238f9a2d3fde33705d18dd50914dd13302ec1daf1/plotly-4.1.0-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied, skipping upgrade: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.3)\n",
            "Requirement already satisfied, skipping upgrade: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=1.4 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: jinja2>=2.8 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling) (2.10.1)\n",
            "Requirement already satisfied, skipping upgrade: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12 (from pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting phik>=0.9.8 (from pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ad/24a16fa4ba612fb96a3c4bb115a5b9741483f53b66d3d3afd987f20fa227/phik-0.9.8-py3-none-any.whl (606kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 43.2MB/s \n",
            "\u001b[?25hCollecting confuse>=1.0.0 (from pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.13.2)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling) (2.4.2)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.8->pandas-profiling) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: seaborn in /usr/local/lib/python3.6/dist-packages (from missingno>=0.4.2->pandas-profiling) (0.9.0)\n",
            "Collecting pytest>=4.0.2 (from phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/1d/2430053122a3c6106f7fd1ff0bc68eb73e27db8f951db70fcd942da52c7b/pytest-5.0.1-py3-none-any.whl (221kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling) (5.5.0)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling) (5.3.1)\n",
            "Requirement already satisfied, skipping upgrade: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling) (0.40.1)\n",
            "Collecting pytest-pylint>=0.13.0 (from phik>=0.9.8->pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/64/dc/6f35f114844fb12e38d60c4f3d2441a55baff7043ad4e013777dff55746c/pytest_pylint-0.14.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4->pandas-profiling) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (19.1)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (19.1.0)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (7.2.0)\n",
            "Requirement already satisfied, skipping upgrade: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (1.3.0)\n",
            "Collecting pluggy<1.0,>=0.12 (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/06/ee/de89e0582276e3551df3110088bf20844de2b0e7df2748406876cc78e021/pluggy-0.12.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (0.19)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (1.4.2)\n",
            "Requirement already satisfied, skipping upgrade: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (2.1.3)\n",
            "Requirement already satisfied, skipping upgrade: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (17.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (4.5.3)\n",
            "Requirement already satisfied, skipping upgrade: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling) (0.29.0)\n",
            "Collecting pylint>=1.4.5 (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/c2/b3f73f4ac008bef6e75bca4992f3963b3f85942e0277237721ef1c151f0d/pylint-2.3.1-py3-none-any.whl (765kB)\n",
            "\u001b[K     |████████████████████████████████| 768kB 37.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12->pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (0.5.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.5.1)\n",
            "Collecting isort<5,>=4.2.5 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 16.5MB/s \n",
            "\u001b[?25hCollecting astroid<3,>=2.2.0 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/ad/7221a62a2dbce5c3b8c57fd18e1052c7331adc19b3f27f1561aa6e620db2/astroid-2.2.5-py3-none-any.whl (193kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 50.3MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.6/dist-packages (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling) (1.11.2)\n",
            "Collecting lazy-object-proxy (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/2a/d73b99e9407be3acd7c0328fcc44bcf6f5c42e6d03d1fb192032c0057d13/lazy_object_proxy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 21.6MB/s \n",
            "\u001b[?25hCollecting typed-ast>=1.3.0; implementation_name == \"cpython\" (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 37.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pandas-profiling, htmlmin, confuse\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.3.0-py2.py3-none-any.whl size=145036 sha256=d7999ead424ff35381f6987e53264e52502b0690950ec8699b80cb43420ff786\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/c7/f1/dbfef4848ebb048cb1d4a22d1ed0c62d8ff2523747235e19fe\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27085 sha256=621557b104000c283ddff79856fc30516ab2e90ebdf1e059f61405447d443c5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.0.0-cp36-none-any.whl size=17487 sha256=62f0ac828e4ca4ef521257ea611fa4a5abf811f4b32d7b6cf086dd65e1a20843\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
            "Successfully built pandas-profiling htmlmin confuse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: category-encoders, htmlmin, pluggy, pytest, isort, lazy-object-proxy, typed-ast, astroid, mccabe, pylint, pytest-pylint, phik, confuse, pandas-profiling, plotly\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Found existing installation: plotly 3.6.1\n",
            "    Uninstalling plotly-3.6.1:\n",
            "      Successfully uninstalled plotly-3.6.1\n",
            "Successfully installed astroid-2.2.5 category-encoders-2.0.0 confuse-1.0.0 htmlmin-0.1.12 isort-4.3.21 lazy-object-proxy-1.4.1 mccabe-0.6.1 pandas-profiling-2.3.0 phik-0.9.8 plotly-4.1.0 pluggy-0.12.0 pylint-2.3.1 pytest-5.0.1 pytest-pylint-0.14.1 typed-ast-1.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_pytest",
                  "pluggy",
                  "pytest"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 4 (delta 0), pack-reused 28\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "From https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM7jYndmHTBt",
        "colab_type": "text"
      },
      "source": [
        "## Import data / Starting Point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJBD4ruICm1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
        "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psT9b09xSo6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ca19a97-f397-42d9-913d-c4ad94c7c590"
      },
      "source": [
        "# Split train into train & val\n",
        "train, valdt = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "train.shape, valdt.shape, test.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 41), (11880, 41), (14358, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhrYtYCbwYko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
        "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "# Split train into train & val\n",
        "train, valdt = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # change region code to a catagory\n",
        "    X['region_code'] = X['region_code'].astype('category')\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "  \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['pump_age'] = X['year_recorded'] - X['construction_year']\n",
        "    X['pump_age_MISSING'] = X['pump_age'].isnull()\n",
        "    \n",
        "    # Turn all NaNs into feaures...\n",
        "    nans_cols = ['funder', 'installer', 'population', 'scheme_name', 'scheme_management',\n",
        "                'public_meeting']\n",
        "    for col in nans_cols:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "    \n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "valdt = wrangle(valdt)\n",
        "test = wrangle(test)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zN-PK8tDQ5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Possible imports\n",
        "\n",
        "%matplotlib inline\n",
        "import itertools\n",
        "from math import floor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjvdCSTJGLg2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "acf0a527-e2ed-43ec-a834-e99a4867a08a"
      },
      "source": [
        "target = 'status_group'\n",
        "\n",
        "train_features = train.drop(columns=[target])\n",
        "\n",
        "num_features = train_features.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "all_cats = train_features.select_dtypes(exclude='number').columns.tolist()\n",
        "\n",
        "# Filter features based upon cardinality\n",
        "cat_features = all_cats[all_cats <= 100].index.tolist()\n",
        "\n",
        "features = all_cats + num_features\n",
        "\n",
        "\n",
        "print('Numeric:', num_features)\n",
        "print('Catagoric:', all_cats)\n",
        "print('all Features:', features)\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-99861df3d767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Filter features based upon cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcat_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_cats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_cats\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_cats\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'list' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Inuo426ES7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector \n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "\n",
        "X_valdt = valdt[features]\n",
        "y_valdt = valdt[target]\n",
        "\n",
        "X_test = test[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG6XTfptG_zX",
        "colab_type": "text"
      },
      "source": [
        "## Exporation Zone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-jdHViMh7zz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "d8cc22ea-1185-4838-8d27-9898dcd9a2c0"
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "amount_tsh                       0\n",
              "funder                        2904\n",
              "gps_height                   16305\n",
              "installer                     2917\n",
              "longitude                     1442\n",
              "latitude                      1442\n",
              "wpt_name                         0\n",
              "num_private                      0\n",
              "basin                            0\n",
              "subvillage                     286\n",
              "region                           0\n",
              "region_code                      0\n",
              "district_code                    0\n",
              "lga                              0\n",
              "ward                             0\n",
              "population                   17066\n",
              "public_meeting                2644\n",
              "scheme_management             3128\n",
              "scheme_name                  22532\n",
              "permit                        2443\n",
              "construction_year            16517\n",
              "extraction_type                  0\n",
              "extraction_type_group            0\n",
              "extraction_type_class            0\n",
              "management                       0\n",
              "management_group                 0\n",
              "payment                          0\n",
              "water_quality                    0\n",
              "quality_group                    0\n",
              "quantity                         0\n",
              "source                           0\n",
              "source_type                      0\n",
              "source_class                     0\n",
              "waterpoint_type                  0\n",
              "waterpoint_type_group            0\n",
              "status_group                     0\n",
              "longitude_MISSING                0\n",
              "latitude_MISSING                 0\n",
              "construction_year_MISSING        0\n",
              "gps_height_MISSING               0\n",
              "population_MISSING               0\n",
              "year_recorded                    0\n",
              "month_recorded                   0\n",
              "day_recorded                     0\n",
              "years                        16517\n",
              "years_MISSING                    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KpP3Ka3WPdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "high_ordinal = ['longitude', 'wpt_name', 'subvillage', 'scheme_name', 'installer', 'funder', \n",
        "    'lga']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoS3IRa_XREK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "b69a0b25-3b5b-4624-a6a9-7a2ad987326f"
      },
      "source": [
        "encoder = ce.OrdinalEncoder()\n",
        "encoded = encoder.fit_transform(train[high_ordinal])\n",
        "encoded.head(20)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>wpt_name</th>\n",
              "      <th>subvillage</th>\n",
              "      <th>scheme_name</th>\n",
              "      <th>installer</th>\n",
              "      <th>funder</th>\n",
              "      <th>lga</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43360</th>\n",
              "      <td>33.542898</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7263</th>\n",
              "      <td>34.665760</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2486</th>\n",
              "      <td>38.238568</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>30.716727</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52726</th>\n",
              "      <td>35.389331</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8558</th>\n",
              "      <td>31.214583</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2559</th>\n",
              "      <td>36.696700</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54735</th>\n",
              "      <td>36.292724</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25763</th>\n",
              "      <td>32.877248</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44540</th>\n",
              "      <td>33.014412</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28603</th>\n",
              "      <td>38.950769</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4372</th>\n",
              "      <td>39.020094</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30666</th>\n",
              "      <td>36.694357</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6431</th>\n",
              "      <td>38.890990</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57420</th>\n",
              "      <td>31.746292</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1373</th>\n",
              "      <td>37.501573</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2026</th>\n",
              "      <td>35.371400</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58977</th>\n",
              "      <td>38.018784</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41101</th>\n",
              "      <td>29.660968</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10019</th>\n",
              "      <td>35.714295</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  wpt_name  subvillage  scheme_name  installer  funder  lga\n",
              "43360  33.542898         1           1            1          1       1    1\n",
              "7263   34.665760         2           2            2          2       2    2\n",
              "2486   38.238568         3           3            3          3       3    3\n",
              "313    30.716727         4           4            3          4       4    4\n",
              "52726  35.389331         5           5            4          5       5    5\n",
              "8558   31.214583         6           6            5          4       6    6\n",
              "2559   36.696700         7           7            6          4       7    7\n",
              "54735  36.292724         8           8            7          4       5    8\n",
              "25763  32.877248         9           9            3          6       8    9\n",
              "44540  33.014412        10          10            3          7       9   10\n",
              "28603  38.950769        11          11            3          8      10   11\n",
              "4372   39.020094        12          12            8          4      11   12\n",
              "30666  36.694357         8          13            3          1       2   13\n",
              "6431   38.890990        13          14            9          9      12    3\n",
              "57420  31.746292        14           4            3          4      13   14\n",
              "1373   37.501573        15          15           10          4       4   15\n",
              "2026   35.371400        16          16           11         10      14   16\n",
              "58977  38.018784        17          17            3         11       4   17\n",
              "41101  29.660968        18          18           12         12      15   18\n",
              "10019  35.714295        19          19           13         13      16   19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA1FTD8AGPU8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "5a2610ad-d923-481c-c19f-6d3d492d745f"
      },
      "source": [
        "# Looking at all catigorical features, cardinality in descending order\n",
        "\n",
        "all_cats.sort_values(ascending=False)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "wpt_name                     30661\n",
              "subvillage                   17231\n",
              "scheme_name                   2563\n",
              "ward                          2082\n",
              "installer                     1929\n",
              "funder                        1716\n",
              "lga                            124\n",
              "region_code                     27\n",
              "region                          21\n",
              "extraction_type                 18\n",
              "extraction_type_group           13\n",
              "scheme_management               12\n",
              "management                      12\n",
              "source                          10\n",
              "basin                            9\n",
              "water_quality                    8\n",
              "extraction_type_class            7\n",
              "source_type                      7\n",
              "payment                          7\n",
              "waterpoint_type                  7\n",
              "quality_group                    6\n",
              "waterpoint_type_group            6\n",
              "management_group                 5\n",
              "quantity                         5\n",
              "source_class                     3\n",
              "latitude_MISSING                 2\n",
              "gps_height_MISSING               2\n",
              "construction_year_MISSING        2\n",
              "public_meeting                   2\n",
              "longitude_MISSING                2\n",
              "permit                           2\n",
              "population_MISSING               2\n",
              "years_MISSING                    2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjw71Uw_Gn9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "068e7976-d771-4408-c998-58da55057ef1"
      },
      "source": [
        "# Inspect Data Types... \n",
        "\n",
        "\n",
        "train.dtypes"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "amount_tsh                      float64\n",
              "date_recorded            datetime64[ns]\n",
              "funder                           object\n",
              "gps_height                        int64\n",
              "installer                        object\n",
              "longitude                       float64\n",
              "latitude                        float64\n",
              "wpt_name                         object\n",
              "num_private                       int64\n",
              "basin                            object\n",
              "subvillage                       object\n",
              "region                           object\n",
              "region_code                    category\n",
              "district_code                     int64\n",
              "lga                              object\n",
              "ward                             object\n",
              "population                        int64\n",
              "public_meeting                   object\n",
              "scheme_management                object\n",
              "scheme_name                      object\n",
              "permit                           object\n",
              "construction_year               float64\n",
              "extraction_type                  object\n",
              "extraction_type_group            object\n",
              "extraction_type_class            object\n",
              "management                       object\n",
              "management_group                 object\n",
              "payment                          object\n",
              "water_quality                    object\n",
              "quality_group                    object\n",
              "quantity                         object\n",
              "source                           object\n",
              "source_type                      object\n",
              "source_class                     object\n",
              "waterpoint_type                  object\n",
              "waterpoint_type_group            object\n",
              "status_group                     object\n",
              "pump_age                        float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSnwaxRHGYz7",
        "colab_type": "text"
      },
      "source": [
        "## Run in Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfRZfcMMos--",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouWw1c5YGdhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With a pipline: LogisticRegression\n",
        "\n",
        "#one-hot / standard-scale / fit / score \n",
        "# (note: subset already dertermined ABOVE when defining X_train, etc. )\n",
        "\n",
        "pipe = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(),                          # also I'm using this, cause...\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
        "    )\n",
        "\n",
        "# fit model to train set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# score model on valdt set\n",
        "print('Validate Yo Self:', pipe.score(X_valdt, y_valdt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG6UT0nLooUP",
        "colab_type": "text"
      },
      "source": [
        "### DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79rB-Mf9Gfi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With a pipline:   DecisionTreeClassifier\n",
        "\n",
        "pipe_dt = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    DecisionTreeClassifier(random_state=42, min_samples_leaf=25, max_depth=21)\n",
        "    )\n",
        "\n",
        "# fit model to train set\n",
        "pipe_dt.fit(X_train, y_train)\n",
        "\n",
        "# score model on valdt set\n",
        "print('Validate Yo Self:', pipe_dt.score(X_valdt, y_valdt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cum1Wjsk1qW",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxmnv7f_gzuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp5rAXicflUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "986105c8-6a1e-4f98-85cc-c8814524b33a"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    )\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_valdt, y_valdt))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8111952861952862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSYpdGFunJOw",
        "colab_type": "text"
      },
      "source": [
        "### Extra Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxyA66eFHmlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij-_2dWDmeoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbiS4gNKmfzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99d40d61-6009-4a11-b1c2-406e7fdd8700"
      },
      "source": [
        "pipe_extra = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    ExtraTreesClassifier(n_estimators=150, random_state=42, n_jobs=-1)\n",
        "    )\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipe_extra.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipe_extra.score(X_valdt, y_valdt))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.799074074074074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oshPkWuSp86Z",
        "colab_type": "text"
      },
      "source": [
        "### Experimental"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd1_jlqPp_oG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install dirty_cat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YRpbekCqEnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder = dirty_cat.TargetEncoder(clf_type='multiclass-clf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1HF5bp_qnES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ce.TargetEncoder("
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvYrYRp60CHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P9zbzdG3ZYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe_experiment = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'),\n",
        "    GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, \n",
        "                               max_depth=2, random_state=42)\n",
        "    )\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipe_experiment.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipe_experiment.score(X_valdt, y_valdt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBIDDCl06TIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ac6f138-bff1-430e-f3ff-7cdf2a5bdaec"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'),\n",
        "    AdaBoostClassifier(\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
        "    )\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_valdt, y_valdt))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7947811447811448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MccGahYHIW4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(strategy='median'),\n",
        "    AdaBoostClassifier(\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
        "    )\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_valdt, y_valdt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PIuGnO4G0qq",
        "colab_type": "text"
      },
      "source": [
        "## Submitting to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xYJtYrwG4b0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WAIT!!! This is the last step...\n",
        "\n",
        "# Predict on test\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "# Write submission csv file\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "submission.to_csv('curry_submit_5.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ1WzjBCG6BX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0a5d931-41b6-4257-85fe-8a20aae7f09d"
      },
      "source": [
        "!head curry_submit_4.csv"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "head: cannot open 'curry_submit_4.csv' for reading: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6z-idyjG8dY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if in_colab:\n",
        "    from google.colab import files\n",
        "    # Just try again if you get this error:\n",
        "    # TypeError: Failed to fetch\n",
        "    # https://github.com/googlecolab/colabtools/issues/337\n",
        "    files.download('curry_submit_5.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}