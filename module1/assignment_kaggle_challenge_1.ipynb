{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_kaggle_challenge_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phatdeluxe/DS-Unit-2-Kaggle-Challenge/blob/master/module1/assignment_kaggle_challenge_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Kaggle Challenge, Module 1\n",
        "\n",
        "## Assignment\n",
        "- [ ] Do train/validate/test split with the Tanzania Waterpumps data.\n",
        "- [ ] Define a function to wrangle train, validate, and test sets in the same way. Clean outliers and engineer features. (For example, [what other columns have zeros and shouldn't?](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values) What other columns are duplicates, or nearly duplicates? Can you extract the year from date_recorded? Can you engineer new features, such as the number of years from waterpump construction to waterpump inspection?)\n",
        "- [ ] Select features. Use a scikit-learn pipeline to encode categoricals, impute missing values, and fit a decision tree classifier.\n",
        "- [ ] Get your validation accuracy score.\n",
        "- [ ] Get and plot your feature importances.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Reading\n",
        "\n",
        "- A Visual Introduction to Machine Learning\n",
        "  - [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n",
        "  - [Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)\n",
        "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
        "- [How a Russian mathematician constructed a decision tree — by hand — to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
        "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
        "- [Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU) — _Don’t worry about understanding the code, just get introduced to the concepts. This 10 minute video has excellent diagrams and explanations._\n",
        "- [Random Forests for Complete Beginners: The definitive guide to Random Forests and Decision Trees](https://victorzhou.com/blog/intro-to-random-forests/)\n",
        "\n",
        "\n",
        "### Doing\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Try other [scikit-learn imputers](https://scikit-learn.org/stable/modules/impute.html).\n",
        "- [ ] Make exploratory visualizations and share on Slack.\n",
        "\n",
        "\n",
        "#### Exploratory visualizations\n",
        "\n",
        "Visualize the relationships between feature(s) and target. I recommend you do this with your training set, after splitting your data. \n",
        "\n",
        "For this problem, you may want to create a new column to represent the target as a number, 0 or 1. For example:\n",
        "\n",
        "```python\n",
        "train['functional'] = (train['status_group']=='functional').astype(int)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "You can try [Seaborn \"Categorical estimate\" plots](https://seaborn.pydata.org/tutorial/categorical.html) for features with reasonably few unique values. (With too many unique values, the plot is unreadable.)\n",
        "\n",
        "- Categorical features. (If there are too many unique values, you can replace less frequent values with \"OTHER.\")\n",
        "- Numeric features. (If there are too many unique values, you can [bin with pandas cut / qcut functions](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=qcut#discretization-and-quantiling).)\n",
        "\n",
        "You can try [Seaborn linear model plots](https://seaborn.pydata.org/tutorial/regression.html) with numeric features. For this classification problem, you may want to use the parameter `logistic=True`, but it can be slow.\n",
        "\n",
        "You do _not_ need to use Seaborn, but it's nice because it includes confidence intervals to visualize uncertainty.\n",
        "\n",
        "#### High-cardinality categoricals\n",
        "\n",
        "This code from a previous assignment demonstrates how to replace less frequent values with 'OTHER'\n",
        "\n",
        "```python\n",
        "# Reduce cardinality for NEIGHBORHOOD feature ...\n",
        "\n",
        "# Get a list of the top 10 neighborhoods\n",
        "top10 = train['NEIGHBORHOOD'].value_counts()[:10].index\n",
        "\n",
        "# At locations where the neighborhood is NOT in the top 10,\n",
        "# replace the neighborhood with 'OTHER'\n",
        "train.loc[~train['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
        "test.loc[~test['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJBD4ruICm1m",
        "outputId": "34468ed2-8e30-4f87-acf4-9048681f228e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((59400, 41), (14358, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBzc5cgPVW6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "9921aad7-1ee5-451c-99d2-41ab0648a842"
      },
      "source": [
        "target = 'status_group'\n",
        "\n",
        "train_features = train.drop(['id', target], axis=1)\n",
        "\n",
        "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
        "\n",
        "high_cardinality = cardinality[cardinality > 50].index.tolist()\n",
        "\n",
        "high_cardinality.remove('date_recorded')\n",
        "print(high_cardinality)\n",
        "\n",
        "for card in high_cardinality:\n",
        "  top_ten = train[card].value_counts()[:10].index\n",
        "  train.loc[~train[card].isin(top_ten), card] = 'Other'\n",
        "  test.loc[~test[card].isin(top_ten), card] = 'Other'\n",
        "\n",
        "features = train.columns.drop(target)\n",
        "print(features)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['funder', 'installer', 'wpt_name', 'subvillage', 'lga', 'ward', 'scheme_name']\n",
            "Index(['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height',\n",
            "       'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n",
            "       'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga',\n",
            "       'ward', 'population', 'public_meeting', 'recorded_by',\n",
            "       'scheme_management', 'scheme_name', 'permit', 'construction_year',\n",
            "       'extraction_type', 'extraction_type_group', 'extraction_type_class',\n",
            "       'management', 'management_group', 'payment', 'payment_type',\n",
            "       'water_quality', 'quality_group', 'quantity', 'quantity_group',\n",
            "       'source', 'source_type', 'source_class', 'waterpoint_type',\n",
            "       'waterpoint_type_group'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Amxyx3xphbb",
        "colab": {}
      },
      "source": [
        "my_train, my_val = train_test_split(train, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVTe6hzBe-C7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "redundant_cols = ['recorded_by', 'extraction_type_group',\n",
        "                  'extraction_type_class', 'management_group',\n",
        "                  'payment_type', 'quality_group', 'quantity_group',\n",
        "                  'source_type', 'source_class', 'waterpoint_type_group',\n",
        "                  'date_recorded']\n",
        "features = features.drop(redundant_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rftx_qZMtDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def wrangle(data):\n",
        "  \n",
        "  data = data.copy()\n",
        "\n",
        "  data['latitude'].replace(-2e-8, 0)\n",
        "\n",
        "  # data['date_recorded'] = pd.to_datetime(data['date_recorded'])\n",
        "\n",
        "  columns_zero = ['longitude', 'latitude', 'construction_year',\n",
        "                  'population', 'amount_tsh']\n",
        "\n",
        "  for cols in columns_zero:\n",
        "    data[cols].replace(0, np.nan)\n",
        "\n",
        "  data = data.drop(redundant_cols, axis=1)\n",
        "  \n",
        "  return data\n",
        "  ## May come back and do more feature engineering"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEmYjX0PNPNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_train = wrangle(my_train)\n",
        "my_val = wrangle(my_val)\n",
        "my_test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpVZB8facWVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = my_train[features]\n",
        "y_train = my_train[target]\n",
        "X_val = my_val[features]\n",
        "y_val = my_val[target]\n",
        "X_test = test[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AudHYr0chd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    StandardScaler(),\n",
        "    DecisionTreeClassifier(min_samples_leaf=20, random_state=42)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhcucjLOgZHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3f3f4be8-a1a3-4899-c05c-464993b509d9"
      },
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "print('Train accuracy: ', pipeline.score(X_train, y_train))\n",
        "print('Validation accuracy: ', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy:  0.8067340067340067\n",
            "Validation accuracy:  0.7603367003367003\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}