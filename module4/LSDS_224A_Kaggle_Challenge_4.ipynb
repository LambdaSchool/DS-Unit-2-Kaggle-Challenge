{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nCc3XZEyG3XV"},"source":["### Tobias Reaper\n","\n","LSDS Unit 2: Predictive Modeling\n","\n","# Kaggle Challenge, Module 4\n","\n","---\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nCc3XZEyG3XV"},"source":["## Assignment\n","- [ ] If you haven't yet, [review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2), then submit your dataset.\n","- [ ] Plot a confusion matrix for your Tanzania Waterpumps model.\n","- [ ] Continue to participate in our Kaggle challenge - at least 5 submission that score at least 60% accuracy.\n","- [ ] Submit your final predictions to our Kaggle competition. Optionally, go to **My Submissions**, and _\"you may select up to 1 submission to be used to count towards your final leaderboard score.\"_\n","- [ ] Commit your notebook to your fork of the GitHub repo.\n","- [ ] Read [Maximizing Scarce Maintenance Resources with Data: Applying predictive modeling, precision at k, and clustering to optimize impact](https://towardsdatascience.com/maximizing-scarce-maintenance-resources-with-data-8f3491133050), by Lambda DS3 student Michael Brady. His blog post extends the Tanzania Waterpumps scenario, far beyond what's in the lecture notebook."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nCc3XZEyG3XV"},"source":["## Stretch Goals\n","\n","### Reading\n","- [Attacking discrimination with smarter machine learning](https://research.google.com/bigpicture/attacking-discrimination-in-ml/), by Google Research, with  interactive visualizations. _\"A threshold classifier essentially makes a yes/no decision, putting things in one category or another. We look at how these classifiers work, ways they can potentially be unfair, and how you might turn an unfair classifier into a fairer one. As an illustrative example, we focus on loan granting scenarios where a bank may grant or deny a loan based on a single, automatically computed number such as a credit score.\"_\n","- [Notebook about how to calculate expected value from a confusion matrix by treating it as a cost-benefit matrix](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb)\n","- [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) by Kevin Markham, with video\n","- [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415)\n","\n","\n","### Doing\n","- [ ] Share visualizations in our Slack channel!\n","- [ ] RandomizedSearchCV / GridSearchCV, for model selection. (See module 3 assignment notebook)\n","- [ ] More Categorical Encoding. (See module 2 assignment notebook)\n","- [ ] Stacking Ensemble. (See below)\n","\n","### Stacking Ensemble\n","\n","Here's some code you can use to \"stack\" multiple submissions, which is another form of ensembling:\n","\n","```python\n","import pandas as pd\n","\n","# Filenames of your submissions you want to ensemble\n","files = ['submission-01.csv', 'submission-02.csv', 'submission-03.csv']\n","\n","target = 'status_group'\n","submissions = (pd.read_csv(file)[[target]] for file in files)\n","ensemble = pd.concat(submissions, axis='columns')\n","majority_vote = ensemble.mode(axis='columns')[0]\n","\n","sample_submission = pd.read_csv('sample_submission.csv')\n","submission = sample_submission.copy()\n","submission[target] = majority_vote\n","submission.to_csv('my-ultimate-ensemble-submission.csv', index=False)\n","```"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"# The classixx\nimport pandas as pd\nimport numpy as np"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"# The extras\nimport pandas_profiling\nimport janitor\n\nimport plotly.express as px\nimport plotly.figure_factory as ff"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"# The SkoolKidz\nfrom scipy.stats import randint, uniform\nimport category_encoders as ce\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer, IterativeImputer\nfrom sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"# The metrikidz\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.utils.multiclass import unique_labels  # Check out what other methods this library has"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"# Define data source\n# DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'  # Remote\nDATA_PATH = '/Users/Tobias/workshop/dasci/sprints/06-Kaggle_Challenge/DS-Unit-2-Kaggle-Challenge/data/'  # Local\n\n# Load and merge train_features + train_labels\ntrain = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n\n# Read test_features + sample_submission\ntest = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\nsample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"---"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"pipeline = make_pipeline(  # Define the pipe\n    ce.OrdinalEncoder(), \n    IterativeImputer(), \n    RandomForestClassifier(random_state=42),\n)\n\nparam_distributions = {  # The hyper-parameters to search\n    'iterativeimputer__initial_strategy': [\"mean\", \"median\"], \n    'iterativeimputer__max_iter': randint(5, 20),\n    'iterativeimputer__n_nearest_features': randint(1, 6),\n    'iterativeimputer__imputation_order': [\"ascending\", \"arabic\"],\n    'randomforestclassifier__n_estimators': randint(100, 300), \n    'randomforestclassifier__max_depth': [16, 20, 24, 32], \n    'randomforestclassifier__max_features': uniform(0, 1), \n}\n\nsearch = RandomizedSearchCV(  # How many times\n    pipeline, \n    param_distributions=param_distributions, \n    n_iter=3,\n    cv=3, \n    scoring='accuracy',\n    verbose=10, \n    return_train_score=True, \n    n_jobs=-1,\n    random_state=42,\n)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Fit and find the best hyperparameters according to above\nsearch.fit(X_train, y_train[\"status_group\"].values.flatten());"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Print the best combo of hyperparameters and the corresponding accuracy\nprint('Best hyperparameters', search.best_params_)\nprint('Accuracy', search.best_score_)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Make predictions on test using best model from random search\nbestest = search.best_estimator_  # Create instance of best model from search\n\n# Predict on the test data\ny_pred = bestest.predict(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Check out values counts\ny_pred_series = pd.Series(y_pred)\ny_pred_series.value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"markdown","execution_count":3,"metadata":{},"outputs":[],"source":"---\n\n## Plot the Matrix\n\n> Main diagonal are correct predictions\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"print(classification_report(y_val, y_pred))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# 3.2 Plot a heatmap with plotly\ndef plot_confusion_matrix(y_true, y_pred):\n    labels = unique_labels(y_true)\n    columns = [f'Predicted {label}' for label in labels]\n    index = [f'Actual {label}' for label in labels]\n    z = confusion_matrix(y_true, y_pred)\n    fig = ff.create_annotated_heatmap(z, x=columns, y=index, colorscale=\"Viridis\")\n    fig.update_yaxes(autorange=\"reversed\")    \n    fig.show()\n\nplot_confusion_matrix(y_val, y_pred)"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}