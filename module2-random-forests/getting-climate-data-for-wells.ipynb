{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import rasterio \n",
    "\n",
    "from rasterstats import zonal_stats, point_query\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(X):\n",
    "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
    "    \n",
    "    # Prevent SettingWithCopyWarning\n",
    "    X = X.copy()\n",
    "    \n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these values like zero.\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values.\n",
    "    # So we will replace the zeros with nulls, and impute missing values later.\n",
    "    # Also create a \"missing indicator\" column, because the fact that\n",
    "    # values are missing may be a predictive signal.\n",
    "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
    "                       'gps_height', 'population']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        X[col+'_MISSING'] = X[col].isnull()\n",
    "            \n",
    "    # Drop duplicate columns\n",
    "    duplicates = ['quantity_group', 'payment_type']\n",
    "    X = X.drop(columns=duplicates)\n",
    "    \n",
    "    # Drop recorded_by (never varies) and id (always varies, random)\n",
    "    unusable_variance = ['recorded_by']\n",
    "    X = X.drop(columns=unusable_variance)\n",
    "    \n",
    "    # Convert date_recorded to datetime\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract components from date_recorded, then drop the original column\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    X['month_recorded'] = X['date_recorded'].dt.month\n",
    "    X['day_recorded'] = X['date_recorded'].dt.day\n",
    "    X = X.drop(columns='date_recorded')\n",
    "    \n",
    "    # Engineer feature: how many years from construction_year to date_recorded\n",
    "    X['years'] = X['year_recorded'] - X['construction_year']\n",
    "    X['years_MISSING'] = X['years'].isnull()\n",
    "    \n",
    "    \n",
    "    # return the wrangled dataframe\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
    "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
    "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
    "\n",
    "\n",
    "# Split train into train & val\n",
    "train, validate = train_test_split(\n",
    "    train, \n",
    "    train_size=0.80, \n",
    "    test_size=0.20, \n",
    "    stratify=train['status_group'], \n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = wrangle(train)\n",
    "validate = wrangle(validate)\n",
    "test = wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coordinates = train[train[\"latitude\"].notna()]\n",
    "validate_coordinates = validate[validate[\"latitude\"].notna()]\n",
    "test_coordinates = test[test[\"latitude\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_rs = train_coordinates[[\"id\",\"latitude\",\"longitude\"]]\n",
    "validate_for_rs = validate_coordinates[[\"id\",\"latitude\",\"longitude\"]]\n",
    "test_for_rs = test_coordinates[[\"id\",\"latitude\",\"longitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_shapefile(dataframe, filename):\n",
    "    gdf = gpd.GeoDataFrame(dataframe, geometry=gpd.points_from_xy(dataframe.longitude, dataframe.latitude))\n",
    "    gdf.crs = \"EPSG:4326\"\n",
    "    gdf.to_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_shapefile(train_for_rs, \"/home/alex/data/tanzania-pumps-rasterstats/train.shp\")\n",
    "save_as_shapefile(validate_for_rs, \"/home/alex/data/tanzania-pumps-rasterstats/validate.shp\")\n",
    "save_as_shapefile(test_for_rs, \"/home/alex/data/tanzania-pumps-rasterstats/test.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = \"/home/alex/data/2012 Wards Shapefiles/TZwards.shp\"\n",
    "\n",
    "raster_folder = \"/home/alex/data/CHIRPS-africa-monthly\"\n",
    "\n",
    "identifier_column = \"Ward_Name\"\n",
    "\n",
    "file_prefix = \"chirps-v2.0.\"\n",
    "\n",
    "file_type_of_interest = \".tif\"\n",
    "\n",
    "statistic_of_interest = \"mean\"\n",
    "\n",
    "train_output_csv = \"/home/alex/data/tanzania-pumps-rasterstats/tanzania_chirps_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "os.chdir(raster_folder)\n",
    "\n",
    "def processing(name): \n",
    "    \n",
    "    result = zonal_stats(boundaries, name, stats=[statistic_of_interest], nodata=-9999, all_touched=True, geojson_out=False) \n",
    "    \n",
    "    return (name, result)  \n",
    "\n",
    "with multiprocessing.Pool(multiprocessing.cpu_count()) as pool: \n",
    "    \n",
    "    for name, result in pool.map(processing, glob.glob(\"*\" + file_type_of_interest)): \n",
    "        \n",
    "        results[name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
