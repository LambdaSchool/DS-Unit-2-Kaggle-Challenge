{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_222_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/accarter/DS-Unit-2-Kaggle-Challenge/blob/master/module2-random-forests/LS_DS_222_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lwR7joO2tIB",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Random Forests\n",
        "\n",
        "## Assignment\n",
        "- [ ] Read [“Adopting a Hypothesis-Driven Workflow”](http://archive.is/Nu3EI), a blog post by a Lambda DS student about the Tanzania Waterpumps challenge.\n",
        "- [ ] Continue to participate in our Kaggle challenge.\n",
        "- [ ] Define a function to wrangle train, validate, and test sets in the same way. Clean outliers and engineer features.\n",
        "- [ ] Try Ordinal Encoding.\n",
        "- [ ] Try a Random Forest Classifier.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Doing\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Do more exploratory data analysis, data cleaning, feature engineering, and feature selection.\n",
        "- [ ] Try other [categorical encodings](https://contrib.scikit-learn.org/category_encoders/).\n",
        "- [ ] Get and plot your feature importances.\n",
        "- [ ] Make visualizations and share on Slack.\n",
        "\n",
        "### Reading\n",
        "\n",
        "Top recommendations in _**bold italic:**_\n",
        "\n",
        "#### Decision Trees\n",
        "- A Visual Introduction to Machine Learning, [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/),  and _**[Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)**_\n",
        "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
        "- [How a Russian mathematician constructed a decision tree — by hand — to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
        "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
        "- [Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU)\n",
        "\n",
        "#### Random Forests\n",
        "- [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/), Chapter 8: Tree-Based Methods\n",
        "- [Coloring with Random Forests](http://structuringtheunstructured.blogspot.com/2017/11/coloring-with-random-forests.html)\n",
        "- _**[Random Forests for Complete Beginners: The definitive guide to Random Forests and Decision Trees](https://victorzhou.com/blog/intro-to-random-forests/)**_\n",
        "\n",
        "#### Categorical encoding for trees\n",
        "- [Are categorical variables getting lost in your random forests?](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)\n",
        "- [Beyond One-Hot: An Exploration of Categorical Variables](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/)\n",
        "- _**[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)**_\n",
        "- _**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)**_\n",
        "- [Mean (likelihood) encodings: a comprehensive study](https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study)\n",
        "- [The Mechanics of Machine Learning, Chapter 6: Categorically Speaking](https://mlbook.explained.ai/catvars.html)\n",
        "\n",
        "#### Imposter Syndrome\n",
        "- [Effort Shock and Reward Shock (How The Karate Kid Ruined The Modern World)](http://www.tempobook.com/2014/07/09/effort-shock-and-reward-shock/)\n",
        "- [How to manage impostor syndrome in data science](https://towardsdatascience.com/how-to-manage-impostor-syndrome-in-data-science-ad814809f068)\n",
        "- [\"I am not a real data scientist\"](https://brohrer.github.io/imposter_syndrome.html)\n",
        "- _**[Imposter Syndrome in Data Science](https://caitlinhudon.com/2018/01/19/imposter-syndrome-in-data-science/)**_\n",
        "\n",
        "\n",
        "### More Categorical Encodings\n",
        "\n",
        "**1.** The article **[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)** mentions 4 encodings:\n",
        "\n",
        "- **\"Categorical Encoding\":** This means using the raw categorical values as-is, not encoded. Scikit-learn doesn't support this, but some tree algorithm implementations do. For example, [Catboost](https://catboost.ai/), or R's [rpart](https://cran.r-project.org/web/packages/rpart/index.html) package.\n",
        "- **Numeric Encoding:** Synonymous with Label Encoding, or \"Ordinal\" Encoding with random order. We can use [category_encoders.OrdinalEncoder](https://contrib.scikit-learn.org/category_encoders/ordinal.html).\n",
        "- **One-Hot Encoding:** We can use [category_encoders.OneHotEncoder](https://contrib.scikit-learn.org/category_encoders/onehot.html).\n",
        "- **Binary Encoding:** We can use [category_encoders.BinaryEncoder](https://contrib.scikit-learn.org/category_encoders/binary.html).\n",
        "\n",
        "\n",
        "**2.** The short video \n",
        "**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)** introduces an interesting idea: use both X _and_ y to encode categoricals.\n",
        "\n",
        "Category Encoders has multiple implementations of this general concept:\n",
        "\n",
        "- [CatBoost Encoder](https://contrib.scikit-learn.org/category_encoders/catboost.html)\n",
        "- [Generalized Linear Mixed Model Encoder](https://contrib.scikit-learn.org/category_encoders/glmm.html)\n",
        "- [James-Stein Encoder](https://contrib.scikit-learn.org/category_encoders/jamesstein.html)\n",
        "- [Leave One Out](https://contrib.scikit-learn.org/category_encoders/leaveoneout.html)\n",
        "- [M-estimate](https://contrib.scikit-learn.org/category_encoders/mestimate.html)\n",
        "- [Target Encoder](https://contrib.scikit-learn.org/category_encoders/targetencoder.html)\n",
        "- [Weight of Evidence](https://contrib.scikit-learn.org/category_encoders/woe.html)\n",
        "\n",
        "Category Encoder's mean encoding implementations work for regression problems or binary classification problems. \n",
        "\n",
        "For multi-class classification problems, you will need to temporarily reformulate it as binary classification. For example:\n",
        "\n",
        "```python\n",
        "encoder = ce.TargetEncoder(min_samples_leaf=..., smoothing=...) # Both parameters > 1 to avoid overfitting\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train=='functional')\n",
        "X_val_encoded = encoder.transform(X_train, y_val=='functional')\n",
        "```\n",
        "\n",
        "For this reason, mean encoding won't work well within pipelines for multi-class classification problems.\n",
        "\n",
        "**3.** The **[dirty_cat](https://dirty-cat.github.io/stable/)** library has a Target Encoder implementation that works with multi-class classification.\n",
        "\n",
        "```python\n",
        " dirty_cat.TargetEncoder(clf_type='multiclass-clf')\n",
        "```\n",
        "It also implements an interesting idea called [\"Similarity Encoder\" for dirty categories](https://www.slideshare.net/GaelVaroquaux/machine-learning-on-non-curated-data-154905090).\n",
        "\n",
        "However, it seems like dirty_cat doesn't handle missing values or unknown categories as well as category_encoders does. And you may need to use it with one column at a time, instead of with your whole dataframe.\n",
        "\n",
        "**4. [Embeddings](https://www.kaggle.com/colinmorris/embedding-layers)** can work well with sparse / high cardinality categoricals.\n",
        "\n",
        "_**I hope it’s not too frustrating or confusing that there’s not one “canonical” way to encode categoricals. It’s an active area of research and experimentation — maybe you can make your own contributions!**_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLP-iMO02tIF",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "\n",
        "You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab (run the code cell below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJBD4ruICm1m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a774e582-12e3-4274-f040-bd372f3d99f4"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((59400, 41), (14358, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si7xiutGtTfL",
        "colab_type": "text"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwuWyQnhtS0g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a7fad65e-e21e-4dd0-8b6d-669d2e4a409f"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okrWJuR6tYCe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "7ce92ac9-52b5-4dee-ae92-ddf64100bc24"
      },
      "source": [
        "target = 'status_group'\n",
        "feature = 'extraction_type_class'\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(24,6))\n",
        "for label, ax in zip(train[target].unique(), axes):\n",
        "  sns.barplot(\n",
        "      x=train[feature],\n",
        "      y=train[target] == label,\n",
        "      ax=ax\n",
        "  ).set_title(label);\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x432 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgO7rszvXDzu",
        "colab_type": "text"
      },
      "source": [
        "### Train/Validate Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxEPX5ej-jGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35f98b4e-78f4-4ac1-8f23-51480d1d8787"
      },
      "source": [
        "# train_raw, val_raw = train_test_split(train, test_size=0.20, train_size=0.80,\n",
        "#                               random_state=42, shuffle=True, stratify=train[target])\n",
        "\n",
        "initial_row_counts = [df.shape[0] for df in (train, test)]\n",
        "\n",
        "def assert_initial_shape(train, test):\n",
        "  '''\n",
        "  Ensure that the number of rows in each DataFrame remains unchanged.\n",
        "  '''\n",
        "  for count, df in zip(initial_row_counts, (train, test)):\n",
        "    assert count == df.shape[0]\n",
        "\n",
        "initial_row_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[59400, 14358]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSGiUAO3JP-C",
        "colab_type": "text"
      },
      "source": [
        "### Filters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ-Dn47vST7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def remove_outliers(se):\n",
        "  '''\n",
        "  Remove outer 1% of values (outliers).\n",
        "  '''\n",
        "  se = se.dropna()\n",
        "  return pd.Series(np.where((se >= np.percentile(se, 0.5)) &\n",
        "                            (se <= np.percentile(se, 99.5)), se, np.nan))\n",
        "  \n",
        "\n",
        "def clean(filter):\n",
        "  '''\n",
        "  Decorator function for casting pd.Series as type float\n",
        "  and removing any outliers after applying the specified filter.\n",
        "  '''\n",
        "  def wrapper(se):\n",
        "    return remove_outliers(filter(se.astype(float)))\n",
        "  return wrapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuc4D5l9ScId",
        "colab_type": "text"
      },
      "source": [
        "Population\n",
        "*  Replace rows with values of 1 or less.\n",
        "*  Feature engineer two categories: (a) \"1 or less\" and (b) \"populated\" if having a population of 1 or less is meaningful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zglga5TGSaUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def population_filter(se):\n",
        "  '''\n",
        "  Replaces rows with populations of 1 or fewer with np.nan.\n",
        "  Replaces rows with outliers with np.nan.\n",
        "  '''\n",
        "  return pd.Series(np.where((se <= 1) | (se == np.nan), np.nan, se))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zg7rxY6Z5m_",
        "colab_type": "text"
      },
      "source": [
        "Total Static Head\n",
        "*  Replace values less than 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs5McGa7Z9mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def amount_tsh_filter(se):\n",
        "  '''\n",
        "  Replaces total static head values less than 0 with np.nan.\n",
        "  '''\n",
        "  return pd.Series(np.where((se <= 0), np.nan, se))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-trQxW0a-o0",
        "colab_type": "text"
      },
      "source": [
        "GPS Height\n",
        "*  Replace gps height values of 0 or less."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPoO1YZobavV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gps_height_filter(se):\n",
        "  '''\n",
        "  Replaces gps height values of 0 or less with np.nan.\n",
        "  '''\n",
        "  return pd.Series(np.where(se <= 1, np.nan, se))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXy7nzrVbrI_",
        "colab_type": "text"
      },
      "source": [
        "Latitude & Longitude\n",
        "*  Replace latitude values of -2e-08.\n",
        "*  Replace longitude values of 0.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RMguc1ucSa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def axis_filter(se):\n",
        "  '''\n",
        "  Replaces latitude values of -2e-08 with np.nan.\n",
        "  Replaces longitude vales of 0.0 with np.nan.\n",
        "  '''\n",
        "  null_lat = se.value_counts().index[0]\n",
        "  return pd.Series(np.where(se == null_lat, np.nan, se))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFJZHHN4d8oX",
        "colab_type": "text"
      },
      "source": [
        "Construction Year\n",
        "* Replace construction years of 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwYqdUX8JV4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def construction_year_filter(se):\n",
        "  '''\n",
        "  Replaces construction years of 0 with np.nan.\n",
        "  '''\n",
        "  return pd.Series(np.where(se == 0, np.nan, se))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTISwv31ebpP",
        "colab_type": "text"
      },
      "source": [
        "Num Private\n",
        "*  Replace num private values of 0 or less."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFxRuiK4ekRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def num_private_filter(se):\n",
        "  '''\n",
        "  Replaces num private values of 0 or less with np.nan.\n",
        "  '''\n",
        "  return pd.Series(np.where(se <= 0, np.nan, se))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYh13xT0n_w_",
        "colab_type": "text"
      },
      "source": [
        "### Replacements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDc0lV-8gOPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "3e0b25f4-1382-4a29-d978-5bc8010f659f"
      },
      "source": [
        "numeric_features = ['population', 'amount_tsh', 'gps_height', \n",
        "                    'latitude', 'longitude', 'num_private']\n",
        "\n",
        "measurements = ['mean', 'median', 'median', 'mean', 'mean', 'mode']\n",
        "\n",
        "filters = [population_filter, amount_tsh_filter, gps_height_filter, \n",
        "           axis_filter, axis_filter, num_private_filter]\n",
        "\n",
        "replacement_config = dict(zip(numeric_features, zip(measurements, filters)))\n",
        "\n",
        "measurement_funcs = {\n",
        "    'mean': lambda se: se.mean(),\n",
        "    'mode': lambda se: se.mode()[0],\n",
        "    'median': lambda se: se.median()\n",
        "}\n",
        "\n",
        "def find_replacement(df, feature):\n",
        "  measurement, filter = replacement_config[feature]\n",
        "  return measurement_funcs[measurement](clean(filter)(df[feature]))\n",
        "\n",
        "# combine DataFrames for generating replacement values\n",
        "tanzania = pd.concat([train.copy(), test.copy()])\n",
        "replacements = {feature: find_replacement(tanzania, feature) for feature in numeric_features}\n",
        "replacements"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'amount_tsh': 250.0,\n",
              " 'gps_height': 1192.0,\n",
              " 'latitude': -5.879993833884067,\n",
              " 'longitude': 35.15198731008472,\n",
              " 'num_private': 1.0,\n",
              " 'population': 319.22367730422}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6T_1OD_tGxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e356497a-5b84-48d4-918e-107935065007"
      },
      "source": [
        "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
        "df['a'] = pd.Series(np.where(df['a'] < 2, -10, df['a']))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-10</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    a  b  c\n",
              "0 -10  4  7\n",
              "1   2  5  8\n",
              "2   3  6  9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQv-vW5CX5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate mean latitude, longitude, gps height, and population within each district code and basin\n",
        "\n",
        "# def replace_by_location(X):\n",
        "#   X = X.copy()\n",
        "#   grouped_by_region = X.groupby(['district_code', 'basin'])\n",
        "#   for feature in ['latitude', 'longitude', 'gps_height', 'population']:\n",
        "#     X[feature] = replacement_config[feature][1](X[feature])\n",
        "#     means_by_region = grouped_by_region[feature].mean()\n",
        "#     for (code, basin), avg in zip(means_by_region.index, means_by_region.values):\n",
        "#       mask = ((X['district_code'] == code) & \n",
        "#               (X['basin'] == basin) & \n",
        "#               (X.apply(lambda x: np.isnan(x[feature]), axis=1)))\n",
        "#       print('-' * 20)\n",
        "#       print(((X['district_code'] == code) & (X['basin'] == basin)).sum())\n",
        "#       print(mask.sum())\n",
        "#       X[feature] = pd.Series(np.where(mask, avg, X[feature]))\n",
        "#   return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwasngx9I8au",
        "colab_type": "text"
      },
      "source": [
        "### Data Wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysm9XSkDuLZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_means_by_region(X, features=['latitude', 'longitude', 'gps_height', 'population']):\n",
        "  X = X.copy()\n",
        "  grouped_by_region = X.groupby(['district_code', 'basin'])\n",
        "  regional_features = {}\n",
        "  for feature in features:\n",
        "    regional_features[feature] = {}\n",
        "    X[feature] = replacement_config[feature][1](X[feature])\n",
        "    means_by_region = grouped_by_region[feature].mean()\n",
        "    regional_means = {}\n",
        "    for (code, basin), avg in zip(means_by_region.index, means_by_region.values):\n",
        "      if np.isnan(avg):\n",
        "        avg = replacements[feature] # improve by getting avg by district code\n",
        "      regional_means[f'{code}-{basin}'] = avg\n",
        "    regional_features[feature] = regional_means\n",
        "      # mask = ((X['district_code'] == code) & \n",
        "      #         (X['basin'] == basin) & \n",
        "      #         (X.apply(lambda x: np.isnan(x[feature]), axis=1)))\n",
        "      # X[feature] = pd.Series(np.where(mask, avg, X[feature]))\n",
        "  return regional_features\n",
        "\n",
        "def replace_by_location(X, features=['latitude', 'longitude', 'gps_height', 'population']):\n",
        "  X = X.copy()\n",
        "  for feature in features:\n",
        "    for k, avg in regional_features[feature].items():\n",
        "      code, basin = k.split('-')\n",
        "      code = float(code)\n",
        "      mask = ((X['district_code'] == code) & \n",
        "              (X['basin'] == basin) & \n",
        "              (X.apply(lambda x: np.isnan(x[feature]), axis=1)))\n",
        "      X[feature] = pd.Series(np.where(mask, avg, X[feature]))\n",
        "  return X\n",
        "\n",
        "regional_features = get_means_by_region(pd.concat([train, test]))\n",
        "train_clean = replace_by_location(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMEH1hs51JKu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75fb99ae-5820-45f1-9c1f-c457c33003fe"
      },
      "source": [
        "train_clean['longitude'].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u5HPKoctMtI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "646e207f-366a-4143-cbd4-74ae876fa1c8"
      },
      "source": [
        "# determine the average latitude and longitude for all functional water pumps;\n",
        "# used to calculate the distance of a water pump from this point\n",
        "\n",
        "functional_epicenters = {}\n",
        "\n",
        "region_groups = train.groupby(['district_code', 'basin']).mean().index\n",
        "for code, basin in region_groups:\n",
        "  mask = ((train['district_code'] == code) & \n",
        "          (train['basin'] == basin) & \n",
        "          (train['status_group'] == 'functional'))\n",
        "  epicenter = tuple(train[mask][axis].mean() for axis in ('latitude', 'longitude'))\n",
        "  functional_epicenters[f'{code}-{basin}'] = epicenter\n",
        "\n",
        "functional_epicenters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0-Wami / Ruvu': (-6.49484046, 36.61340932),\n",
              " '1-Internal': (-4.257938997119477, 35.18327106226682),\n",
              " '1-Lake Rukwa': (-7.072763199268293, 31.890557895243926),\n",
              " '1-Lake Tanganyika': (-4.035638910502869, 31.211031567241374),\n",
              " '1-Lake Victoria': (-0.9925286880645217, 18.403038800830632),\n",
              " '1-Pangani': (-4.265011984715448, 38.107021013626024),\n",
              " '1-Rufiji': (-7.603974256217497, 35.94432032867611),\n",
              " '1-Ruvuma / Southern Coast': (-10.797426077961626, 38.49029161947243),\n",
              " '1-Wami / Ruvu': (-6.507284747578368, 37.961556794717794),\n",
              " '13-Rufiji': (-8.426247647826084, 39.117544284782596),\n",
              " '13-Ruvuma / Southern Coast': (-8.96267593895834, 39.22224717302081),\n",
              " '2-Internal': (-4.258641330707071, 34.81101356656565),\n",
              " '2-Lake Nyasa': (-9.887927225381524, 34.884559370562236),\n",
              " '2-Lake Rukwa': (-8.682244059576915, 32.67345967065384),\n",
              " '2-Lake Tanganyika': (-5.056670504038709, 30.287101401187105),\n",
              " '2-Lake Victoria': (-2.058765973903471, 31.560747006308222),\n",
              " '2-Pangani': (-3.763536821642553, 37.24045389993195),\n",
              " '2-Rufiji': (-8.485350519144045, 34.893918609645056),\n",
              " '2-Ruvuma / Southern Coast': (-10.748919921196165, 35.50615157665071),\n",
              " '2-Wami / Ruvu': (-6.927903590178128, 38.65697313683206),\n",
              " '23-Ruvuma / Southern Coast': (-10.102401186787876, 39.46229404903031),\n",
              " '3-Internal': (-4.28788079297153, 34.26522626475091),\n",
              " '3-Lake Nyasa': (-9.837608401311474, 34.25635032352886),\n",
              " '3-Lake Rukwa': (-7.637381150100001, 31.240591669300002),\n",
              " '3-Lake Tanganyika': (-4.611768388219372, 31.511939193703668),\n",
              " '3-Lake Victoria': (-2.5588608809223294, 32.67773849655343),\n",
              " '3-Pangani': (-4.456720804427996, 38.03160829915209),\n",
              " '3-Rufiji': (-8.166965338700479, 36.23556747713151),\n",
              " '3-Ruvuma / Southern Coast': (-10.87973771299146, 35.84800317316238),\n",
              " '3-Wami / Ruvu': (-6.449633752795035, 37.54504654537269),\n",
              " '30-Internal': (-3.3804529559493677, 35.6627484970886),\n",
              " '30-Lake Tanganyika': (-2.8704486796000004, 30.768428742),\n",
              " '30-Lake Victoria': (-2.5973183039080445, 30.638009130459746),\n",
              " '33-Rufiji': (-7.34043448375, 38.7594888575),\n",
              " '33-Ruvuma / Southern Coast': (-10.769790830526313, 39.113732918552614),\n",
              " '33-Wami / Ruvu': (-7.163674006764705, 38.86373446617647),\n",
              " '4-Internal': (-4.887277293284672, 34.99771021708031),\n",
              " '4-Lake Nyasa': (-9.364133507586208, 34.11347700437666),\n",
              " '4-Lake Rukwa': (-7.979308967083331, 31.645083108750004),\n",
              " '4-Lake Tanganyika': (-4.3200597231468505, 31.623234672867135),\n",
              " '4-Lake Victoria': (-2.709210151190105, 33.10477139846984),\n",
              " '4-Pangani': (-3.497350231934066, 37.455234210439535),\n",
              " '4-Rufiji': (-8.906623872683166, 35.268011553910554),\n",
              " '4-Ruvuma / Southern Coast': (-10.730578956722693, 38.01244280689075),\n",
              " '4-Wami / Ruvu': (-6.323485850208335, 37.039584141354176),\n",
              " '43-Rufiji': (-7.34216788, 38.98771749375),\n",
              " '43-Ruvuma / Southern Coast': (-9.836140894871793, 38.06273948564103),\n",
              " '43-Wami / Ruvu': (-7.060353671566264, 39.25803222138554),\n",
              " '5-Internal': (-3.615245145781252, 35.722323651171884),\n",
              " '5-Lake Nyasa': (-9.884048200457793, 34.56793057340482),\n",
              " '5-Lake Rukwa': (-6.848071609999999, 33.35616089166667),\n",
              " '5-Lake Tanganyika': (-3.682285895084269, 32.11996430095508),\n",
              " '5-Lake Victoria': (-2.4885680460512813, 32.80448211025641),\n",
              " '5-Pangani': (-3.5320818805374588, 37.378588229462494),\n",
              " '5-Rufiji': (-10.194904302285716, 35.960128922571435),\n",
              " '5-Ruvuma / Southern Coast': (-10.73163383019512, 37.44689558956096),\n",
              " '5-Wami / Ruvu': (-6.385186562279411, 36.81417926330882),\n",
              " '53-Rufiji': (-7.857561830606064, 38.801611641717166),\n",
              " '53-Ruvuma / Southern Coast': (-10.045692199807691, 38.95024924442308),\n",
              " '6-Internal': (-3.8280973420075055, 35.50935254848031),\n",
              " '6-Lake Nyasa': (-9.254543428372097, 33.016405977093015),\n",
              " '6-Lake Rukwa': (-9.009110815879119, 32.87577671013736),\n",
              " '6-Lake Tanganyika': (-2.4020838023076907, 15.6964942717094),\n",
              " '6-Lake Victoria': (-1.1293749394326267, 17.367241425650118),\n",
              " '6-Pangani': (-4.716038205925927, 37.95979028143518),\n",
              " '6-Rufiji': (-7.170724593928573, 37.89698049857143),\n",
              " '6-Wami / Ruvu': (-6.397862632777776, 37.488483409930545),\n",
              " '60-Rufiji': (-7.922825364313724, 39.67881483784314),\n",
              " '62-Ruvuma / Southern Coast': (-10.00859080210526, 39.60749074017545),\n",
              " '63-Rufiji': (-7.852384610500001, 39.801169852499996),\n",
              " '63-Ruvuma / Southern Coast': (-11.006793887142855, 38.47994390642856),\n",
              " '67-Rufiji': (-7.971441876, 39.74001064),\n",
              " '7-Internal': (-3.2977501548113213, 35.74707109830188),\n",
              " '7-Lake Victoria': (-2.3514794950378795, 32.57651393795455),\n",
              " '7-Pangani': (-3.330267624194284, 36.973365798731436),\n",
              " '7-Rufiji': (-8.379773866654059, 34.91054222060494),\n",
              " '7-Wami / Ruvu': (-5.496904376428572, 37.414944915),\n",
              " '8-Internal': (-3.581885001839079, 33.65919278086207),\n",
              " '8-Lake Tanganyika': (-2.9529620814285713, 31.614346175714292),\n",
              " '8-Lake Victoria': (-2.6014498136413042, 32.125733043749996),\n",
              " '8-Pangani': (-4.816163590625002, 38.89996710035715),\n",
              " '80-Internal': (-3.9552611433333333, 34.01495585)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLH00H6Ou_F6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from geopy.distance import great_circle\n",
        "\n",
        "def mean_district_epicenter(district):\n",
        "  lat, lon, n = 0, 0, 0\n",
        "  for k, coord in functional_epicenters.items():\n",
        "    if int(k.split('-')[0]) == district:\n",
        "      lat += coord[0]\n",
        "      lon += coord[1]\n",
        "      n += 1\n",
        "  if n == 0:\n",
        "    print(district)\n",
        "    return (replacements['latitude'], replacements['longitude'])\n",
        "  final_lat = lat / n\n",
        "  final_lon = lon / n\n",
        "  if abs(final_lat) > 90 or abs(final_lon) > 90:\n",
        "    print(f'Woops: {final_lat} {final_lon}')\n",
        "  return (final_lat, final_lon)\n",
        "\n",
        "def coords_to_dist(row):\n",
        "  '''\n",
        "  Returns distance between coordinate and center of functional water pumps\n",
        "  for that region.\n",
        "  '''\n",
        "  code = int(row['district_code'])\n",
        "  region = row['region']\n",
        "  try:\n",
        "    epicenter = functional_epicenters['{:.0f}-{}'.format(code, region)]\n",
        "  except:\n",
        "    epicenter = mean_district_epicenter(code)\n",
        "  latitude = row['latitude']\n",
        "  longitude = row['longitude']\n",
        "  print(f'{latitude} {longitude}')\n",
        "  return great_circle((latitude, longitude), epicenter).miles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqH5LLPw3fYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2aa1c2dc-41d5-4617-cfef-947dd5f6597c"
      },
      "source": [
        "test['district_code'].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj6xUf6N9KaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98c27901-9d60-4740-9b99-b62fba1a6dea"
      },
      "source": [
        "train_raw.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47520, 41)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbJhzs6q8Ang",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "546d94e5-5fef-45e6-9c91-f8f99bd50ea7"
      },
      "source": [
        "result['latitude'].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47110"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6q4XF-z2wN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e177c88-d265-4e3e-a6c9-74c68515fcaf"
      },
      "source": [
        "# result.apply(coords_to_dist, axis=1)\n",
        "result = replace_by_location(train_raw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "19\n",
            "4\n",
            "--------------------\n",
            "1744\n",
            "660\n",
            "--------------------\n",
            "527\n",
            "254\n",
            "--------------------\n",
            "1208\n",
            "693\n",
            "--------------------\n",
            "2031\n",
            "1354\n",
            "--------------------\n",
            "941\n",
            "660\n",
            "--------------------\n",
            "951\n",
            "744\n",
            "--------------------\n",
            "658\n",
            "515\n",
            "--------------------\n",
            "1712\n",
            "1431\n",
            "--------------------\n",
            "1653\n",
            "1398\n",
            "--------------------\n",
            "326\n",
            "277\n",
            "--------------------\n",
            "446\n",
            "396\n",
            "--------------------\n",
            "1072\n",
            "952\n",
            "--------------------\n",
            "1961\n",
            "1751\n",
            "--------------------\n",
            "1585\n",
            "1399\n",
            "--------------------\n",
            "574\n",
            "506\n",
            "--------------------\n",
            "277\n",
            "242\n",
            "--------------------\n",
            "1023\n",
            "938\n",
            "--------------------\n",
            "850\n",
            "788\n",
            "--------------------\n",
            "1590\n",
            "1453\n",
            "--------------------\n",
            "180\n",
            "163\n",
            "--------------------\n",
            "1449\n",
            "1351\n",
            "--------------------\n",
            "1018\n",
            "941\n",
            "--------------------\n",
            "1041\n",
            "960\n",
            "--------------------\n",
            "969\n",
            "895\n",
            "--------------------\n",
            "388\n",
            "354\n",
            "--------------------\n",
            "534\n",
            "497\n",
            "--------------------\n",
            "184\n",
            "171\n",
            "--------------------\n",
            "1312\n",
            "1238\n",
            "--------------------\n",
            "58\n",
            "55\n",
            "--------------------\n",
            "703\n",
            "667\n",
            "--------------------\n",
            "910\n",
            "856\n",
            "--------------------\n",
            "1287\n",
            "1228\n",
            "--------------------\n",
            "2303\n",
            "2162\n",
            "--------------------\n",
            "269\n",
            "245\n",
            "--------------------\n",
            "210\n",
            "194\n",
            "--------------------\n",
            "262\n",
            "250\n",
            "--------------------\n",
            "744\n",
            "688\n",
            "--------------------\n",
            "15\n",
            "14\n",
            "--------------------\n",
            "525\n",
            "501\n",
            "--------------------\n",
            "291\n",
            "274\n",
            "--------------------\n",
            "756\n",
            "731\n",
            "--------------------\n",
            "246\n",
            "232\n",
            "--------------------\n",
            "314\n",
            "301\n",
            "--------------------\n",
            "326\n",
            "314\n",
            "--------------------\n",
            "655\n",
            "625\n",
            "--------------------\n",
            "103\n",
            "99\n",
            "--------------------\n",
            "724\n",
            "699\n",
            "--------------------\n",
            "205\n",
            "196\n",
            "--------------------\n",
            "671\n",
            "653\n",
            "--------------------\n",
            "291\n",
            "279\n",
            "--------------------\n",
            "33\n",
            "32\n",
            "--------------------\n",
            "558\n",
            "539\n",
            "--------------------\n",
            "334\n",
            "321\n",
            "--------------------\n",
            "486\n",
            "473\n",
            "--------------------\n",
            "1037\n",
            "999\n",
            "--------------------\n",
            "772\n",
            "733\n",
            "--------------------\n",
            "62\n",
            "59\n",
            "--------------------\n",
            "300\n",
            "289\n",
            "--------------------\n",
            "5\n",
            "3\n",
            "--------------------\n",
            "283\n",
            "276\n",
            "--------------------\n",
            "235\n",
            "228\n",
            "--------------------\n",
            "72\n",
            "70\n",
            "--------------------\n",
            "237\n",
            "230\n",
            "--------------------\n",
            "225\n",
            "218\n",
            "--------------------\n",
            "262\n",
            "255\n",
            "--------------------\n",
            "27\n",
            "27\n",
            "--------------------\n",
            "486\n",
            "477\n",
            "--------------------\n",
            "11\n",
            "11\n",
            "--------------------\n",
            "613\n",
            "604\n",
            "--------------------\n",
            "83\n",
            "80\n",
            "--------------------\n",
            "41\n",
            "40\n",
            "--------------------\n",
            "123\n",
            "119\n",
            "--------------------\n",
            "246\n",
            "242\n",
            "--------------------\n",
            "359\n",
            "355\n",
            "--------------------\n",
            "232\n",
            "228\n",
            "--------------------\n",
            "48\n",
            "48\n",
            "--------------------\n",
            "85\n",
            "84\n",
            "--------------------\n",
            "28\n",
            "28\n",
            "--------------------\n",
            "130\n",
            "130\n",
            "--------------------\n",
            "5\n",
            "5\n",
            "--------------------\n",
            "11\n",
            "11\n",
            "--------------------\n",
            "19\n",
            "4\n",
            "--------------------\n",
            "1744\n",
            "660\n",
            "--------------------\n",
            "527\n",
            "254\n",
            "--------------------\n",
            "1208\n",
            "693\n",
            "--------------------\n",
            "2031\n",
            "1354\n",
            "--------------------\n",
            "941\n",
            "660\n",
            "--------------------\n",
            "951\n",
            "744\n",
            "--------------------\n",
            "658\n",
            "515\n",
            "--------------------\n",
            "1712\n",
            "1431\n",
            "--------------------\n",
            "1653\n",
            "1398\n",
            "--------------------\n",
            "326\n",
            "277\n",
            "--------------------\n",
            "446\n",
            "396\n",
            "--------------------\n",
            "1072\n",
            "952\n",
            "--------------------\n",
            "1961\n",
            "1751\n",
            "--------------------\n",
            "1585\n",
            "1399\n",
            "--------------------\n",
            "574\n",
            "506\n",
            "--------------------\n",
            "277\n",
            "242\n",
            "--------------------\n",
            "1023\n",
            "938\n",
            "--------------------\n",
            "850\n",
            "788\n",
            "--------------------\n",
            "1590\n",
            "1453\n",
            "--------------------\n",
            "180\n",
            "163\n",
            "--------------------\n",
            "1449\n",
            "1351\n",
            "--------------------\n",
            "1018\n",
            "941\n",
            "--------------------\n",
            "1041\n",
            "960\n",
            "--------------------\n",
            "969\n",
            "895\n",
            "--------------------\n",
            "388\n",
            "354\n",
            "--------------------\n",
            "534\n",
            "497\n",
            "--------------------\n",
            "184\n",
            "171\n",
            "--------------------\n",
            "1312\n",
            "1238\n",
            "--------------------\n",
            "58\n",
            "55\n",
            "--------------------\n",
            "703\n",
            "667\n",
            "--------------------\n",
            "910\n",
            "856\n",
            "--------------------\n",
            "1287\n",
            "1228\n",
            "--------------------\n",
            "2303\n",
            "2162\n",
            "--------------------\n",
            "269\n",
            "245\n",
            "--------------------\n",
            "210\n",
            "194\n",
            "--------------------\n",
            "262\n",
            "250\n",
            "--------------------\n",
            "744\n",
            "688\n",
            "--------------------\n",
            "15\n",
            "14\n",
            "--------------------\n",
            "525\n",
            "501\n",
            "--------------------\n",
            "291\n",
            "274\n",
            "--------------------\n",
            "756\n",
            "731\n",
            "--------------------\n",
            "246\n",
            "232\n",
            "--------------------\n",
            "314\n",
            "301\n",
            "--------------------\n",
            "326\n",
            "314\n",
            "--------------------\n",
            "655\n",
            "625\n",
            "--------------------\n",
            "103\n",
            "99\n",
            "--------------------\n",
            "724\n",
            "699\n",
            "--------------------\n",
            "205\n",
            "196\n",
            "--------------------\n",
            "671\n",
            "653\n",
            "--------------------\n",
            "291\n",
            "279\n",
            "--------------------\n",
            "33\n",
            "32\n",
            "--------------------\n",
            "558\n",
            "539\n",
            "--------------------\n",
            "334\n",
            "321\n",
            "--------------------\n",
            "486\n",
            "473\n",
            "--------------------\n",
            "1037\n",
            "999\n",
            "--------------------\n",
            "772\n",
            "733\n",
            "--------------------\n",
            "62\n",
            "59\n",
            "--------------------\n",
            "300\n",
            "289\n",
            "--------------------\n",
            "5\n",
            "3\n",
            "--------------------\n",
            "283\n",
            "276\n",
            "--------------------\n",
            "235\n",
            "228\n",
            "--------------------\n",
            "72\n",
            "70\n",
            "--------------------\n",
            "237\n",
            "230\n",
            "--------------------\n",
            "225\n",
            "218\n",
            "--------------------\n",
            "262\n",
            "255\n",
            "--------------------\n",
            "27\n",
            "27\n",
            "--------------------\n",
            "486\n",
            "477\n",
            "--------------------\n",
            "11\n",
            "11\n",
            "--------------------\n",
            "613\n",
            "604\n",
            "--------------------\n",
            "83\n",
            "80\n",
            "--------------------\n",
            "41\n",
            "40\n",
            "--------------------\n",
            "123\n",
            "119\n",
            "--------------------\n",
            "246\n",
            "242\n",
            "--------------------\n",
            "359\n",
            "355\n",
            "--------------------\n",
            "232\n",
            "228\n",
            "--------------------\n",
            "48\n",
            "48\n",
            "--------------------\n",
            "85\n",
            "84\n",
            "--------------------\n",
            "28\n",
            "28\n",
            "--------------------\n",
            "130\n",
            "130\n",
            "--------------------\n",
            "5\n",
            "5\n",
            "--------------------\n",
            "11\n",
            "11\n",
            "--------------------\n",
            "19\n",
            "12\n",
            "--------------------\n",
            "1744\n",
            "997\n",
            "--------------------\n",
            "527\n",
            "329\n",
            "--------------------\n",
            "1208\n",
            "853\n",
            "--------------------\n",
            "2031\n",
            "1566\n",
            "--------------------\n",
            "941\n",
            "738\n",
            "--------------------\n",
            "951\n",
            "796\n",
            "--------------------\n",
            "658\n",
            "554\n",
            "--------------------\n",
            "1712\n",
            "1491\n",
            "--------------------\n",
            "1653\n",
            "1437\n",
            "--------------------\n",
            "326\n",
            "282\n",
            "--------------------\n",
            "446\n",
            "397\n",
            "--------------------\n",
            "1072\n",
            "968\n",
            "--------------------\n",
            "1961\n",
            "1778\n",
            "--------------------\n",
            "1585\n",
            "1418\n",
            "--------------------\n",
            "574\n",
            "509\n",
            "--------------------\n",
            "277\n",
            "244\n",
            "--------------------\n",
            "1023\n",
            "942\n",
            "--------------------\n",
            "850\n",
            "792\n",
            "--------------------\n",
            "1590\n",
            "1458\n",
            "--------------------\n",
            "180\n",
            "163\n",
            "--------------------\n",
            "1449\n",
            "1353\n",
            "--------------------\n",
            "1018\n",
            "941\n",
            "--------------------\n",
            "1041\n",
            "961\n",
            "--------------------\n",
            "969\n",
            "895\n",
            "--------------------\n",
            "388\n",
            "354\n",
            "--------------------\n",
            "534\n",
            "497\n",
            "--------------------\n",
            "184\n",
            "171\n",
            "--------------------\n",
            "1312\n",
            "1238\n",
            "--------------------\n",
            "58\n",
            "55\n",
            "--------------------\n",
            "703\n",
            "669\n",
            "--------------------\n",
            "910\n",
            "856\n",
            "--------------------\n",
            "1287\n",
            "1228\n",
            "--------------------\n",
            "2303\n",
            "2162\n",
            "--------------------\n",
            "269\n",
            "245\n",
            "--------------------\n",
            "210\n",
            "194\n",
            "--------------------\n",
            "262\n",
            "250\n",
            "--------------------\n",
            "744\n",
            "688\n",
            "--------------------\n",
            "15\n",
            "14\n",
            "--------------------\n",
            "525\n",
            "501\n",
            "--------------------\n",
            "291\n",
            "274\n",
            "--------------------\n",
            "756\n",
            "731\n",
            "--------------------\n",
            "246\n",
            "232\n",
            "--------------------\n",
            "314\n",
            "301\n",
            "--------------------\n",
            "326\n",
            "314\n",
            "--------------------\n",
            "655\n",
            "625\n",
            "--------------------\n",
            "103\n",
            "99\n",
            "--------------------\n",
            "724\n",
            "699\n",
            "--------------------\n",
            "205\n",
            "196\n",
            "--------------------\n",
            "671\n",
            "653\n",
            "--------------------\n",
            "291\n",
            "279\n",
            "--------------------\n",
            "33\n",
            "32\n",
            "--------------------\n",
            "558\n",
            "539\n",
            "--------------------\n",
            "334\n",
            "321\n",
            "--------------------\n",
            "486\n",
            "473\n",
            "--------------------\n",
            "1037\n",
            "999\n",
            "--------------------\n",
            "772\n",
            "733\n",
            "--------------------\n",
            "62\n",
            "59\n",
            "--------------------\n",
            "300\n",
            "289\n",
            "--------------------\n",
            "5\n",
            "3\n",
            "--------------------\n",
            "283\n",
            "276\n",
            "--------------------\n",
            "235\n",
            "228\n",
            "--------------------\n",
            "72\n",
            "70\n",
            "--------------------\n",
            "237\n",
            "230\n",
            "--------------------\n",
            "225\n",
            "218\n",
            "--------------------\n",
            "262\n",
            "255\n",
            "--------------------\n",
            "27\n",
            "27\n",
            "--------------------\n",
            "486\n",
            "477\n",
            "--------------------\n",
            "11\n",
            "11\n",
            "--------------------\n",
            "613\n",
            "604\n",
            "--------------------\n",
            "83\n",
            "80\n",
            "--------------------\n",
            "41\n",
            "40\n",
            "--------------------\n",
            "123\n",
            "119\n",
            "--------------------\n",
            "246\n",
            "242\n",
            "--------------------\n",
            "359\n",
            "355\n",
            "--------------------\n",
            "232\n",
            "228\n",
            "--------------------\n",
            "48\n",
            "48\n",
            "--------------------\n",
            "85\n",
            "84\n",
            "--------------------\n",
            "28\n",
            "28\n",
            "--------------------\n",
            "130\n",
            "130\n",
            "--------------------\n",
            "5\n",
            "5\n",
            "--------------------\n",
            "11\n",
            "11\n",
            "--------------------\n",
            "19\n",
            "13\n",
            "--------------------\n",
            "1744\n",
            "1152\n",
            "--------------------\n",
            "527\n",
            "365\n",
            "--------------------\n",
            "1208\n",
            "904\n",
            "--------------------\n",
            "2031\n",
            "1629\n",
            "--------------------\n",
            "941\n",
            "760\n",
            "--------------------\n",
            "951\n",
            "813\n",
            "--------------------\n",
            "658\n",
            "559\n",
            "--------------------\n",
            "1712\n",
            "1517\n",
            "--------------------\n",
            "1653\n",
            "1453\n",
            "--------------------\n",
            "326\n",
            "285\n",
            "--------------------\n",
            "446\n",
            "402\n",
            "--------------------\n",
            "1072\n",
            "975\n",
            "--------------------\n",
            "1961\n",
            "1786\n",
            "--------------------\n",
            "1585\n",
            "1422\n",
            "--------------------\n",
            "574\n",
            "512\n",
            "--------------------\n",
            "277\n",
            "244\n",
            "--------------------\n",
            "1023\n",
            "942\n",
            "--------------------\n",
            "850\n",
            "792\n",
            "--------------------\n",
            "1590\n",
            "1460\n",
            "--------------------\n",
            "180\n",
            "163\n",
            "--------------------\n",
            "1449\n",
            "1352\n",
            "--------------------\n",
            "1018\n",
            "941\n",
            "--------------------\n",
            "1041\n",
            "961\n",
            "--------------------\n",
            "969\n",
            "895\n",
            "--------------------\n",
            "388\n",
            "354\n",
            "--------------------\n",
            "534\n",
            "497\n",
            "--------------------\n",
            "184\n",
            "171\n",
            "--------------------\n",
            "1312\n",
            "1238\n",
            "--------------------\n",
            "58\n",
            "55\n",
            "--------------------\n",
            "703\n",
            "668\n",
            "--------------------\n",
            "910\n",
            "856\n",
            "--------------------\n",
            "1287\n",
            "1228\n",
            "--------------------\n",
            "2303\n",
            "2162\n",
            "--------------------\n",
            "269\n",
            "245\n",
            "--------------------\n",
            "210\n",
            "194\n",
            "--------------------\n",
            "262\n",
            "250\n",
            "--------------------\n",
            "744\n",
            "688\n",
            "--------------------\n",
            "15\n",
            "14\n",
            "--------------------\n",
            "525\n",
            "501\n",
            "--------------------\n",
            "291\n",
            "274\n",
            "--------------------\n",
            "756\n",
            "731\n",
            "--------------------\n",
            "246\n",
            "232\n",
            "--------------------\n",
            "314\n",
            "301\n",
            "--------------------\n",
            "326\n",
            "314\n",
            "--------------------\n",
            "655\n",
            "625\n",
            "--------------------\n",
            "103\n",
            "99\n",
            "--------------------\n",
            "724\n",
            "699\n",
            "--------------------\n",
            "205\n",
            "196\n",
            "--------------------\n",
            "671\n",
            "653\n",
            "--------------------\n",
            "291\n",
            "279\n",
            "--------------------\n",
            "33\n",
            "32\n",
            "--------------------\n",
            "558\n",
            "539\n",
            "--------------------\n",
            "334\n",
            "321\n",
            "--------------------\n",
            "486\n",
            "473\n",
            "--------------------\n",
            "1037\n",
            "999\n",
            "--------------------\n",
            "772\n",
            "733\n",
            "--------------------\n",
            "62\n",
            "59\n",
            "--------------------\n",
            "300\n",
            "289\n",
            "--------------------\n",
            "5\n",
            "3\n",
            "--------------------\n",
            "283\n",
            "276\n",
            "--------------------\n",
            "235\n",
            "228\n",
            "--------------------\n",
            "72\n",
            "70\n",
            "--------------------\n",
            "237\n",
            "230\n",
            "--------------------\n",
            "225\n",
            "218\n",
            "--------------------\n",
            "262\n",
            "255\n",
            "--------------------\n",
            "27\n",
            "27\n",
            "--------------------\n",
            "486\n",
            "477\n",
            "--------------------\n",
            "11\n",
            "11\n",
            "--------------------\n",
            "613\n",
            "604\n",
            "--------------------\n",
            "83\n",
            "80\n",
            "--------------------\n",
            "41\n",
            "40\n",
            "--------------------\n",
            "123\n",
            "119\n",
            "--------------------\n",
            "246\n",
            "242\n",
            "--------------------\n",
            "359\n",
            "355\n",
            "--------------------\n",
            "232\n",
            "228\n",
            "--------------------\n",
            "48\n",
            "48\n",
            "--------------------\n",
            "85\n",
            "84\n",
            "--------------------\n",
            "28\n",
            "28\n",
            "--------------------\n",
            "130\n",
            "130\n",
            "--------------------\n",
            "5\n",
            "5\n",
            "--------------------\n",
            "11\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CWNDMssvPy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace(X, feature):\n",
        "  '''\n",
        "  Replaces feature in X with replacement value.\n",
        "  '''\n",
        "  filter = replacement_config[feature][1]\n",
        "  X[feature] = filter(X[feature])\n",
        "  X[feature] = X[feature].replace(np.nan, replacements[feature])\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGNQP7N1IvM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrangle(X):\n",
        "  X = X.copy()\n",
        "\n",
        "  # Engineer feature: \n",
        "  # X['populated'] = pd.Series(np.where(X['population'] <= 250, 0, 1))\n",
        "\n",
        "  # Engineer feature:\n",
        "  # X['extraction_type_binary'] = pd.Series(np.where(X['extraction_type'] == 'other', 0, 1))\n",
        "\n",
        "  # replace non-sense values in numeric columns with guesses\n",
        "  no_replacements = ['latitude', 'longitude', 'gps_height', 'population']\n",
        "  for feature in [replacement for replacement in replacements if replacement not in no_replacements]:\n",
        "    X = replace(X, feature)\n",
        "\n",
        "  X = replace_by_location(X)  \n",
        "\n",
        "  # replace NaN values in categorical features with \"Unknown\"\n",
        "  nan_cols = ['funder', 'installer', 'subvillage', 'public_meeting', \n",
        "              'scheme_management', 'scheme_name', 'permit']\n",
        "\n",
        "  for feature in nan_cols:\n",
        "    X[feature] = X[feature].replace(np.nan, 'Unknown')\n",
        "  \n",
        "  # drop duplicate columns\n",
        "  duplicate_cols = ['quantity_group', 'extraction_type_group',\n",
        "                    'extraction_type_class', 'payment_type',\n",
        "                    'source_type', 'waterpoint_type_group']\n",
        "  X = X.drop(columns=duplicate_cols)\n",
        "\n",
        "  # drop columns meant for book-keeping\n",
        "  book_keeping_cols = ['id', 'recorded_by']\n",
        "  X = X.drop(columns=book_keeping_cols)\n",
        "\n",
        "  # Convert date_recorded to datetime\n",
        "  X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "\n",
        "  # Extract components from date_recorded, then drop the original column\n",
        "  X['year_recorded'] = X['date_recorded'].dt.year\n",
        "  X['month_recorded'] = X['date_recorded'].dt.month\n",
        "  X['day_recorded'] = X['date_recorded'].dt.day\n",
        "  X = X.drop(columns='date_recorded')\n",
        "\n",
        "  # Engineer feature: how many years from construction_year to date_recorded\n",
        "  X['years'] = X['year_recorded'] - X['construction_year']\n",
        "  # X['years'] = pd.Series(np.where(X['years'] > 0, X['years'], 1))\n",
        "\n",
        "  # Engineer feature: geographic center of functional water pumps\n",
        "  X['miles_from_functional_epicenter'] = X.apply(coords_to_dist, axis=1)\n",
        "\n",
        "  # Engineer feature: boolean features to binary\n",
        "  boolean_features = ['permit']\n",
        "  for feature in boolean_features:\n",
        "      X[feature] = pd.Series(np.where(X[feature], 1, 0))\n",
        "\n",
        "  X['government_funded'] = pd.Series(np.where(X['funder'] == 'Government of Tanzania', 1, 0))\n",
        "\n",
        "  X['source'] = pd.Series(np.where(X['source'] == 'other', 'unknown', X['source']))\n",
        "\n",
        "  # Inspired Feature Engineering:\n",
        "\n",
        "  # 1. pop/year\n",
        "\n",
        "  # X['pop/year'] = X['population'] / X['years']\n",
        "\n",
        "  # 2. water/person\n",
        "\n",
        "  # X['water/person'] = X['amount_tsh'] / X['population']\n",
        "\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSc8tWierQ4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "0cf4eb38-dbb3-40bf-9129-00ecacb3cb30"
      },
      "source": [
        "train_clean, val_clean, test_clean = [wrangle for df in (train_raw, val_raw, test)]\n",
        "\n",
        "assert_initial_shape(train_clean, val_clean, test_clean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "660\n",
            "254\n",
            "693\n",
            "1354\n",
            "660\n",
            "744\n",
            "515\n",
            "1431\n",
            "1398\n",
            "277\n",
            "396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-fc123b4573cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0massert_initial_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-9bc4587b0b36>\u001b[0m in \u001b[0;36mwrangle\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace_by_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# replace NaN values in categorical features with \"Unknown\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-5967984b8ac6>\u001b[0m in \u001b[0;36mreplace_by_location\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     10\u001b[0m       mask = ((X['district_code'] == code) & \n\u001b[1;32m     11\u001b[0m                   \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'basin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbasin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                   (X.apply(lambda x: np.isnan(x[feature]), axis=1)))\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6877\u001b[0m         )\n\u001b[0;32m-> 6878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6880\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 result = libreduction.compute_reduction(\n\u001b[0;32m--> 296\u001b[0;31m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 )\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-5967984b8ac6>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m       mask = ((X['district_code'] == code) & \n\u001b[1;32m     11\u001b[0m                   \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'basin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbasin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                   (X.apply(lambda x: np.isnan(x[feature]), axis=1)))\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4398\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4400\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4401\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66rklTfTj4pk",
        "colab_type": "text"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-F494ssj6No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = train_clean.drop(columns=[target])\n",
        "\n",
        "# Get a list of the numeric features\n",
        "numeric_features = train_features.select_dtypes(\n",
        "    include='number').columns.tolist()\n",
        "\n",
        "# Get a series with the cardinality of the nonnumeric features\n",
        "categorical_features = train_features.select_dtypes(\n",
        "    exclude='number').columns.tolist()\n",
        "\n",
        "features = numeric_features + categorical_features\n",
        "\n",
        "X_train, X_val, X_test = map(lambda df: df[features], (train_clean, val_clean, test_clean))\n",
        "y_train, y_val = map(lambda df: df[target], (train_clean, val_clean))\n",
        "\n",
        "assert_initial_shape(X_train, X_val, X_test)\n",
        "\n",
        "print('Number of columns')\n",
        "for df, name in [(X_train, 'X_train'), (X_val, 'X_val'), (X_test, 'X_test')]:\n",
        "  print(f'{name}: {df.shape[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMIt999tB7NO",
        "colab_type": "text"
      },
      "source": [
        "### Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsK_UPBtB9IU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hin2myShCBg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='mean'), \n",
        "    RandomForestClassifier(random_state=42, \n",
        "                           n_jobs=-1)\n",
        "                          #  max_depth=32, # 30 -  \n",
        "                          #  n_estimators=100), # 100\n",
        ")\n",
        "\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "print('Training Score:', rf.score(X_train, y_train))\n",
        "print('Validation Score:', accuracy_score(y_val, rf.predict(X_val)))\n",
        "# Top score: 0.8035353535353535\n",
        "\n",
        "# Current score: 0.7974747474747474"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWIm49eJdll6",
        "colab_type": "text"
      },
      "source": [
        "### Encoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbLJkB7Cd2Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import category_encoders as ce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDgNYCLfdnpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "\n",
        "def encode(encoder, X_train, X_val, X_test, features, target, y_train=None):\n",
        "  if y_train is None:\n",
        "    X_train = encoder.fit_transform(X_train, y_train)\n",
        "    X_val = encoder.transform(X_val)\n",
        "    X_test = encoder.transform(X_test)\n",
        "    return X_train, X_val, X_test\n",
        "  else:\n",
        "    target_vectors = [[1.0 if x == name else 0.0 for x in y_train] for name in y_train.value_counts().index.tolist()]\n",
        "    for target_vector in target_vectors:\n",
        "        X_train = encoder.fit_transform(X_train, target_vector)\n",
        "        X_val = encoder.transform(X_val)\n",
        "        X_test = encoder.transform(X_test)\n",
        "    return X_train, X_val, X_test\n",
        "\n",
        "cat_boost_encoded_features = ['funder']\n",
        "hash_encoded_features = ['scheme_management']\n",
        "target_encoded_features = ['management']\n",
        "\n",
        "encoders = [ce.cat_boost.CatBoostEncoder(cols=cat_boost_encoded_features, random_state=42), \n",
        "            ce.hashing.HashingEncoder(cols=hash_encoded_features), \n",
        "            ce.target_encoder.TargetEncoder(cols=target_encoded_features, \n",
        "                                            min_samples_leaf=100,\n",
        "                                            smoothing=10)]\n",
        "encoded_features = [cat_boost_encoded_features, hash_encoded_features, target_encoded_features]\n",
        "target_vectors = [y_train, None, y_train]\n",
        "\n",
        "X_train_encoded, X_val_encoded, X_test_encoded = (df.copy() for df in (X_train, X_val, X_test))\n",
        "for encoder, features, target_vector in zip(encoders, encoded_features, target_vectors):\n",
        "  X_train_encoded, X_val_encoded, X_test_encoded = encode(encoder, X_train_encoded, X_val_encoded, X_test_encoded, features, target, target_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NLmuu_ts3ca",
        "colab_type": "text"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-bkG93Fkoz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6igkpN0mAMtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQvW9eY1fw07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rn = make_pipeline(\n",
        "#     SimpleImputer(),\n",
        "#     RadiusNeighborsClassifier()\n",
        "# )\n",
        "\n",
        "# rn.fit(X_train[['latitude', 'longitude']], y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI651k5_rqnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rn = make_pipeline(\n",
        "#     ce.OrdinalEncoder(),\n",
        "#     SimpleImputer(),\n",
        "#     RadiusNeighborsClassifier()\n",
        "# )\n",
        "\n",
        "# lr = make_pipeline(\n",
        "#     ce.OneHotEncoder(use_cat_names=True), \n",
        "#     SimpleImputer(strategy='mean'), \n",
        "#     StandardScaler(),\n",
        "#     SelectKBest(f_regression, k=20) \n",
        "#     LogisticRegressionCV(solver='lbfgs', n_jobs=-1)\n",
        "# )\n",
        "\n",
        "# dt = make_pipeline(\n",
        "#     ce.OrdinalEncoder(),\n",
        "#     SimpleImputer(),\n",
        "#     DecisionTreeClassifier(random_state=42)\n",
        "# )\n",
        "\n",
        "# rf = make_pipeline(\n",
        "#     ce.OrdinalEncoder(), \n",
        "#     SimpleImputer(strategy='mean'), \n",
        "#     RandomForestClassifier(random_state=42, \n",
        "#                            n_jobs=-1)\n",
        "#                           #  max_depth=32, # 30 -  \n",
        "#                           #  n_estimators=100), # 100\n",
        "# )\n",
        "\n",
        "# stack = StackingClassifier(classifiers = [dt, rf], \n",
        "#                            use_probas=True,\n",
        "#                            meta_classifier=lr)\n",
        "\n",
        "# # pipeline.fit(X_train, y_train);\n",
        "# for model, label in zip((dt, rf, stack), ('Decision Tree', 'Random Forest', 'Stack')):\n",
        "#   scores = model_selection.cross_val_score(model, X_train, y_train, cv=10)\n",
        "#   print('F1 Scores: %0.8f (+/- %0.8f) [%s]' % (scores.mean(), scores.std(), label))\n",
        "\n",
        "# # print('Training Score:', pipeline.score(X_train, y_train))\n",
        "# stack.fit(X_train, y_train)\n",
        "\n",
        "# print('Validation Score:', accuracy_score(y_val, stack.predict(X_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djiCjAvJJCnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rf = make_pipeline(\n",
        "#     ce.OrdinalEncoder(), \n",
        "#     SimpleImputer(strategy='mean'), \n",
        "#     RandomForestClassifier(random_state=42, \n",
        "#                            n_jobs=-1) \n",
        "#                           #  max_depth=30, # 30 -  \n",
        "#                           #  n_estimators=1300), # 1300\n",
        "# )\n",
        "\n",
        "# kn = make_pipeline(\n",
        "#     ce.OrdinalEncoder(),\n",
        "#     SimpleImputer(),\n",
        "#     KNeighborsClassifier(n_neighbors=100, \n",
        "#                         #  leaf_size=100,\n",
        "#                          algorithm='brute',\n",
        "#                          n_jobs=-1)\n",
        "# )\n",
        "\n",
        "# rn = make_pipeline(\n",
        "#     ce.OrdinalEncoder(),\n",
        "#     SimpleImputer(),\n",
        "#     RadiusNeighborsClassifier()\n",
        "# )\n",
        "\n",
        "# scores = model_selection.cross_val_score(rf, X_train_encoded, y_train, cv=5, scoring='accuracy')\n",
        "# rf.fit(X_train_encoded, y_train)\n",
        "# print('Training Score:', rf.score(X_train_encoded, y_train))\n",
        "# print('Validation Score:', accuracy_score(y_val, rf.predict(X_val_encoded)))\n",
        "# Top score: 0.8035353535353535\n",
        "\n",
        "# scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXZj-IN0UDeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import validation_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32jduiBsXPyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_scores, val_scores = validation_curve(\n",
        "#     rf, X_train, y_train,\n",
        "#     param_name='randomforestclassifier__max_depth',\n",
        "#     param_range=range(1, 100, 10),\n",
        "#     scoring='accuracy',\n",
        "#     cv=3,\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "\n",
        "# train_scores, val_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXIBlXJia479",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.plot(np.array(range(1,100, 10)), [score[2] for score in val_scores]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgIgL9YebfaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}