{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "222 Random Forests Assignment/Notes.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dondreojordan/DS-Unit-2-Kaggle-Challenge/blob/master/module2-random-forests/LS_DS_222_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCfTSB3O-JDb",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Random Forests\n",
        "\n",
        "## Assignment\n",
        "- [ ] Read [“Adopting a Hypothesis-Driven Workflow”](http://archive.is/Nu3EI), a blog post by a Lambda DS student about the Tanzania Waterpumps challenge.\n",
        "- [ ] Continue to participate in our Kaggle challenge.\n",
        "- [ ] Define a function to wrangle train, validate, and test sets in the same way. Clean outliers and engineer features.\n",
        "- [ ] Try Ordinal Encoding.\n",
        "- [ ] Try a Random Forest Classifier.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Doing\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Do more exploratory data analysis, data cleaning, feature engineering, and feature selection.\n",
        "- [ ] Try other [categorical encodings](https://contrib.scikit-learn.org/category_encoders/).\n",
        "- [ ] Get and plot your feature importances.\n",
        "- [ ] Make visualizations and share on Slack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNM0fLv9-JDg",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "\n",
        "You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab (run the code cell below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzwUew7zB7y4",
        "colab_type": "text"
      },
      "source": [
        "#Import Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDsoW141Amoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqTGXT-TB_q7",
        "colab_type": "text"
      },
      "source": [
        "#Engineer DataFrames Train, Test, and Validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJBD4ruICm1m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fc554372-f277-44d2-90c7-ff1ae147d542"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Merge Train Features and Train Labels\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "\n",
        "#Read test_features and sample_submission\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "#Split train into train and validation\n",
        "train, val = train_test_split(train, train_size=.80, test_size=0.20,\n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "print(\"Check Train Shape: \",train.shape, \"\\nCheck Test Shape\", test.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check Train Shape:  (47520, 41) \n",
            "Check Test Shape (14358, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt1K_P0lA9Hi",
        "colab_type": "text"
      },
      "source": [
        "#Define a function...\n",
        "\n",
        "    Wrangle(X) train, validate, and test sets.\n",
        "    Clean outliers.\n",
        "    Engineer features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie6R0ArP6tWH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d6255e8b-ef4a-4084-8fc0-f27a6ebb2065"
      },
      "source": [
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Check Train Shape: \",train.shape, \"\\nCheck Validation Shape\", val.shape,\"\\nCheck Test Shape\", test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check Train Shape:  (47520, 46) \n",
            "Check Validation Shape (11880, 46) \n",
            "Check Test Shape (14358, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a7AA_l_D-Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The status_group column is the target\n",
        "target = 'status_group'\n",
        "\n",
        "# Get a dataframe with all train columns except the target\n",
        "train_features = train.drop(columns=[target])\n",
        "\n",
        "# Get a list of the numeric features\n",
        "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "# Get a series with the cardinality of the nonnumeric features\n",
        "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
        "\n",
        "# Get a list of all categorical features with cardinality <= 50\n",
        "categorical_features = cardinality[cardinality <= 50].index.tolist()\n",
        "\n",
        "# Combine the lists \n",
        "features = numeric_features + categorical_features"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV4D1AvTD-gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector \n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "X_test = test[features]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dMqEpZYSsgC",
        "colab_type": "text"
      },
      "source": [
        "#  We can use Pandas Profiling to get a report,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EQlNLX8SiTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "9d12b1a4-28bc-41d8-b42e-c23591edfc2f"
      },
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(train, minimal=True).to_notebook_iframe()\n",
        "\n",
        "profile"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/usr/local/lib/python3.6/dist-packages/pandas_profiling/describe.py\", line 282, in multiprocess_func\n    return x[0], describe_1d(x[1], **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/pandas_profiling/describe.py\", line 270, in describe_1d\n    result = result.append(describe_numeric_1d(data, **kwargs))\n  File \"/usr/local/lib/python3.6/dist-packages/pandas_profiling/describe.py\", line 54, in describe_numeric_1d\n    stats['histogram'] = histogram(series, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/pandas_profiling/plot.py\", line 73, in histogram\n    plot = _plot_histogram(series, **kwargs)\nTypeError: _plot_histogram() got an unexpected keyword argument 'minimal'\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1dbe60d4f2f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_notebook_iframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_profiling/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mdescription_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         self.html = to_html(sample,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_profiling/describe.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(df, bins, check_correlation, correlation_threshold, correlation_overrides, check_recoded, pool_size, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mlocal_multiprocess_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiprocess_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0mldesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_multiprocess_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _plot_histogram() got an unexpected keyword argument 'minimal'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU8VzdbVDIqA",
        "colab_type": "text"
      },
      "source": [
        "#Categorical Exploration\n",
        "Re-run until \"Ordinal Coding\". Change feature to explore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDhX-9dJVkPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "94476de4-c908-4f0b-edf6-7592d8627580"
      },
      "source": [
        "train['status_group'].value_counts(normalize=True).plot(kind='barh')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0ed5e05c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXZ_RHM9Dgvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "261362fa-69b6-4038-c4ac-759a45c8d0b2"
      },
      "source": [
        "train.describe(exclude='number').columns"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date_recorded', 'funder', 'installer', 'wpt_name', 'basin',\n",
              "       'subvillage', 'region', 'lga', 'ward', 'public_meeting', 'recorded_by',\n",
              "       'scheme_management', 'scheme_name', 'permit', 'extraction_type',\n",
              "       'extraction_type_group', 'extraction_type_class', 'management',\n",
              "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
              "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
              "       'source_class', 'waterpoint_type', 'waterpoint_type_group',\n",
              "       'status_group'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtAQ60tBDX45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pull no_num feature from above\n",
        "feature = 'water_quality'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OADTYUg0DYBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "c155a605-e4a0-472d-ccf5-7d8945ab5d69"
      },
      "source": [
        "X_train[feature].value_counts()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "soft                  40598\n",
              "salty                  3903\n",
              "unknown                1503\n",
              "milky                   658\n",
              "coloured                403\n",
              "salty abandoned         276\n",
              "fluoride                165\n",
              "fluoride abandoned       14\n",
              "Name: water_quality, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRNWRVNvDX8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(16,9))\n",
        "sns.barplot(\n",
        "    x=train[feature], \n",
        "    y=train['status_group']=='functional', \n",
        "    color='black'\n",
        ");"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U73NwgaNX3t",
        "colab_type": "text"
      },
      "source": [
        "#OneHotEncoding (OHE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHwqEWeLNWgC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "33f9b20e-0707-442d-b22c-e988b8c3b4e9"
      },
      "source": [
        "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
        "import category_encoders as ce\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "encoded = encoder.fit_transform(X_train[[feature]])\n",
        "print(f'{len(encoded.columns)} columns')\n",
        "encoded.head(10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 columns\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>water_quality_soft</th>\n",
              "      <th>water_quality_salty</th>\n",
              "      <th>water_quality_fluoride</th>\n",
              "      <th>water_quality_milky</th>\n",
              "      <th>water_quality_unknown</th>\n",
              "      <th>water_quality_salty abandoned</th>\n",
              "      <th>water_quality_coloured</th>\n",
              "      <th>water_quality_fluoride abandoned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43360</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7263</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2486</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52726</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8558</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2559</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54735</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25763</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44540</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       water_quality_soft  ...  water_quality_fluoride abandoned\n",
              "43360                   1  ...                                 0\n",
              "7263                    1  ...                                 0\n",
              "2486                    0  ...                                 0\n",
              "313                     1  ...                                 0\n",
              "52726                   1  ...                                 0\n",
              "8558                    1  ...                                 0\n",
              "2559                    1  ...                                 0\n",
              "54735                   1  ...                                 0\n",
              "25763                   1  ...                                 0\n",
              "44540                   1  ...                                 0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQclGCsMNovZ",
        "colab_type": "text"
      },
      "source": [
        "###One-Hot Encoding, Logistic Regression, Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzntw6fyNsHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "f844eb18-6c56-4a13-f494-794e6e86ffbe"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "lr = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True), \n",
        "    SimpleImputer(), \n",
        "    StandardScaler(), \n",
        "    LogisticRegressionCV(multi_class='auto', solver='lbfgs', cv=5, n_jobs=-1)\n",
        ")\n",
        "\n",
        "lr.fit(X_train[[feature]], y_train)\n",
        "score = lr.score(X_val[[feature]], y_val)\n",
        "print('Logistic Regression, Validation Accuracy', score)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-2cdb2554a588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m lr = make_pipeline(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_cat_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'make_pipeline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HevVrmN0zl",
        "colab_type": "text"
      },
      "source": [
        "###One-Hot Encoding, Decision Tree, Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oqCaiYyNsWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True), \n",
        "    SimpleImputer(), \n",
        "    DecisionTreeClassifier(random_state=42)\n",
        ")\n",
        "\n",
        "dt.fit(X_train[[feature]], y_train)\n",
        "score = dt.score(X_val[[feature]], y_val)\n",
        "print('Decision Tree, Validation Accuracy', score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8WE1BeuN6UW",
        "colab_type": "text"
      },
      "source": [
        "###One-Hot Encoding, Logistic Regression, Model Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9gquXEvNsTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = lr.named_steps['logisticregressioncv']\n",
        "encoder = lr.named_steps['onehotencoder']\n",
        "encoded_columns = encoder.transform(X_val[[feature]]).columns\n",
        "coefficients = pd.Series(model.coef_[0], encoded_columns)\n",
        "coefficients.sort_values().plot.barh(color='grey');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr7H-HU1OANF",
        "colab_type": "text"
      },
      "source": [
        "#### One-Hot Encoding, Decision Tree, Model Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCAGUNFmNsPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot tree\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "model = dt.named_steps['decisiontreeclassifier']\n",
        "encoder = dt.named_steps['onehotencoder']\n",
        "encoded_columns = encoder.transform(X_val[[feature]]).columns\n",
        "\n",
        "dot_data = export_graphviz(model, \n",
        "                           out_file=None, \n",
        "                           max_depth=7, \n",
        "                           feature_names=encoded_columns,\n",
        "                           class_names=model.classes_, \n",
        "                           impurity=False, \n",
        "                           filled=True, \n",
        "                           proportion=True, \n",
        "                           rounded=True)   \n",
        "display(graphviz.Source(dot_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWPo_vXVNsL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyQl0plbConM",
        "colab_type": "text"
      },
      "source": [
        "#Ordinal Coding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH8xewXpNHo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from category_encoders import OneHotEncoder, OrdinalEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1piy1mPIAuKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = ce.OrdinalEncoder()\n",
        "encoded = encoder.fit_transform(X_train[[feature]])\n",
        "print(f'1 column, {encoded[feature].nunique()} unique values')\n",
        "encoded.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM1z8r_zOOsJ",
        "colab_type": "text"
      },
      "source": [
        "###Ordinal Encoding, Logistic Regression, Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h4a_TUhOPBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(), \n",
        "    StandardScaler(), \n",
        "    LogisticRegressionCV(multi_class='auto', solver='lbfgs', cv=5, n_jobs=-1)\n",
        ")\n",
        "\n",
        "lr.fit(X_train[[feature]], y_train)\n",
        "score = lr.score(X_val[[feature]], y_val)\n",
        "print('Logistic Regression, Validation Accuracy', score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14R7UENnOV4j",
        "colab_type": "text"
      },
      "source": [
        "###Ordinal Encoding, Decision Tree, Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avdUYVTnOPLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(), \n",
        "    DecisionTreeClassifier(random_state=42)\n",
        ")\n",
        "\n",
        "dt.fit(X_train[[feature]], y_train)\n",
        "score = dt.score(X_val[[feature]], y_val)\n",
        "print('Decision Tree, Validation Accuracy', score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPdyFaXEOcEW",
        "colab_type": "text"
      },
      "source": [
        "###Ordinal Encoding, Logistic Regression, Model Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8lYVwamOXaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = lr.named_steps['logisticregressioncv']\n",
        "encoder = lr.named_steps['ordinalencoder']\n",
        "encoded_columns = encoder.transform(X_val[[feature]]).columns\n",
        "coefficients = pd.Series(model.coef_[0], encoded_columns)\n",
        "coefficients.sort_values().plot.barh(color='grey');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-Wut3b0OiUV",
        "colab_type": "text"
      },
      "source": [
        "###Ordinal Encoding, Decision Tree, Model Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6AuZnUNOXoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = dt.named_steps['decisiontreeclassifier']\n",
        "encoder = dt.named_steps['ordinalencoder']\n",
        "encoded_columns = encoder.transform(X_val[[feature]]).columns\n",
        "\n",
        "dot_data = export_graphviz(model, \n",
        "                           out_file=None, \n",
        "                           max_depth=5, \n",
        "                           feature_names=encoded_columns,\n",
        "                           class_names=model.classes_, \n",
        "                           impurity=False, \n",
        "                           filled=True, \n",
        "                           proportion=True, \n",
        "                           rounded=True)   \n",
        "display(graphviz.Source(dot_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhhz8NkIOrsq",
        "colab_type": "text"
      },
      "source": [
        "#     Understand how tree ensembles (multiple decision trees) reduce overfitting compared to a single decision tree with unlimited depth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urtcggbHOXkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import seaborn as sns\n",
        "\n",
        "def pred_heatmap(model, X, features, class_index=-1, title='', num=100):\n",
        "    \"\"\"\n",
        "    Visualize predicted probabilities, for classifier fit on 2 numeric features\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    model : scikit-learn classifier, already fit\n",
        "    X : pandas dataframe, which was used to fit model\n",
        "    features : list of strings, column names of the 2 numeric features\n",
        "    class_index : integer, index of class label\n",
        "    title : string, title of plot\n",
        "    num : int, number of grid points for each feature\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    y_pred_proba : numpy array, predicted probabilities for class_index\n",
        "    \"\"\"\n",
        "    feature1, feature2 = features\n",
        "    min1, max1 = X[feature1].min(), X[feature1].max()\n",
        "    min2, max2 = X[feature2].min(), X[feature2].max()\n",
        "    x1 = np.linspace(min1, max1, num)\n",
        "    x2 = np.linspace(max2, min2, num)\n",
        "    combos = list(itertools.product(x1, x2))\n",
        "    y_pred_proba = model.predict_proba(combos)[:, class_index]\n",
        "    pred_grid = y_pred_proba.reshape(num, num).T\n",
        "    table = pd.DataFrame(pred_grid, columns=x1, index=x2)\n",
        "    sns.heatmap(table, vmin=0, vmax=1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.xlabel(feature1)\n",
        "    plt.ylabel(feature2)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "    return y_pred_proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sLGJ580Qsx9",
        "colab_type": "text"
      },
      "source": [
        "###Compare Decision Tree, Random Forest, Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjWjlgwrPuz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.describe(exclude='number').columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbwB3XBJOXgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instructions\n",
        "# 1. Choose two features\n",
        "# 2. Run this code cell\n",
        "# 3. Interact with the widget sliders\n",
        "feature1 = 'years_MISSING'\n",
        "feature2 = 'population_MISSING'\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def get_X_y(df, feature1, feature2, target):\n",
        "    features = [feature1, feature2]\n",
        "    X = df[features]\n",
        "    y = df[target]\n",
        "    X = X.fillna(X.median())\n",
        "    X = ce.OrdinalEncoder().fit_transform(X)\n",
        "    return X, y\n",
        "\n",
        "def compare_models(max_depth=1, n_estimators=1):\n",
        "    models = [DecisionTreeClassifier(max_depth=max_depth), \n",
        "              RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators), \n",
        "              LogisticRegression(solver='lbfgs', multi_class='auto')]\n",
        "    \n",
        "    for model in models:\n",
        "        name = model.__class__.__name__\n",
        "        model.fit(X, y)\n",
        "        pred_heatmap(model, X, [feature1, feature2], class_index=0, title=name)\n",
        "\n",
        "X, y = get_X_y(train, feature1, feature2, target='status_group')\n",
        "interact(compare_models, max_depth=(1,6,1), n_estimators=(10,40,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id0wJnSRPhea",
        "colab_type": "text"
      },
      "source": [
        "###Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yh1X5dPOXW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do-it-yourself Bagging Ensemble of Decision Trees (like a Random Forest)\n",
        "\n",
        "# Instructions\n",
        "# 1. Choose two features\n",
        "# 2. Run this code cell\n",
        "# 3. Interact with the widget sliders\n",
        "import category_encoders as ce\n",
        "feature1 = 'years_MISSING'\n",
        "feature2 = 'population_MISSING'\n",
        "\n",
        "def waterpumps_bagging(max_depth=1, n_estimators=1):\n",
        "    predicteds = []\n",
        "    for i in range(n_estimators):\n",
        "        title = f'Tree {i+1}'\n",
        "        bootstrap_sample = train.sample(n=len(train), replace=True)\n",
        "        X, y = get_X_y(bootstrap_sample, feature1, feature2, target='status_group')\n",
        "        tree = DecisionTreeClassifier(max_depth=max_depth)\n",
        "        tree.fit(X, y)\n",
        "        predicted = pred_heatmap(tree, X, [feature1, feature2], class_index=0, title=title)\n",
        "        predicteds.append(predicted)\n",
        "    \n",
        "    ensembled = np.vstack(predicteds).mean(axis=0)\n",
        "    title = f'Ensemble of {n_estimators} trees, with max_depth={max_depth}'\n",
        "    sns.heatmap(ensembled.reshape(100, 100).T, vmin=0, vmax=1)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(feature1)\n",
        "    plt.ylabel(feature2)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()\n",
        "        \n",
        "interact(waterpumps_bagging, max_depth=(1,6,1), n_estimators=(2,5,1));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwk2k7GTFdak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Random Forest Classification w/ Validation Accuracy Score\n",
        "%%time\n",
        "import category_encoders as ce\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(strategy='median'),\n",
        "    RandomForestClassifier(random_state=0, n_jobs=1)\n",
        ")\n",
        "#   F I T\n",
        "pipeline.fit(X_train, y_train)\n",
        "print(\"Training Accuracy\", pipeline.score(X_val, y_val))\n",
        "print(\"Validation Accuracy\", pipeline.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULEYvqpdRAQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Lookeyyyyy Here\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL2NbnqC-drB",
        "colab_type": "text"
      },
      "source": [
        "#Dondre' After Hours Study Session DS 211 Notes¶\n",
        "Instructor: Keri Kalmbuch\n",
        "\n",
        "\n",
        "### Reading\n",
        "\n",
        "Top recommendations in _**bold italic:**_\n",
        "\n",
        "#### Decision Trees\n",
        "- A Visual Introduction to Machine Learning, [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/),  and _**[Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)**_\n",
        "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
        "- [How a Russian mathematician constructed a decision tree — by hand — to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
        "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
        "- [Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU)\n",
        "\n",
        "#### Random Forests\n",
        "- [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/), Chapter 8: Tree-Based Methods\n",
        "- [Coloring with Random Forests](http://structuringtheunstructured.blogspot.com/2017/11/coloring-with-random-forests.html)\n",
        "- _**[Random Forests for Complete Beginners: The definitive guide to Random Forests and Decision Trees](https://victorzhou.com/blog/intro-to-random-forests/)**_\n",
        "\n",
        "#### Categorical encoding for trees\n",
        "- [Are categorical variables getting lost in your random forests?](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)\n",
        "- [Beyond One-Hot: An Exploration of Categorical Variables](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/)\n",
        "- _**[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)**_\n",
        "- _**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)**_\n",
        "- [Mean (likelihood) encodings: a comprehensive study](https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study)\n",
        "- [The Mechanics of Machine Learning, Chapter 6: Categorically Speaking](https://mlbook.explained.ai/catvars.html)\n",
        "\n",
        "#### Imposter Syndrome\n",
        "- [Effort Shock and Reward Shock (How The Karate Kid Ruined The Modern World)](http://www.tempobook.com/2014/07/09/effort-shock-and-reward-shock/)\n",
        "- [How to manage impostor syndrome in data science](https://towardsdatascience.com/how-to-manage-impostor-syndrome-in-data-science-ad814809f068)\n",
        "- [\"I am not a real data scientist\"](https://brohrer.github.io/imposter_syndrome.html)\n",
        "- _**[Imposter Syndrome in Data Science](https://caitlinhudon.com/2018/01/19/imposter-syndrome-in-data-science/)**_\n",
        "\n",
        "\n",
        "### More Categorical Encodings\n",
        "\n",
        "**1.** The article **[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)** mentions 4 encodings:\n",
        "\n",
        "- **\"Categorical Encoding\":** This means using the raw categorical values as-is, not encoded. Scikit-learn doesn't support this, but some tree algorithm implementations do. For example, [Catboost](https://catboost.ai/), or R's [rpart](https://cran.r-project.org/web/packages/rpart/index.html) package.\n",
        "- **Numeric Encoding:** Synonymous with Label Encoding, or \"Ordinal\" Encoding with random order. We can use [category_encoders.OrdinalEncoder](https://contrib.scikit-learn.org/category_encoders/ordinal.html).\n",
        "- **One-Hot Encoding:** We can use [category_encoders.OneHotEncoder](https://contrib.scikit-learn.org/category_encoders/onehot.html).\n",
        "- **Binary Encoding:** We can use [category_encoders.BinaryEncoder](https://contrib.scikit-learn.org/category_encoders/binary.html).\n",
        "\n",
        "\n",
        "**2.** The short video \n",
        "**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)** introduces an interesting idea: use both X _and_ y to encode categoricals.\n",
        "\n",
        "Category Encoders has multiple implementations of this general concept:\n",
        "\n",
        "- [CatBoost Encoder](https://contrib.scikit-learn.org/category_encoders/catboost.html)\n",
        "- [Generalized Linear Mixed Model Encoder](https://contrib.scikit-learn.org/category_encoders/glmm.html)\n",
        "- [James-Stein Encoder](https://contrib.scikit-learn.org/category_encoders/jamesstein.html)\n",
        "- [Leave One Out](https://contrib.scikit-learn.org/category_encoders/leaveoneout.html)\n",
        "- [M-estimate](https://contrib.scikit-learn.org/category_encoders/mestimate.html)\n",
        "- [Target Encoder](https://contrib.scikit-learn.org/category_encoders/targetencoder.html)\n",
        "- [Weight of Evidence](https://contrib.scikit-learn.org/category_encoders/woe.html)\n",
        "\n",
        "Category Encoder's mean encoding implementations work for regression problems or binary classification problems. \n",
        "\n",
        "For multi-class classification problems, you will need to temporarily reformulate it as binary classification. For example:\n",
        "\n",
        "```python\n",
        "encoder = ce.TargetEncoder(min_samples_leaf=..., smoothing=...) # Both parameters > 1 to avoid overfitting\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train=='functional')\n",
        "X_val_encoded = encoder.transform(X_train, y_val=='functional')\n",
        "```\n",
        "\n",
        "For this reason, mean encoding won't work well within pipelines for multi-class classification problems.\n",
        "\n",
        "**3.** The **[dirty_cat](https://dirty-cat.github.io/stable/)** library has a Target Encoder implementation that works with multi-class classification.\n",
        "\n",
        "```python\n",
        " dirty_cat.TargetEncoder(clf_type='multiclass-clf')\n",
        "```\n",
        "It also implements an interesting idea called [\"Similarity Encoder\" for dirty categories](https://www.slideshare.net/GaelVaroquaux/machine-learning-on-non-curated-data-154905090).\n",
        "\n",
        "However, it seems like dirty_cat doesn't handle missing values or unknown categories as well as category_encoders does. And you may need to use it with one column at a time, instead of with your whole dataframe.\n",
        "\n",
        "**4. [Embeddings](https://www.kaggle.com/colinmorris/embedding-layers)** can work well with sparse / high cardinality categoricals.\n",
        "\n",
        "_**I hope it’s not too frustrating or confusing that there’s not one “canonical” way to encode categoricals. It’s an active area of research and experimentation — maybe you can make your own contributions!**_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FZQagBT-0Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yZ-rHc_-JD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T9XdOgCNuk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The status_group column is the target\n",
        "target = 'status_group'\n",
        "\n",
        "# Get a dataframe with all train columns except the target\n",
        "train_features = train.drop(columns=[target])\n",
        "\n",
        "# Get a list of the numeric features\n",
        "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "# Get a series with the cardinality of the nonnumeric features\n",
        "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
        "\n",
        "# Get a list of all categorical features with cardinality <= 50\n",
        "categorical_features = cardinality[cardinality <= 50].index.tolist()\n",
        "\n",
        "# Combine the lists \n",
        "features = numeric_features + categorical_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XUxbTN2Nxxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector \n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "X_test = test[features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuTp9ox1NNb8",
        "colab_type": "text"
      },
      "source": [
        "#Use SciKit-Learn Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxzlxRLjOD9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdqRbf5_IsQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oic_model = Pipeline([\n",
        "                  ('ohe', OneHotEncoder()),\n",
        "                  ('impute', SimpleImputer()),\n",
        "                  ('classifier', DecisionTreeClassifier())\n",
        "                  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi6OyI7WOTqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time \n",
        "# How hard are we working our machine\n",
        "oic_model.fit(X_train, y_train)\n",
        "\n",
        "print('training accuracy:', oic_model.score(X_train, y_train))\n",
        "print('validation accuracy:', oic_model.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpkQowSHPYOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"This is how many cuts the Decision Tree did:\", oic_model.named_steps['classifier'].get_depth())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLbLd6BD-pwg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQxiuHMMPpXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "oisc_model = Pipeline([\n",
        "                  ('ohe', OneHotEncoder()),\n",
        "                  ('impute', SimpleImputer()),\n",
        "                  ('select', SelectKBest(k=20)),\n",
        "                  ('classifier', DecisionTreeClassifier())\n",
        "                  ])\n",
        "\n",
        "oisc_model.fit(X_train, y_train)\n",
        "\n",
        "print('training accuracy:', oisc_model.score(X_train, y_train))\n",
        "print('validation accuracy:', oisc_model.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_en5WIhP7e6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"This is how many cuts the Decision Tree did:\", oisc_model.named_steps['classifier'].get_depth())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZz7Wp-DR-Pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Against:\", oic_model.named_steps['classifier'].get_depth())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXVS3eU_SB5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ohe = oic_model.named_steps['ohe']\n",
        "X_trans = ohe.transform(X_train)\n",
        "print(\"X Train Shape:\", X_train.shape)\n",
        "print(\"X Transformed Shape:\", X_trans.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV5YNLOAX1OE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "model = Pipeline([\n",
        "                  ('ohe', OrdinalEncoder()),\n",
        "                  ('impute', SimpleImputer()),\n",
        "                  ('classifier', DecisionTreeClassifier())\n",
        "])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('training accuracy:', model.score(X_train, y_train))\n",
        "print('validation accuracy:', model.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zwczdbNWvmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "model = Pipeline([\n",
        "                  ('ohe', OneHotEncoder()),\n",
        "                  ('impute', SimpleImputer()),\n",
        "                  ('classifier', RandomForestClassifier())\n",
        "])\n",
        "#This FITTING is important in the pipeline\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print('training accuracy:', model.score(X_train, y_train))\n",
        "print('validation accuracy:', model.score(X_val, y_val))\n",
        "\n",
        "#Time went up to train a lot more trees. \n",
        "#We aren't overfit  becuase of the overfitting across the entire forest balances everything out. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8a4WmKuUErA",
        "colab_type": "text"
      },
      "source": [
        "**What is the difference between the two used for categorical encoding?**\n",
        "###One Hot Encoder (OHE)\n",
        "\n",
        "\n",
        "###Ordinal Encoder\n",
        "    What is an example of ordinal numbers?\n",
        "The numbers 1st(First), 2nd(Second), 3rd(Third), 4th(Fourth), 5th(Fifth), 6th(Sixth), 7th(Seventh), 8th(Eighth), 9th(Ninth) and 10th(Tenth) tell the position of different athletes in the race. Hence, all of them are ordinal numbers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pfIEAL4UEZB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "```\n",
        "Understand how categorical encodings affect trees differently compared to linear models\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXSPEAr6VG5d",
        "colab_type": "text"
      },
      "source": [
        "### Categorical exploration, 1 feature at a time\n",
        "\n",
        "Change `feature`, then re-run these cells!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGmdncl0UHPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49PGY2XRUNjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEECMjgUSP5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}