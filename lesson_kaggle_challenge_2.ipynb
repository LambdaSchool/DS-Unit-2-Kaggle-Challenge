{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mRfPLX4WgLVJ"
   },
   "source": [
    "Lambda School Data Science, Unit 2: Predictive Modeling\n",
    "\n",
    "# Kaggle Challenge, Module 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRRNhkxcgLVK"
   },
   "source": [
    "### Objectives\n",
    "- use scikit-learn for random forests\n",
    "- understand how tree ensembles reduce overfitting compared to a single decision tree with unlimited depth\n",
    "- do ordinal encoding with high-cardinality categoricals\n",
    "- understand how categorical encodings affect trees differently compared to linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-3TH11e1gLVL"
   },
   "source": [
    "### Summary \n",
    "\n",
    "#### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
    "- \"Tree Ensembles\" means Random Forest or Gradient Boosting models. \n",
    "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
    "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
    "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or boosting (Gradient Boosting).\n",
    "- Random Forest's advantage: may be less sensitive to hyperparameters. Gradient Boosting's advantage: may get better predictive accuracy.\n",
    "\n",
    "#### One-hot encoding isnâ€™t the only way, and may not be the best way, of categorical encoding for tree ensembles.\n",
    "- For example, tree ensembles can work with arbitrary \"ordinal\" encoding! (Randomly assigning an integer to each category.) Compared to one-hot encoding, the dimensionality will be lower, and the predictive accuracy may be just as good or even better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5PbOFEuFfGF"
   },
   "source": [
    "### Setup\n",
    "\n",
    "#### If you're using [Anaconda](https://www.anaconda.com/distribution/) locally\n",
    "\n",
    "Install required Python package, if you haven't already:\n",
    "\n",
    "- [category_encoders](http://contrib.scikit-learn.org/categorical-encoding/), version >= 2.0\n",
    "\n",
    "```\n",
    "conda install -c conda-forge category_encoders\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Samue\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - category_encoders\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.6.16          |           py37_1         149 KB  conda-forge\n",
      "    conda-4.7.11               |           py37_0         3.0 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.2 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2019.5.15-1 --> conda-forge::ca-certificates-2019.6.16-hecc5488_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                         pkgs/main --> conda-forge\n",
      "  conda                                           pkgs/main --> conda-forge\n",
      "  openssl              pkgs/main::openssl-1.1.1c-he774522_1 --> conda-forge::openssl-1.1.1c-hfa6e2cd_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "conda-4.7.11         | 3.0 MB    |            |   0% \n",
      "conda-4.7.11         | 3.0 MB    |            |   1% \n",
      "conda-4.7.11         | 3.0 MB    | #3         |  13% \n",
      "conda-4.7.11         | 3.0 MB    | ##6        |  26% \n",
      "conda-4.7.11         | 3.0 MB    | ####       |  40% \n",
      "conda-4.7.11         | 3.0 MB    | #####3     |  54% \n",
      "conda-4.7.11         | 3.0 MB    | ######7    |  68% \n",
      "conda-4.7.11         | 3.0 MB    | ########   |  81% \n",
      "conda-4.7.11         | 3.0 MB    | #########4 |  94% \n",
      "conda-4.7.11         | 3.0 MB    | ########## | 100% \n",
      "\n",
      "certifi-2019.6.16    | 149 KB    |            |   0% \n",
      "certifi-2019.6.16    | 149 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FStAplyRFoEu"
   },
   "outputs": [],
   "source": [
    "# If you're in Colab...\n",
    "import os, sys\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "\n",
    "if in_colab:\n",
    "    # Install required python packages:\n",
    "    # category_encoders, version >= 2.0\n",
    "    # pandas-profiling, version >= 2.0\n",
    "    # plotly, version >= 4.0\n",
    "    !pip install --upgrade category_encoders pandas-profiling plotly\n",
    "    \n",
    "    # Pull files from Github repo\n",
    "    os.chdir('/content')\n",
    "    !git init .\n",
    "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge.git\n",
    "    !git pull origin master\n",
    "    \n",
    "    # Change into directory for module\n",
    "    os.chdir('module2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHFxMCPSgLVM"
   },
   "source": [
    "## Solution example\n",
    "\n",
    "> Define a function to wrangle train, validate, and test sets in the same way. Clean outliers and engineer features. (For example, [what other columns have zeros and shouldn't?](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values) What other columns are duplicates, or nearly duplicates? Can you extract the year from date_recorded? Can you engineer new features, such as the number of years from waterpump construction to waterpump inspection?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YTLm-rDagLVM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Merge train_features.csv & train_labels.csv\n",
    "train = pd.merge(pd.read_csv('train_features.csv'), \n",
    "                 pd.read_csv('train_labels.csv'))\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "test = pd.read_csv('test_features.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Split train into train & val\n",
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
    "                              stratify=train['status_group'], random_state=42)\n",
    "\n",
    "\n",
    "def wrangle(X):\n",
    "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
    "    \n",
    "    # Prevent SettingWithCopyWarning\n",
    "    X = X.copy()\n",
    "    \n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these values like zero.\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values.\n",
    "    # So we will replace the zeros with nulls, and impute missing values later.\n",
    "    # Also create a \"missing indicator\" column, because the fact that\n",
    "    # values are missing may be a predictive signal.\n",
    "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
    "                       'gps_height', 'population']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        X[col+'_MISSING'] = X[col].isnull()\n",
    "            \n",
    "    # Drop duplicate columns\n",
    "    duplicates = ['quantity_group', 'payment_type']\n",
    "    X = X.drop(columns=duplicates)\n",
    "    \n",
    "    # Drop recorded_by (never varies) and id (always varies, random)\n",
    "    unusable_variance = ['recorded_by', 'id']\n",
    "    X = X.drop(columns=unusable_variance)\n",
    "    \n",
    "    # Convert date_recorded to datetime\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract components from date_recorded, then drop the original column\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    X['month_recorded'] = X['date_recorded'].dt.month\n",
    "    X['day_recorded'] = X['date_recorded'].dt.day\n",
    "    X = X.drop(columns='date_recorded')\n",
    "    \n",
    "    # Engineer feature: how many years from construction_year to date_recorded\n",
    "    X['years'] = X['year_recorded'] - X['construction_year']\n",
    "    X['years_MISSING'] = X['years'].isnull()\n",
    "    \n",
    "    # return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2HppBvZgLVP"
   },
   "outputs": [],
   "source": [
    "# The status_group column is the target\n",
    "target = 'status_group'\n",
    "\n",
    "# Get a dataframe with all train columns except the target\n",
    "train_features = train.drop(columns=[target])\n",
    "\n",
    "# Get a list of the numeric features\n",
    "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Get a series with the cardinality of the nonnumeric features\n",
    "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
    "\n",
    "# Get a list of all categorical features with cardinality <= 50\n",
    "categorical_features = cardinality[cardinality <= 50].index.tolist()\n",
    "\n",
    "# Combine the lists \n",
    "features = numeric_features + categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXmK2brXgLVR"
   },
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector \n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZL-yK8B7gLVW"
   },
   "source": [
    "## Use scikit-learn for random forests\n",
    "\n",
    "[Scikit-Learn User Guide: Random Forests](https://scikit-learn.org/stable/modules/ensemble.html#random-forests) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "57yyygsdgLVW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.8096801346801347\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# WARNING: there are sometimes quirks with this command,\n",
    "# which can lead to weird bugs.\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names='True'),\n",
    "    SimpleImputer(strategy='median'),\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# Fit on train, score on val\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Validation Accuracy', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape before encoding (47520, 38)\n",
      "X_train shape after encoding (47520, 201)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape before encoding', X_train.shape)\n",
    "\n",
    "encoder = pipeline.named_steps['onehotencoder']\n",
    "encoded = encoder.transform(X_train)\n",
    "print('X_train shape after encoding', encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfyk_aa5gLVY"
   },
   "source": [
    "## Do ordinal encoding with high-cardinality categoricals\n",
    "\n",
    "http://contrib.scikit-learn.org/categorical-encoding/ordinal.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8d_WJtcgLVZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score 0.8135521885521886\n",
      "Wall time: 7.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Arrange data into X features matrix and y target vector\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=target)\n",
    "y_val = val[target]\n",
    "X_test = test\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    SimpleImputer(strategy='median'),\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# Fit on train, score on val\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Validation score', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape before encoding (47520, 45)\n",
      "X_train shape after encoding (47520, 45)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape before encoding', X_train.shape)\n",
    "\n",
    "encoder = pipeline.named_steps['ordinalencoder']\n",
    "encoded = encoder.transform(X_train)\n",
    "print('X_train shape after encoding', encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4EJi2GvgLVa"
   },
   "source": [
    "## Understand how tree ensembles reduce overfitting compared to a single decision tree with unlimited depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUYP619CgLVb"
   },
   "source": [
    "### Interlude: [predicting golf putts](https://statmodeling.stat.columbia.edu/2008/12/04/the_golf_puttin/)\n",
    "(1 feature, non-linear, regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4640ukxgLVc"
   },
   "outputs": [],
   "source": [
    "putts = pd.DataFrame(\n",
    "    columns=['distance', 'tries', 'successes'], \n",
    "    data = [[2, 1443, 1346],\n",
    "            [3, 694, 577],\n",
    "            [4, 455, 337],\n",
    "            [5, 353, 208],\n",
    "            [6, 272, 149],\n",
    "            [7, 256, 136],\n",
    "            [8, 240, 111],\n",
    "            [9, 217, 69],\n",
    "            [10, 200, 67],\n",
    "            [11, 237, 75],\n",
    "            [12, 202, 52],\n",
    "            [13, 192, 46],\n",
    "            [14, 174, 54],\n",
    "            [15, 167, 28],\n",
    "            [16, 201, 27],\n",
    "            [17, 195, 31],\n",
    "            [18, 191, 33],\n",
    "            [19, 147, 20],\n",
    "            [20, 152, 24]]\n",
    ")\n",
    "\n",
    "putts['rate of success'] = putts['successes'] / putts['tries']\n",
    "putts_X = putts[['distance']]\n",
    "putts_y = putts['rate of success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0IpCcKggLVd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31afb878301748e88ba6f1ee60d9b8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='max_depth', max=6, min=1), IntSlider(value=10, descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def putt_trees(max_depth=1, n_estimators=1):\n",
    "    models = [DecisionTreeRegressor(max_depth=max_depth), \n",
    "              RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators)]\n",
    "    \n",
    "    for model in models:\n",
    "        name = model.__class__.__name__\n",
    "        model.fit(putts_X, putts_y)\n",
    "        ax = putts.plot('distance', 'rate of success', kind='scatter', title=name)\n",
    "        ax.step(putts_X, model.predict(putts_X), where='mid')\n",
    "        plt.show()\n",
    "        \n",
    "interact(putt_trees, max_depth=(1,6,1), n_estimators=(10,40,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0nNABF3HgLVg"
   },
   "source": [
    "### What's \"random\" about random forests?\n",
    "1. Each tree trains on a random bootstrap sample of the data. (In scikit-learn, for `RandomForestRegressor` and `RandomForestClassifier`, the `bootstrap` parameter's default is `True`.) This type of ensembling is called Bagging. (Bootstrap AGGregatING.)\n",
    "2. Each split considers a random subset of the features. (In scikit-learn, when the `max_features` parameter is not `None`.) \n",
    "\n",
    "For extra randomness, you can try [\"extremely randomized trees\"](https://scikit-learn.org/stable/modules/ensemble.html#extremely-randomized-trees)!\n",
    "\n",
    ">In extremely randomized trees (see [ExtraTreesClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html) and [ExtraTreesRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html) classes), randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KgZK9_9gLVh"
   },
   "source": [
    "### Bagging demo, with golf putts data\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vA9mrSTNgLVi",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5232df60d84b90a0f41e54abe08fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='max_depth', max=6, min=1), IntSlider(value=2, descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do-it-yourself Bagging Ensemble of Decision Trees (like a Random Forest)\n",
    "def diy_bagging(max_depth=1, n_estimators=1):\n",
    "    y_preds = []\n",
    "    for i in range(n_estimators):\n",
    "        title = f'Tree {i+1}'\n",
    "        bootstrap_sample = putts.sample(n=len(putts), replace=True).sort_values(by='distance')\n",
    "        bootstrap_X = bootstrap_sample[['distance']]\n",
    "        bootstrap_y = bootstrap_sample['rate of success']\n",
    "        tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "        tree.fit(bootstrap_X, bootstrap_y)\n",
    "        y_pred = tree.predict(bootstrap_X)\n",
    "        y_preds.append(y_pred)\n",
    "        ax = bootstrap_sample.plot('distance', 'rate of success', kind='scatter', title=title)\n",
    "        ax.step(bootstrap_X, y_pred, where='mid')\n",
    "        plt.show()\n",
    "        \n",
    "    ensembled = np.vstack(y_preds).mean(axis=0)\n",
    "    title = f'Ensemble of {n_estimators} trees, with max_depth={max_depth}'\n",
    "    ax = putts.plot('distance', 'rate of success', kind='scatter', title=title)\n",
    "    ax.step(putts_X, ensembled, where='mid')\n",
    "    plt.show()\n",
    "    \n",
    "interact(diy_bagging, max_depth=(1,6,1), n_estimators=(2,5,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rq4Z_wQ_gLVj"
   },
   "source": [
    "### Go back to Tanzania Waterpumps ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FoSE9iT6YXQz"
   },
   "source": [
    "#### Helper function to visualize predicted probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzIAjGpJgLVj"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "def pred_heatmap(model, X, features, class_index=-1, title='', num=100):\n",
    "    \"\"\"\n",
    "    Visualize predicted probabilities, for classifier fit on 2 numeric features\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : scikit-learn classifier, already fit\n",
    "    X : pandas dataframe, which was used to fit model\n",
    "    features : list of strings, column names of the 2 numeric features\n",
    "    class_index : integer, index of class label\n",
    "    title : string, title of plot\n",
    "    num : int, number of grid points for each feature\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    y_pred_proba : numpy array, predicted probabilities for class_index\n",
    "    \"\"\"\n",
    "    feature1, feature2 = features\n",
    "    min1, max1 = X[feature1].min(), X[feature1].max()\n",
    "    min2, max2 = X[feature2].min(), X[feature2].max()\n",
    "    x1 = np.linspace(min1, max1, num)\n",
    "    x2 = np.linspace(max2, min2, num)\n",
    "    combos = list(itertools.product(x1, x2))\n",
    "    y_pred_proba = model.predict_proba(combos)[:, class_index]\n",
    "    pred_grid = y_pred_proba.reshape(num, num).T\n",
    "    table = pd.DataFrame(pred_grid, columns=x1, index=x2)\n",
    "    sns.heatmap(table)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(feature1)\n",
    "    plt.ylabel(feature2)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return y_pred_proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DiRfPqHjgLVl"
   },
   "source": [
    "### Compare Decision Tree, Random Forest, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKkMLXhMgLVl"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d39ea675604408ab624d1f098fa391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='max_depth', max=6, min=1), IntSlider(value=10, descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instructions\n",
    "# 1. Choose two features\n",
    "# 2. Run this code cell\n",
    "# 3. Interact with the widget sliders\n",
    "feature1 = 'longitude'\n",
    "feature2 = 'quantity'\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def get_X_y(df, feature1, feature2, target):\n",
    "    features = [feature1, feature2]\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    X = X.fillna(X.median())\n",
    "    X = ce.OrdinalEncoder().fit_transform(X)\n",
    "    return X, y\n",
    "\n",
    "def compare_models(max_depth=1, n_estimators=1):\n",
    "    models = [DecisionTreeClassifier(max_depth=max_depth), \n",
    "              RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators), \n",
    "              LogisticRegression(solver='lbfgs', multi_class='auto')]\n",
    "    \n",
    "    for model in models:\n",
    "        name = model.__class__.__name__\n",
    "        model.fit(X, y)\n",
    "        pred_heatmap(model, X, [feature1, feature2], class_index=0, title=name)\n",
    "\n",
    "X, y = get_X_y(train, feature1, feature2, target='status_group')\n",
    "interact(compare_models, max_depth=(1,6,1), n_estimators=(10,40,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hOQqjLEDgLVn"
   },
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hm4aPgs2gLVn"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9788d9731dd148f8a3a3bf3b8d2e06d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='max_depth', max=6, min=1), IntSlider(value=2, descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do-it-yourself Bagging Ensemble of Decision Trees (like a Random Forest)\n",
    "\n",
    "# Instructions\n",
    "# 1. Choose two features\n",
    "# 2. Run this code cell\n",
    "# 3. Interact with the widget sliders\n",
    "\n",
    "feature1 = 'longitude'\n",
    "feature2 = 'quantity'\n",
    "\n",
    "def waterpumps_bagging(max_depth=1, n_estimators=1):\n",
    "    predicteds = []\n",
    "    for i in range(n_estimators):\n",
    "        title = f'Tree {i+1}'\n",
    "        bootstrap_sample = train.sample(n=len(train), replace=True)\n",
    "        X, y = get_X_y(bootstrap_sample, feature1, feature2, target='status_group')\n",
    "        tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "        tree.fit(X, y)\n",
    "        predicted = pred_heatmap(tree, X, [feature1, feature2], class_index=0, title=title)\n",
    "        predicteds.append(predicted)\n",
    "    \n",
    "    ensembled = np.vstack(predicteds).mean(axis=0)\n",
    "    title = f'Ensemble of {n_estimators} trees, with max_depth={max_depth}'\n",
    "    sns.heatmap(ensembled.reshape(100, 100).T)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(feature1)\n",
    "    plt.ylabel(feature2)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "        \n",
    "interact(waterpumps_bagging, max_depth=(1,6,1), n_estimators=(2,5,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xs2UPoVdgLVp"
   },
   "source": [
    "## Understand how categorical encodings affect trees differently compared to linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8V-A92mgLVp"
   },
   "source": [
    "### Categorical exploration, 1 feature at a time\n",
    "\n",
    "Change `feature`, then re-run these cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "years_MISSING                    2\n",
       "permit                           2\n",
       "public_meeting                   2\n",
       "population_MISSING               2\n",
       "gps_height_MISSING               2\n",
       "construction_year_MISSING        2\n",
       "latitude_MISSING                 2\n",
       "longitude_MISSING                2\n",
       "source_class                     3\n",
       "quantity                         5\n",
       "year_recorded                    5\n",
       "management_group                 5\n",
       "waterpoint_type_group            6\n",
       "quality_group                    6\n",
       "waterpoint_type                  7\n",
       "source_type                      7\n",
       "payment                          7\n",
       "extraction_type_class            7\n",
       "water_quality                    8\n",
       "basin                            9\n",
       "source                          10\n",
       "management                      12\n",
       "scheme_management               12\n",
       "month_recorded                  12\n",
       "extraction_type_group           13\n",
       "extraction_type                 18\n",
       "district_code                   20\n",
       "region                          21\n",
       "region_code                     27\n",
       "day_recorded                    31\n",
       "construction_year               54\n",
       "num_private                     59\n",
       "years                           60\n",
       "amount_tsh                      94\n",
       "lga                            124\n",
       "population                     985\n",
       "funder                        1716\n",
       "installer                     1929\n",
       "ward                          2082\n",
       "gps_height                    2400\n",
       "scheme_name                   2563\n",
       "subvillage                   17231\n",
       "wpt_name                     30661\n",
       "latitude                     46026\n",
       "longitude                    46028\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G35RAzVdgLVq"
   },
   "outputs": [],
   "source": [
    "feature = 'quantity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuxHWiH8gLVr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enough          26567\n",
       "insufficient    12153\n",
       "dry              4921\n",
       "seasonal         3244\n",
       "unknown           635\n",
       "Name: quantity, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[feature].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVxoC4NngLVt"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=train[feature], \n",
    "            y=train['status_group']=='functional');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w99mek14gLVv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43360    insufficient\n",
       "7263           enough\n",
       "2486     insufficient\n",
       "313            enough\n",
       "52726          enough\n",
       "8558     insufficient\n",
       "2559     insufficient\n",
       "54735          enough\n",
       "25763          enough\n",
       "44540          enough\n",
       "28603             dry\n",
       "4372     insufficient\n",
       "30666    insufficient\n",
       "6431           enough\n",
       "57420    insufficient\n",
       "1373           enough\n",
       "2026           enough\n",
       "58977             dry\n",
       "41101        seasonal\n",
       "10019          enough\n",
       "Name: quantity, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[feature].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ezzK2IdbgLVx"
   },
   "source": [
    "### [One Hot Encoding](http://contrib.scikit-learn.org/categorical-encoding/onehot.html)\n",
    "\n",
    "> Onehot (or dummy) coding for categorical features, produces one feature per category, each binary.\n",
    "\n",
    "Warning: May run slow, or run out of memory, with high cardinality categoricals!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDQZtV6GgLVy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantity_insufficient</th>\n",
       "      <th>quantity_enough</th>\n",
       "      <th>quantity_dry</th>\n",
       "      <th>quantity_seasonal</th>\n",
       "      <th>quantity_unknown</th>\n",
       "      <th>quantity_-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43360</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52726</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8558</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54735</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25763</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44540</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30666</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57420</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58977</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       quantity_insufficient  quantity_enough  quantity_dry  \\\n",
       "43360                      1                0             0   \n",
       "7263                       0                1             0   \n",
       "2486                       1                0             0   \n",
       "313                        0                1             0   \n",
       "52726                      0                1             0   \n",
       "8558                       1                0             0   \n",
       "2559                       1                0             0   \n",
       "54735                      0                1             0   \n",
       "25763                      0                1             0   \n",
       "44540                      0                1             0   \n",
       "28603                      0                0             1   \n",
       "4372                       1                0             0   \n",
       "30666                      1                0             0   \n",
       "6431                       0                1             0   \n",
       "57420                      1                0             0   \n",
       "1373                       0                1             0   \n",
       "2026                       0                1             0   \n",
       "58977                      0                0             1   \n",
       "41101                      0                0             0   \n",
       "10019                      0                1             0   \n",
       "\n",
       "       quantity_seasonal  quantity_unknown  quantity_-1  \n",
       "43360                  0                 0            0  \n",
       "7263                   0                 0            0  \n",
       "2486                   0                 0            0  \n",
       "313                    0                 0            0  \n",
       "52726                  0                 0            0  \n",
       "8558                   0                 0            0  \n",
       "2559                   0                 0            0  \n",
       "54735                  0                 0            0  \n",
       "25763                  0                 0            0  \n",
       "44540                  0                 0            0  \n",
       "28603                  0                 0            0  \n",
       "4372                   0                 0            0  \n",
       "30666                  0                 0            0  \n",
       "6431                   0                 0            0  \n",
       "57420                  0                 0            0  \n",
       "1373                   0                 0            0  \n",
       "2026                   0                 0            0  \n",
       "58977                  0                 0            0  \n",
       "41101                  1                 0            0  \n",
       "10019                  0                 0            0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
    "encoded = encoder.fit_transform(X_train[[feature]])\n",
    "print(f'{len(encoded.columns)} columns')\n",
    "encoded.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QUd6gzcZgLVz"
   },
   "source": [
    "### [Ordinal Encoding](http://contrib.scikit-learn.org/categorical-encoding/ordinal.html)\n",
    "\n",
    "> Ordinal encoding uses a single column of integers to represent the classes. An optional mapping dict can be passed in; in this case, we use the knowledge that there is some true order to the classes themselves. Otherwise, the classes are assumed to have no true order and integers are selected at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnBz2RbwgLVz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 column, 5 unique values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43360</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52726</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8558</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54735</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25763</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44540</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28603</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30666</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57420</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58977</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41101</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       quantity\n",
       "43360         1\n",
       "7263          2\n",
       "2486          1\n",
       "313           2\n",
       "52726         2\n",
       "8558          1\n",
       "2559          1\n",
       "54735         2\n",
       "25763         2\n",
       "44540         2\n",
       "28603         3\n",
       "4372          1\n",
       "30666         1\n",
       "6431          2\n",
       "57420         1\n",
       "1373          2\n",
       "2026          2\n",
       "58977         3\n",
       "41101         4\n",
       "10019         2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = ce.OrdinalEncoder()\n",
    "encoded = encoder.fit_transform(X_train[[feature]])\n",
    "print(f'1 column, {encoded[feature].nunique()} unique values')\n",
    "encoded.head(20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lesson_kaggle_challenge_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
