{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "LS_DS_224_assignment.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4lEjzDHbqNT",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "# Classification Metrics\n",
        "\n",
        "## Assignment\n",
        "- [ ] If you haven't yet, [review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2), then submit your dataset.\n",
        "- [ ] Plot a confusion matrix for your Tanzania Waterpumps model.\n",
        "- [ ] Continue to participate in our Kaggle challenge. Every student should have made at least one submission that scores at least 70% accuracy (well above the majority class baseline).\n",
        "- [ ] Submit your final predictions to our Kaggle competition. Optionally, go to **My Submissions**, and _\"you may select up to 1 submission to be used to count towards your final leaderboard score.\"_\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "- [ ] Read [Maximizing Scarce Maintenance Resources with Data: Applying predictive modeling, precision at k, and clustering to optimize impact](https://towardsdatascience.com/maximizing-scarce-maintenance-resources-with-data-8f3491133050), by Lambda DS3 student Michael Brady. His blog post extends the Tanzania Waterpumps scenario, far beyond what's in the lecture notebook.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Reading\n",
        "\n",
        "- [Attacking discrimination with smarter machine learning](https://research.google.com/bigpicture/attacking-discrimination-in-ml/), by Google Research, with  interactive visualizations. _\"A threshold classifier essentially makes a yes/no decision, putting things in one category or another. We look at how these classifiers work, ways they can potentially be unfair, and how you might turn an unfair classifier into a fairer one. As an illustrative example, we focus on loan granting scenarios where a bank may grant or deny a loan based on a single, automatically computed number such as a credit score.\"_\n",
        "- [Notebook about how to calculate expected value from a confusion matrix by treating it as a cost-benefit matrix](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb)\n",
        "- [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415)\n",
        "\n",
        "\n",
        "### Doing\n",
        "- [ ] Share visualizations in our Slack channel!\n",
        "- [ ] RandomizedSearchCV / GridSearchCV, for model selection. (See module 3 assignment notebook)\n",
        "- [ ] Stacking Ensemble. (See module 3 assignment notebook)\n",
        "- [ ] More Categorical Encoding. (See module 2 assignment notebook)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lsbRiKBoB5RE",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BVA1lph8CcNX",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtQLim8-bqNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing numpy and scipy stats\n",
        "from scipy.stats import mode\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSjfInvmcoHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "561cb8e6-f7af-4b3e-fa1a-0cb6a59191d1"
      },
      "source": [
        "target = 'status_group'\n",
        "y_train = train[target]\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59400,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bdd9hjyqYLA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2aefc00-e747-4257-e8b7-93acb2f90653"
      },
      "source": [
        "x_train['longitude'].isnull().sum()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e9BRm3xpdPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f80c8e73-cbaf-4fa7-e5d9-1a4153dfb124"
      },
      "source": [
        "x_train['ward'].isnull().sum()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1p9Oxvwcxxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the list of the columns that I want to drop here and\n",
        "# then will pass them into the wrangle function\n",
        "target = 'status_group'\n",
        "# This is a list of some of the colums that I want to drop\n",
        "# Will drop subvillage -- because similar results as lat and lon\n",
        "# Dropping funder:  has high cardinality\n",
        "# Dropping the wpt_name:  has high cardinality is the name of the water point\n",
        "# Dropping payment_type:  same as payment(duplicate)\n",
        "cols_to_drop = ['id', 'quantity_group', 'recorded_by', \"subvillage\", \n",
        "                'num_private', 'funder', 'wpt_name' ,'scheme_name', 'payment_type',\n",
        "                'quality_group', ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz1lNPCrr18N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are some inner functions in my wrangle function that help\n",
        "# With the fixing the latitude and the longitude\n",
        "def myLatitude(theRow,df):\n",
        "  \n",
        "  if pd.isnull(theRow['latitude']):\n",
        "    theWard = theRow['ward']\n",
        "    lat = df[df['ward'] == theWard]\n",
        "    theMode = mode(lat['latitude'])\n",
        "    return (theMode[0][0])\n",
        "  return (theRow['latitude'])\n",
        "\n",
        "def myLon(theRow, df): \n",
        "  if (pd.isnull(theRow['longitude'])):\n",
        "    lon = df[df['ward'] == theRow['ward']]\n",
        "    theMode = mode(lon['longitude'])\n",
        "    return (theMode[0][0])\n",
        "  return (theRow['longitude'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_6AlDqsropW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is my wrangle function\n",
        "\n",
        "def wrangleFxn(df, cols_to_drop ,numCardinal=50, useMode=True, num=None, highVar=None, lowVar=None, useDropList=True ):\n",
        "  ''' This is the wrangle function\n",
        "      It will take in a dataFrame either the train, test, or validate.\n",
        "      It should have the TARGET already removed from it. \n",
        "\n",
        "      cols_to_drop:   List of features that you want to drop automatically from \n",
        "                      the dataFrame\n",
        "                      It will drop the columns before looking at the cardinality of the\n",
        "                      columns.\n",
        "\n",
        "      numCardinal:  default is 50. This is the threshold.  If it is less\n",
        "                    than  or equal to this number it is retained in the \n",
        "                    features.\n",
        "      useMode:  default is True.  This will use the apply functiontion to \n",
        "                make the lat and lon have values similar to those in \n",
        "                the ward that it is found.\n",
        "      num:      default is None.  It this is set to a number, \n",
        "                it will further reduce the cardinality of the\n",
        "                cardinal features to a specified number. \n",
        "      \n",
        "      highVar:  Default is None. If set will drop any columns that have more \n",
        "                variance than what is set here as the threshold.  Should be\n",
        "                set as a float ie(.90 or .8)\n",
        "      \n",
        "      lowVar:   Default is None. if set will drop any columns who have less\n",
        "                variance than here.  Should be set as a float ie(.1 or .234)\n",
        "\n",
        "      useDropList:  Default is True.  When is True will use the cols_to_drop parameter.\n",
        "                    When false will not use the cols_to_drop parameter \n",
        "\n",
        "      returns:  Will return the datframe prepared for the pipeline.\n",
        "\n",
        "  '''\n",
        "  \n",
        "  \n",
        "  target = 'status_group'\n",
        "  # making the copy\n",
        "  df = df.copy()\n",
        "  # will try to drop the target if it is present\n",
        "  if target in df.columns:\n",
        "    df = df.drop(columns=[target])\n",
        "  \n",
        "  # Will be setting the long and lat before doing any dropping\n",
        "  df['latitude'] = df['latitude'].replace(-2e-08, 0)\n",
        "\n",
        "  # Getting rid of the zeros in the latitude and the longitude putting in \n",
        "  # np.nan\n",
        "  cols_w_zeros = ['latitude', 'longitude']\n",
        "\n",
        "  for col in cols_w_zeros:\n",
        "    df[col] = df[col].replace(0, np.nan)\n",
        "\n",
        "  if useMode == True:\n",
        "    #This is to make the latitude and the longitude have\n",
        "    # numbers similar to those whose region they are in\n",
        "    df['latitude'] = df.apply(myLatitude, axis=1, args=(df,))\n",
        "    df['longitude'] = df.apply(myLon, axis=1, args=(df,))\n",
        "    pd.to_numeric(df['latitude'])\n",
        "  \n",
        "  # Changing the format to dateTime format and then\n",
        "  # making \n",
        "  df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
        "  df['construction_year'] = pd.to_datetime(df['construction_year'])\n",
        "  df['construction_year'] = df['construction_year'].dt.year\n",
        "\n",
        "  df['year_recorded'] = df['date_recorded'].dt.year\n",
        "  df['month_recorded'] = df['date_recorded'].dt.month\n",
        "  df['day_recorded'] = df['date_recorded'].dt.day\n",
        "\n",
        "  # Making a new feature that will be \"year_age\"\n",
        "  df['year_age']  = df['year_recorded'] - df['construction_year']\n",
        "  \n",
        "  # Dropping the columns preset to drop\n",
        "  if useDropList == True:\n",
        "    df = df.drop(columns= cols_to_drop)\n",
        "\n",
        "  # Getting a list of the cardinal features at the start\n",
        "  cardinals = df.select_dtypes(exclude='number')\n",
        "\n",
        "  # This to drop features that are left that have high skew (almost no variance)\n",
        "  # or possibly too much variance\n",
        "  if highVar != None:\n",
        "    # Getting a list of the cardinal features at the start\n",
        "    cardinals = df.select_dtypes(exclude='number')\n",
        "    tCol = cardinals.columns.to_list()\n",
        "    for col in tCol:\n",
        "      if df[col].value_counts(normalize=True, dropna=False).to_list()[0]  > highVar:\n",
        "        df = df.drop(columns=[col])\n",
        "  \n",
        "  if lowVar != None:\n",
        "    # Getting a list of the cardinal features at the start\n",
        "    cardinals = df.select_dtypes(exclude='number')\n",
        "    tCol = cardinals.columns.to_list()\n",
        "    \n",
        "    for col in tCol:\n",
        "      if df[col].value_counts(normalize=True, dropna=False).to_list()[0] < lowVar:\n",
        "        df = df.drop(columns=[col])\n",
        "\n",
        "\n",
        "  # Getting the number of features that are numerical\n",
        "  numerical_features = df.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "  # Getting the amounts in each feature of the cardinal features\n",
        "  cardinalFeatureAmounts = df.select_dtypes(exclude='number')\n",
        "  cardinalFeatureAmounts = cardinalFeatureAmounts.nunique()\n",
        "  # checking to see if 'ward' is in the list\n",
        "\n",
        "  # Creating a list of the features that have less than 50 cardinality\n",
        "  cardinal = cardinalFeatureAmounts[cardinalFeatureAmounts <= numCardinal].index.tolist()\n",
        "  \n",
        "  if num != None:\n",
        "    #This is to reduce the number of features in the cardinal groups\n",
        "    for feature in cardinal:\n",
        "      # getting the top specified amount\n",
        "      topNum = df[feature].value_counts().index[:num-1].tolist()\n",
        "      # replace those that are not in there with 'other'\n",
        "      df.loc[~df[feature].isin(topNum), feature] = 'Other'\n",
        "\n",
        "  # List of all the features\n",
        "  features = numerical_features + cardinal\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  return df[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9F7pkmhdDvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train1 = wrangleFxn(train, cols_to_drop=cols_to_drop, numCardinal=55, useMode=True, num=None, highVar=.90, lowVar=.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYv7kLsppDLz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "d3e9d7f0-2883-4c2c-d3a9-d37aa419b839"
      },
      "source": [
        "x_train1.isnull().sum()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "amount_tsh                  0\n",
              "gps_height                  0\n",
              "longitude                1458\n",
              "latitude                 1458\n",
              "region_code                 0\n",
              "district_code               0\n",
              "population                  0\n",
              "construction_year           0\n",
              "year_recorded               0\n",
              "month_recorded              0\n",
              "day_recorded                0\n",
              "year_age                    0\n",
              "public_meeting           3334\n",
              "scheme_management        3877\n",
              "permit                   3056\n",
              "extraction_type             0\n",
              "extraction_type_group       0\n",
              "extraction_type_class       0\n",
              "management                  0\n",
              "management_group            0\n",
              "payment                     0\n",
              "water_quality               0\n",
              "quantity                    0\n",
              "source_class                0\n",
              "waterpoint_type             0\n",
              "waterpoint_type_group       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlJ--3_CexAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = wrangleFxn(test, cols_to_drop=cols_to_drop, numCardinal=55, useMode=True, num=20, highVar=.88, lowVar=.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvrpnPN2faVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# going to do some sklearn imports\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import category_encoders as ce \n",
        "from sklearn.impute import SimpleImputer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRiobv7bhHJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making the pipeline\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='mean'), \n",
        "    RandomForestClassifier(n_estimators=150, max_depth=10, min_samples_split=3, min_samples_leaf=2, random_state=42 )\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q_il08Kk04_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f05b758-61ac-4671-dbad-e5752363bb81"
      },
      "source": [
        "cross_val_score(pipeline, x_train1, y_train, cv=5, n_jobs=-1, scoring='neg_median_absolute_error')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 544, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 591, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n    *args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\", line 212, in _score\n    **self._kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_regression.py\", line 384, in median_absolute_error\n    y_true, y_pred, multioutput)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_regression.py\", line 85, in _check_reg_targets\n    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\", line 531, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\", line 85, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\", line 951, in __array__\n    return np.asarray(self.array, dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\", line 85, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/arrays/numpy_.py\", line 166, in __array__\n    return np.asarray(self._ndarray, dtype=dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\", line 85, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'functional'\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-9164f28234e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_median_absolute_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'functional'"
          ]
        }
      ]
    }
  ]
}